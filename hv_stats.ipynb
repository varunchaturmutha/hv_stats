{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1001\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1001\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.2.1.min.js\": \"qkRvDQVAIfzsJo40iRBbxt6sttt0hv4lh74DG7OK4MCHv4C5oohXYoHUM5W11uqS\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.2.1.min.js\": \"Sb7Mr06a9TNlet/GEBeKaf5xH3eb6AlCzwjtU82wNPyDrnfoiVl26qnvlKjmcAd+\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.2.1.min.js\": \"HaJ15vgfmcfRtB4c4YBOI4f1MUujukqInOWVqZJZZGK7Q+ivud0OKGSTn/Vm2iso\"};\n",
       "\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      if (url in hashes) {\n",
       "        element.crossOrigin = \"anonymous\";\n",
       "        element.integrity = \"sha384-\" + hashes[url];\n",
       "      }\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  \n",
       "  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.2.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.2.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.2.1.min.js\"];\n",
       "  var css_urls = [];\n",
       "  \n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    function(Bokeh) {\n",
       "    \n",
       "    \n",
       "    }\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if (root.Bokeh !== undefined || force === true) {\n",
       "      \n",
       "    for (var i = 0; i < inline_js.length; i++) {\n",
       "      inline_js[i].call(root, root.Bokeh);\n",
       "    }\n",
       "    if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1001\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    const hashes = {\"https://cdn.bokeh.org/bokeh/release/bokeh-2.2.1.min.js\": \"qkRvDQVAIfzsJo40iRBbxt6sttt0hv4lh74DG7OK4MCHv4C5oohXYoHUM5W11uqS\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.2.1.min.js\": \"Sb7Mr06a9TNlet/GEBeKaf5xH3eb6AlCzwjtU82wNPyDrnfoiVl26qnvlKjmcAd+\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.2.1.min.js\": \"HaJ15vgfmcfRtB4c4YBOI4f1MUujukqInOWVqZJZZGK7Q+ivud0OKGSTn/Vm2iso\"};\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      if (url in hashes) {\n        element.crossOrigin = \"anonymous\";\n        element.integrity = \"sha384-\" + hashes[url];\n      }\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  \n  var js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.2.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.2.1.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.2.1.min.js\"];\n  var css_urls = [];\n  \n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    function(Bokeh) {\n    \n    \n    }\n  ];\n\n  function run_inline_js() {\n    \n    if (root.Bokeh !== undefined || force === true) {\n      \n    for (var i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\n    if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "\n",
    "from bokeh.plotting import *\n",
    "from bokeh.layouts import gridplot\n",
    "from bokeh.models import *# Span, ColumnDataSource, LogColorMapper, ColorMapper, LogTicker, ColorBar, BasicTicker, LinearColorMapper, PrintfTickFormatter, HoverTool, CategoricalColorMapper, Range1d, Title\n",
    "from bokeh.models.widgets import Tabs, Panel\n",
    "from bokeh.io import show, output_notebook, reset_output\n",
    "output_notebook()\n",
    "from bokeh.models.glyphs import Text\n",
    "import bokeh.palettes as bp\n",
    "from bokeh.transform import factor_cmap\n",
    "\n",
    "import json\n",
    "import urllib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import (MultipleLocator, FormatStrFormatter, AutoMinorLocator)\n",
    "\n",
    "from pathlib import Path\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from hv_setup import *\n",
    "weekdays = [ 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_url = urllib.request.urlopen('https://api.helioviewer.org/?action=getDataSources')\n",
    "hv_keys = json.loads(json_url.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv_sid = pd.DataFrame(columns=['OBS','SOURCE_ID'])\n",
    "\n",
    "# while sid=='sourceId':\n",
    "#     key=hv_keys.keys()\n",
    "\n",
    "for key1 in hv_keys.keys():\n",
    "    for key2 in hv_keys[key1].keys():\n",
    "        if 'sourceId' in hv_keys[key1][key2].keys(): \n",
    "            hv_sid.loc[len(hv_sid)] = \" \".join([key1, key2]), hv_keys[key1][key2]['sourceId']\n",
    "        else:\n",
    "            for key3 in hv_keys[key1][key2].keys():\n",
    "                if 'sourceId' in hv_keys[key1][key2][key3].keys(): \n",
    "                    hv_sid.loc[len(hv_sid)] = \" \".join([key1, key2, key3]), hv_keys[key1][key2][key3]['sourceId']\n",
    "                else:\n",
    "                    for key4 in hv_keys[key1][key2][key3].keys():\n",
    "                        if 'sourceId' in hv_keys[key1][key2][key3][key4].keys(): \n",
    "                            hv_sid.loc[len(hv_sid)] = \" \".join([key1, key2, key3, key4]), hv_keys[key1][key2][key3][key4]['sourceId']\n",
    "                        else:\n",
    "                            for key5 in hv_keys[key1][key2][key3][key4].keys():\n",
    "                                if 'sourceId' in hv_keys[key1][key2][key3][key4][key5].keys(): \n",
    "                                    hv_sid.loc[len(hv_sid)] = \" \".join([key1, key2, key3, key4, key5]), hv_keys[key1][key2][key3][key4][key5]['sourceId']\n",
    "                                else:\n",
    "                                    for key6 in hv_keys[key1][key2][key3][key4][key5].keys():\n",
    "                                        if 'sourceId' in hv_keys[key1][key2][key3][key4][key5][key6].keys(): \n",
    "                                            hv_sid.loc[len(hv_sid)] = \" \".join([key1, key2, key3, key4, key5,key6]), hv_keys[key1][key2][key3][key4][key5][key6]['sourceId']    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBS</th>\n",
       "      <th>SOURCE_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SOHO EIT 171</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SOHO EIT 195</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SOHO EIT 284</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SOHO EIT 304</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SOHO LASCO C2 white-light</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Hinode XRT Al_poly Any</td>\n",
       "      <td>10009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Hinode XRT Be_med Any</td>\n",
       "      <td>10010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Hinode XRT Be_thin Any</td>\n",
       "      <td>10011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Hinode XRT C_poly Any</td>\n",
       "      <td>10012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Hinode XRT Open Any</td>\n",
       "      <td>10013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          OBS SOURCE_ID\n",
       "0                SOHO EIT 171         0\n",
       "1                SOHO EIT 195         1\n",
       "2                SOHO EIT 284         2\n",
       "3                SOHO EIT 304         3\n",
       "4   SOHO LASCO C2 white-light         4\n",
       "..                        ...       ...\n",
       "71     Hinode XRT Al_poly Any     10009\n",
       "72      Hinode XRT Be_med Any     10010\n",
       "73     Hinode XRT Be_thin Any     10011\n",
       "74      Hinode XRT C_poly Any     10012\n",
       "75        Hinode XRT Open Any     10013\n",
       "\n",
       "[76 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hv_sid = hv_sid.sort_values(['SOURCE_ID']).reset_index(drop=True)\n",
    "hv_sid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting SQL query for table data in hv database...\n",
      "Querying completed in 67 seconds.\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting SQL query for table data in hv database...\")\n",
    "def sql_hv(sourceId, obs=None):\n",
    "    query = \"SELECT date_format(date, '%Y-%m-%d 00:00:00') as date, count(*) as count FROM data FORCE INDEX (date_index) WHERE sourceId={} GROUP BY date_format(date, '%Y-%m-%d 00:00:00');\".format(sourceId)\n",
    "    hv = sql_query(query)\n",
    "    return hv_prepare(hv, sourceId, obs)\n",
    "\n",
    "par = Parallel(n_jobs=20)\n",
    "start_time=time.time()\n",
    "results = par(delayed(sql_hv)(df['SOURCE_ID'], df['OBS']) for ind, df in hv_sid.iterrows())\n",
    "print(\"Querying completed in %d seconds.\"%(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>date</th>\n",
       "      <th>Year</th>\n",
       "      <th>Day</th>\n",
       "      <th>SOURCE_ID</th>\n",
       "      <th>OBS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1996-04-01</td>\n",
       "      <td>1996 April</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>SOHO LASCO C3 white-light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1996-04-02</td>\n",
       "      <td>1996 April</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>SOHO LASCO C3 white-light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1996-04-03</td>\n",
       "      <td>1996 April</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>SOHO LASCO C3 white-light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1996-04-04</td>\n",
       "      <td>1996 April</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>SOHO LASCO C3 white-light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1996-04-05</td>\n",
       "      <td>1996 April</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>SOHO LASCO C3 white-light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8914</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-08-27</td>\n",
       "      <td>2020 August</td>\n",
       "      <td>27</td>\n",
       "      <td>5</td>\n",
       "      <td>SOHO LASCO C3 white-light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8915</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-08-28</td>\n",
       "      <td>2020 August</td>\n",
       "      <td>28</td>\n",
       "      <td>5</td>\n",
       "      <td>SOHO LASCO C3 white-light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8916</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-08-29</td>\n",
       "      <td>2020 August</td>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>SOHO LASCO C3 white-light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8917</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-08-30</td>\n",
       "      <td>2020 August</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>SOHO LASCO C3 white-light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8918</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2020-08-31</td>\n",
       "      <td>2020 August</td>\n",
       "      <td>31</td>\n",
       "      <td>5</td>\n",
       "      <td>SOHO LASCO C3 white-light</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8919 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      count       date         Year Day  SOURCE_ID                        OBS\n",
       "0       NaN 1996-04-01   1996 April   1          5  SOHO LASCO C3 white-light\n",
       "1       NaN 1996-04-02   1996 April   2          5  SOHO LASCO C3 white-light\n",
       "2       NaN 1996-04-03   1996 April   3          5  SOHO LASCO C3 white-light\n",
       "3       NaN 1996-04-04   1996 April   4          5  SOHO LASCO C3 white-light\n",
       "4       NaN 1996-04-05   1996 April   5          5  SOHO LASCO C3 white-light\n",
       "...     ...        ...          ...  ..        ...                        ...\n",
       "8914    NaN 2020-08-27  2020 August  27          5  SOHO LASCO C3 white-light\n",
       "8915    NaN 2020-08-28  2020 August  28          5  SOHO LASCO C3 white-light\n",
       "8916    NaN 2020-08-29  2020 August  29          5  SOHO LASCO C3 white-light\n",
       "8917    NaN 2020-08-30  2020 August  30          5  SOHO LASCO C3 white-light\n",
       "8918    NaN 2020-08-31  2020 August  31          5  SOHO LASCO C3 white-light\n",
       "\n",
       "[8919 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hv_obs = {}\n",
    "for i in range(len(hv_sid)):\n",
    "    if results[i].empty:\n",
    "        hv_sid = hv_sid.drop(index = hv_sid.index[hv_sid.index == i])\n",
    "        continue\n",
    "    hv_obs[hv_sid.iloc[i]['SOURCE_ID']] = results[i]\n",
    "hv_obs[np.random.choice(list(hv_obs.keys()))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COVERAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing coverage plots...\n",
      "Coverage plots completed.\n"
     ]
    }
   ],
   "source": [
    "print(\"Preparing coverage plots...\")\n",
    "directory = './coverages'\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "    \n",
    "for observatory in hv_keys.keys():\n",
    "    panels_obs=[]\n",
    "    for ind, df_obs in hv_sid[hv_sid['OBS'].str.match(observatory)].iterrows():\n",
    "        \n",
    "        df = hv_obs[df_obs['SOURCE_ID']].copy()\n",
    "        df['index'] = (df['date'].dt.year - df['date'].min().year)*12 + (df['date'].dt.month - df['date'].min().month)\n",
    "        sid = df['SOURCE_ID'].unique()[0]\n",
    "        name = df['OBS'][0]\n",
    "        name_ = name.replace(\" \", \"_\")\n",
    "\n",
    "        years = np.array(df['Year'].unique()).astype(str)# hv_cov.index.values#.astype(str)\n",
    "        days = df['Day'].unique().astype(str) # np.arange(1,32).astype(str)\n",
    "\n",
    "        colors = bp.Viridis[256]# [\"#75968f\", \"#a5bab7\", \"#c9d9d3\", \"#e2e2e2\", \"#dfccce\", \"#ddb7b1\", \"#cc7878\", \"#933b41\", \"#550b1d\"]\n",
    "\n",
    "        TOOLS = \"hover,save,pan,box_zoom,reset,wheel_zoom\"\n",
    "\n",
    "        # output_file('AIA1600_coverage.html')\n",
    "        panels = []\n",
    "        for mapper_type, mapper, ticker in zip([\"log\", \"linear\"],\n",
    "                                               [LogColorMapper, LinearColorMapper],\n",
    "                                               [LogTicker, BasicTicker]):\n",
    "            p = figure(y_range=list(reversed(days)),\n",
    "                       x_axis_location=\"above\",\n",
    "                       sizing_mode='stretch_both',# width_policy='max', height_policy='max',#, plot_width=1400,\n",
    "#                        match_aspect=True,\n",
    "                       x_axis_label=\"Year Month\", y_axis_label=\"Date\",\n",
    "                       tools=TOOLS, output_backend=\"webgl\", toolbar_location='above',\n",
    "                       tooltips=[('Date', '@Year @Day'), ('#Data Files', '@count{0,0}')])\n",
    "                       \n",
    "\n",
    "            total_days = (hv_obs[sid]['count']>=0).sum()\n",
    "            total_files = (hv_obs[sid]['count']).sum()\n",
    "            \n",
    "            p.add_layout(Title(text=\"%s Coverage\"%(name), text_font_size='14pt'), 'above')\n",
    "            p.add_layout(Title(text=\"Date Range: %s - %s\"%(df.dropna()['date'].min().strftime(\"%Y, %b %d\"), df.dropna()['date'].max().strftime(\"%Y, %b %d\"))), 'above')\n",
    "            p.add_layout(Title(text=\"Total Files: {:,.0f} | Total Days: {:,.0f} | Source ID: {:,.0f}\".format(total_files, total_days, df['SOURCE_ID'].unique()[0]), text_font_style=\"italic\"), 'above')\n",
    "#             p.add_layout(Title(text=\"Total Days: %d\"%total_days, text_font_style=\"italic\"), 'above')\n",
    "#             p.add_layout(Title(text=\"Source ID: %d\"%df['SOURCE_ID'].unique()[0], text_font_style=\"italic\"), 'above')\n",
    "\n",
    "            # p.grid.grid_line_color = None\n",
    "            p.axis.axis_line_color = None\n",
    "            p.axis.major_tick_line_color = None\n",
    "            p.axis.major_label_text_font_size = \"7px\"\n",
    "            p.axis.major_label_standoff = 0\n",
    "            p.xaxis.major_label_orientation = np.pi / 3\n",
    "            p.xaxis.axis_label_text_font_size = \"12pt\"\n",
    "            p.yaxis.axis_label_text_font_size = \"12pt\"\n",
    "            p.xaxis.visible = True\n",
    "            p.xgrid.visible = True\n",
    "            p.ygrid.visible = False\n",
    "\n",
    "            p.xaxis.major_label_text_font_size = \"7pt\"\n",
    "            p.yaxis.major_label_text_font_size = \"8pt\"\n",
    "\n",
    "\n",
    "            p.rect(x=\"index\", y=\"Day\", width=1, height=1,\n",
    "                   source=df, \n",
    "                   hover_alpha=0.3,\n",
    "                   hover_color=\"navy\",#{'field': 'count', 'transform': mapper(palette=colors, low=0.1, high=np.nanmax(df['count']))},\n",
    "                   color={'field': 'count', 'transform': mapper(palette=colors, low=0.1, high=np.nanmax(df['count']))},\n",
    "                   line_color=None, \n",
    "                   dilate=True)\n",
    "            \n",
    "            num_ticks=10\n",
    "            if (len(df[df['count']>0]['count'].unique()) <= 10):\n",
    "                num_ticks = len(df[df['count']>0]['count'].unique())\n",
    "            color_bar = ColorBar(color_mapper = mapper(palette=colors, low=0.1, high=np.nanmax(df['count'])), \n",
    "                                 major_label_text_font_size=\"10px\",\n",
    "                                 ticker=ticker(desired_num_ticks=num_ticks),\n",
    "                                 formatter=NumeralTickFormatter(format=\"0,0\"),\n",
    "                                 label_standoff=6, border_line_color=None, location=(0, 0))\n",
    "            p.add_layout(color_bar, 'right')\n",
    "            interval_months = 3\n",
    "            inter_thresh = 12\n",
    "            if(len(years)<inter_thresh): \n",
    "                interval_months = 1\n",
    "            p.xaxis.ticker = df['index'].unique()[::interval_months]\n",
    "            p.xaxis.major_tick_line_color = 'black'\n",
    "            p.xaxis.major_label_overrides = {i*interval_months: date for i, date in enumerate(years[::interval_months])}\n",
    "#             p.width_policy = 'fit'\n",
    "#             p.height_policy = 'fit'\n",
    "            p.border_fill_color = \"whitesmoke\"\n",
    "            p.x_range.range_padding = 0.0\n",
    "            p.y_range.range_padding = 0.0\n",
    "            panel = Panel(child=p, title=mapper_type)\n",
    "            panels.append(panel)\n",
    "        tabs = Tabs(tabs=panels)\n",
    "#         show(tabs)\n",
    "        panel_obs = Panel(child=tabs, title=name.replace(observatory+' ',''))\n",
    "        panels_obs.append(panel_obs)\n",
    "        \n",
    "    tabs_obs = Tabs(tabs=panels_obs)\n",
    "#     show(tabs_obs)\n",
    "    save(tabs_obs, filename='./coverages/%s_coverage.html'%observatory, title=\"Coverage plot for %s\"%observatory)\n",
    "#     break\n",
    "print(\"Coverage plots completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HISTOGRAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing histogram and cumulative distribution plots...\n",
      "Histograms and cumulative distribution plots completed.\n"
     ]
    }
   ],
   "source": [
    "print(\"Preparing histogram and cumulative distribution plots...\")\n",
    "directory = './histograms'\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "for observatory in hv_keys.keys():\n",
    "    panels_obs=[]\n",
    "    for ind, df_obs in hv_sid[hv_sid['OBS'].str.match(observatory)].iterrows():\n",
    "        \n",
    "        df = hv_obs[df_obs['SOURCE_ID']].copy()\n",
    "        sid = df['SOURCE_ID'].unique()[0]\n",
    "        name = df['OBS'][0]\n",
    "        name_ = name.replace(\" \", \"_\")\n",
    "\n",
    "        df = hv_obs[sid].copy()\n",
    "        df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "        name = df['OBS'].unique()[0]\n",
    "        name_ = name.replace(\" \", \"_\")\n",
    "\n",
    "        bin_size = bin_width(df['count'].max())# np.arange(0,count.max(),) 30#.astype(int)#100\n",
    "#         btabs = interactive_histogram(df['count'], sid, name, bin_size)\n",
    "        counts = df['count']\n",
    "        title=name\n",
    "\n",
    "        arr_hist, edges, patches = plt.hist(counts, bins=np.arange(0, counts.max()+bin_size, bin_size))\n",
    "        cum_bin_size  = max(bin_size//10,1)\n",
    "        cum_hist, cum_edges, patches = plt.hist(counts, bins=np.arange(0,counts.max()+cum_bin_size, cum_bin_size), cumulative=True)\n",
    "        plt.close()\n",
    "\n",
    "        # Column data source\n",
    "        df_hist = pd.DataFrame({'count': arr_hist, 'left': edges[:-1], 'right': edges[1:]})\n",
    "        total = df_hist['count'].sum()\n",
    "        df_hist['f_count'] = ['%d' % count for count in df_hist['count']]\n",
    "        df_hist['f_percent'] = ['%.2f%%' %(count/total*100) for count in df_hist['count']]\n",
    "        df_hist['f_interval'] = ['[%d,%d) ' % (left, right) for left, right in zip(df_hist['left'], df_hist['right'])]\n",
    "        # column data source\n",
    "        hist_src = ColumnDataSource(df_hist)\n",
    "\n",
    "        #cumulative data\n",
    "        cumulative_data = cum_hist#np.cumsum(arr_hist)\n",
    "        x_bins = cum_edges[1:]#edges[1:]# np.arange(0, counts.max(), bin_size)[1:]\n",
    "        df_cum = pd.DataFrame({'count_cum': cumulative_data, 'x': x_bins})\n",
    "        cum_src = ColumnDataSource(df_cum)\n",
    "    #     df_hist['f_count'] = np.log10(df_hist['f_count']+1)\n",
    "        # Set up the figure same as before\n",
    "        panels = []\n",
    "\n",
    "        for axis_type in [\"log\",\"linear\"]:\n",
    "            p = figure(y_axis_type = axis_type,\n",
    "                       x_axis_label = 'No. of Data files', y_axis_label = 'Day count', \n",
    "                       background_fill_color=\"#fafafa\",\n",
    "                       y_range = (0.9, df_hist['count'].max() + df_hist['count'].max()//10))\n",
    "\n",
    "            # Add a quad glyph with source this time\n",
    "            p.quad(bottom=0.9, top='count', left='left', right='right', source=hist_src, fill_color='navy', alpha=0.5,\n",
    "                   hover_fill_color='navy', hover_fill_alpha=0.2, line_color='white', legend_label='Histogram')\n",
    "    #         p.y_range(Range1d(0.8,df_hist['count'].max()))\n",
    "            # Add style to the plot\n",
    "            p.title.align = 'center'\n",
    "            p.title.text_font_size = '18pt'\n",
    "            p.xaxis.axis_label_text_font_size = '12pt'\n",
    "            p.xaxis.major_label_text_font_size = '12pt'\n",
    "            p.yaxis.axis_label_text_font_size = '12pt'\n",
    "            p.yaxis.major_label_text_font_size = '12pt'\n",
    "            p.yaxis[0].formatter = NumeralTickFormatter(format='0,0')\n",
    "            p.xaxis[0].formatter = NumeralTickFormatter(format='0,0')\n",
    "            \n",
    "            df_stats = pd.DataFrame({'height': np.linspace(0.5, df_hist['count'].max(), 2),\n",
    "                                     'mean':np.nanmean(counts), 'median': np.nanmedian(counts), 'mode':stats.mode(counts)[0][0]})\n",
    "            p.line(x='mean', y='height', line_color=\"black\", line_dash='solid', line_width = 4, legend_label=\"Mean (%.2f)\"%(df_stats['mean'][0]), source=df_stats)\n",
    "            p.line(x='median', y='height', line_color = \"red\", line_dash='dashed', line_width=3, legend_label=\"Median (%.2f)\"%(df_stats['median'][0]), source=df_stats)\n",
    "#             p.line(x='mode', y='height', line_color = \"lightgreen\", line_dash = 'dashdot',line_width=2,legend_label=\"Mode (%.2f)\"%(df_stats['mode'][0]), source=df_stats)\n",
    "\n",
    "            total_days = (counts>=0).sum()\n",
    "            total_files = counts.sum()\n",
    "            \n",
    "            p.add_layout(Title(text = \"Histogram for %s\"%title, text_font_size = \"16pt\", text_font_style=\"bold\"), \n",
    "                         place = 'above')\n",
    "            p.add_layout(Title(text=\"Date range: %s - %s\"%(df['date'].min().strftime('%Y, %b %d'),df['date'].max().strftime('%Y, %b %d'))),\n",
    "                         place = 'above')\n",
    "            p.add_layout(Title(text=\"Total Files: {:,.0f} | Total Days: {:,.0f} | Source ID: {}\".format(total_files, total_days, sid), text_font_style=\"italic\"),\n",
    "                         place = 'above')\n",
    "\n",
    "    #         p.legend.location = \"top_left\"\n",
    "    #         p.grid.grid_line_color=\"white\"\n",
    "\n",
    "    #         text_source = ColumnDataSource(dict(x=[x_bins.max()*3/4],y=[df_hist['count'].max()*3/4],text=['Total Day Count = \\n %d'%total]))\n",
    "    #         glyph = Text(x=\"x\", y=\"y\", text=\"text\", text_color=\"black\")\n",
    "    #         p.add_glyph(text_source, glyph)\n",
    "\n",
    "            # Add a hover tool referring to the formatted columns\n",
    "            hover = HoverTool(tooltips = [('#Data files', '@f_interval'),\n",
    "                                          ('Day count', '@f_count{0,0}'),\n",
    "                                          ('Day count percentage', '@f_percent')],\n",
    "                              mode= 'vline')\n",
    "\n",
    "            # Add the hover tool to the graph\n",
    "            p.add_tools(hover)\n",
    "            p.border_fill_color = \"whitesmoke\"\n",
    "\n",
    "            p2 = figure(y_axis_type=axis_type,\n",
    "                       x_axis_label = 'No. of Data files', \n",
    "                       y_axis_label = 'Day count',\n",
    "                       background_fill_color=\"#fafafa\")\n",
    "                       \n",
    "\n",
    "            p2_line = p2.line(x='x', y='count_cum', line_color='#036564', line_width=3, source=cum_src, legend_label=\"Cumulative distribution\")\n",
    "    #         p2_circle = p2.circle(x='x', y='count_cum', line_color='#036564', line_width=5, source=cum_src, hover_line_alpha=0.5, legend_label=\"Cumulative distribution\" )\n",
    "            p2.add_layout(Title(text = \"Cumulative Distribution for %s\"%title, text_font_size = \"16pt\", text_font_style=\"bold\"), place = 'above')\n",
    "            p2.add_layout(Title(text=\"Date range: %s - %s\"%(df['date'].min().strftime('%Y, %b %d'),df['date'].max().strftime('%Y, %b %d'))), 'above')\n",
    "            p2.add_layout(Title(text=\"Total Files: {:,.0f} | Total Days: {:,.0f} | Source ID: {}\".format(total_files, total_days, sid), text_font_style=\"italic\"), 'above')\n",
    "#             p2.add_layout(Title(text=\"Total Days: %d\"%total_days, text_font_style=\"italic\"), 'above')\n",
    "#             p2.add_layout(Title(text=\"Source ID: %d\"%sid, text_font_style=\"italic\"), 'above')\n",
    "            \n",
    "            hover = HoverTool(line_policy='nearest', \n",
    "                              tooltips = [('#Data files', '<@x{0,0}'), \n",
    "                                          ('Cumulative Day count', '@count_cum{0,0}')], \n",
    "                              mode='vline')\n",
    "            df_cumstats = pd.DataFrame({'height': np.linspace(df_cum['count_cum'].min(),df_cum['count_cum'].max(),2),\n",
    "                                        'mean':np.nanmean(counts), 'median': np.nanmedian(counts), 'mode':stats.mode(counts)[0][0]})\n",
    "            p2.line(x='mean', y='height', line_color=\"black\", line_dash='solid', line_width = 4, legend_label=\"Mean (%.2f)\"%(df_cumstats['mean'][0]), source=df_cumstats)\n",
    "            p2.line(x='median', y='height', line_color = \"red\", line_dash='dashed', line_width=3, legend_label=\"Median (%.2f)\"%(df_cumstats['median'][0]), source=df_cumstats)\n",
    "#             p2.line(x='mode', y='height', line_color = \"lightgreen\", line_dash = 'dashdot',line_width=2,legend_label=\"Mode (%.2f)\"%(df_cumstats['mode'][0]), source=df_cumstats)\n",
    "        \n",
    "\n",
    "            # Add the hover tool to the graph\n",
    "            p2.add_tools(hover)\n",
    "            p2.title.align = 'center'\n",
    "            p2.title.text_font_size = '18pt'\n",
    "            p2.xaxis.axis_label_text_font_size = '12pt'\n",
    "            p2.xaxis.major_label_text_font_size = '12pt'\n",
    "            p2.yaxis.axis_label_text_font_size = '12pt'\n",
    "            p2.yaxis.major_label_text_font_size = '12pt'\n",
    "            p2.legend.location = \"bottom_right\"\n",
    "            p2.yaxis[0].formatter = NumeralTickFormatter(format='0,0')\n",
    "            p2.xaxis[0].formatter = NumeralTickFormatter(format='0,0')\n",
    "            p2.border_fill_color = \"whitesmoke\"\n",
    "            grid = gridplot([[p, p2]], sizing_mode='stretch_both')# width_policy='max', height_policy='max')#,plot_width=1200, plot_height=1000, sizing_mode='scale_width')#, plot_width=250, plot_height=250)\n",
    "            panel = Panel(child=grid, title=axis_type)\n",
    "            panels.append(panel)\n",
    "        tabs = Tabs(tabs=panels)\n",
    "#         show(tabs)\n",
    "        panel_obs = Panel(child=tabs, title=name.replace(observatory+' ',''))\n",
    "        panels_obs.append(panel_obs)\n",
    "    tabs_obs = Tabs(tabs=panels_obs)\n",
    "#     show(tabs_obs)\n",
    "    save(tabs_obs, filename='./%s/%s_histogram.html'%(directory, observatory), title=\"Histogram and Cumulative distribution for %s\"%observatory)\n",
    "#     break\n",
    "print(\"Histograms and cumulative distribution plots completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sid in hv_obs.keys()\n",
    "#     df = hv_obs[sid].copy()\n",
    "#     name = df['OBS'].unique()[0]\n",
    "#     name_ = name.replace(\" \", \"_\")\n",
    "    \n",
    "#     df = df.dropna().reset_index(drop=True)\n",
    "#     f = open(\"./csv_files/%d_%s.csv\"%(sid, name_), mode='w')\n",
    "#     f.write(\"# %s\\n\"%name)\n",
    "#     f.write(\"# %d\\n\"%sid)\n",
    "#     df.to_csv(f, columns=[\"date\", \"count\", \"SOURCE_ID\", \"OBS\"], index=False)\n",
    "#     f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for key in hv_obs.keys():\n",
    "#     if len(hv_obs[key]) < 100: \n",
    "#         plt.scatter(key, len(hv_obs[key].dropna().reset_index(drop=True)))\n",
    "#         print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POSTER PLOTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helioviewer Movie length histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Helioviewer Movies' Length histogram ###\n",
      "Starting SQL query in movies table of hv database...\n",
      "Query completed in 6 seconds.\n"
     ]
    }
   ],
   "source": [
    "print(\"### Helioviewer Movies' Length histogram ###\")\n",
    "print(\"Starting SQL query in movies table of hv database...\")\n",
    "start_time = time.time()\n",
    "hv={}\n",
    "# query=\"SELECT dataSourceString FROM movies\"\n",
    "# query = \"SELECT DATE_FORMAT(reqStartDate, '%1980-%m-%d %H:%i:%S') AS reqStartDate, timestamp, reqEndDate, startDate, endDate, dataSourceString FROM movies\"\n",
    "# date_format(reqStartDate, '%Y-%m-%d %H:%i:%s') AS REQ_START, date_format(reqEndDate, '%Y-%m-%d %H:%i:%s')\n",
    "query = \"SELECT reqStartDate, reqEndDate, dataSourceString, eventSourceString, numFrames, frameRate, maxFrames, timestamp as date, TIMESTAMPDIFF(second, reqStartDate, reqEndDate) AS reqDuration, TIMESTAMPDIFF(second, startDate, endDate) AS genDuration FROM movies WHERE reqEndDate!='None' AND reqStartDate!='None' AND startDate!='None' AND endDate!='None';\"\n",
    "# query = \"SELECT ROUND(TIMESTAMPDIFF(second, reqStartDate, reqEndDate)/60/60/24, 3) AS reqDuration, ROUND(TIMESTAMPDIFF(second, startDate, endDate)/60/60/24, 3) AS genDuration FROM movies;\"\n",
    "hv['hv_movies'] = sql_query(query)\n",
    "print(\"Query completed in %d seconds.\"%(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reqStartDate</th>\n",
       "      <th>reqEndDate</th>\n",
       "      <th>dataSourceString</th>\n",
       "      <th>eventSourceString</th>\n",
       "      <th>numFrames</th>\n",
       "      <th>frameRate</th>\n",
       "      <th>maxFrames</th>\n",
       "      <th>date</th>\n",
       "      <th>reqDuration</th>\n",
       "      <th>genDuration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>503991</th>\n",
       "      <td>2014-03-01 13:43:57</td>\n",
       "      <td>2014-03-01 16:43:57</td>\n",
       "      <td>[STEREO_B,SECCHI,EUVI,284,2,100],[STEREO_B,SEC...</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>30.0</td>\n",
       "      <td>300</td>\n",
       "      <td>2014-03-05 12:11:19</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503997</th>\n",
       "      <td>2014-03-01 13:48:57</td>\n",
       "      <td>2014-03-01 16:48:57</td>\n",
       "      <td>[STEREO_B,SECCHI,EUVI,304,2,100],[STEREO_B,SEC...</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>30.0</td>\n",
       "      <td>300</td>\n",
       "      <td>2014-03-05 12:24:47</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503985</th>\n",
       "      <td>2014-03-01 13:27:57</td>\n",
       "      <td>2014-03-01 16:27:57</td>\n",
       "      <td>[STEREO_B,SECCHI,EUVI,171,2,100],[STEREO_B,SEC...</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>25.0</td>\n",
       "      <td>300</td>\n",
       "      <td>2014-03-05 11:56:20</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.080000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447834</th>\n",
       "      <td>2013-11-28 00:24:05</td>\n",
       "      <td>2013-11-28 01:24:05</td>\n",
       "      <td>[PROBA2,SWAP,SWAP,174,1,100],[SOHO,LASCO,C2,wh...</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>30.0</td>\n",
       "      <td>300</td>\n",
       "      <td>2013-11-27 21:45:50</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124513</th>\n",
       "      <td>2012-04-27 08:17:06</td>\n",
       "      <td>2012-04-27 09:17:06</td>\n",
       "      <td>[SOHO,LASCO,C2,white-light,1,100],[SOHO,LASCO,...</td>\n",
       "      <td>[NA,none,1]</td>\n",
       "      <td>3</td>\n",
       "      <td>30.0</td>\n",
       "      <td>300</td>\n",
       "      <td>2012-05-14 16:24:51</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805205</th>\n",
       "      <td>2018-04-03 08:30:07</td>\n",
       "      <td>2018-04-10 08:30:07</td>\n",
       "      <td>[STEREO_A,SECCHI,EUVI,195,2,100,0,60,1,2018-04...</td>\n",
       "      <td></td>\n",
       "      <td>300</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300</td>\n",
       "      <td>2018-04-05 21:03:16</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>927360</th>\n",
       "      <td>2020-03-02 02:05:35</td>\n",
       "      <td>2020-03-09 02:05:35</td>\n",
       "      <td>[SOHO,LASCO,C3,white-light,3,100,1,60,1,2020-0...</td>\n",
       "      <td>[AR,all,1],[CC,all,1],[CD,all,1],[CH,all,1],[C...</td>\n",
       "      <td>300</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300</td>\n",
       "      <td>2020-05-31 10:39:40</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761589</th>\n",
       "      <td>2017-09-03 12:54:08</td>\n",
       "      <td>2017-09-10 12:54:08</td>\n",
       "      <td>[SOHO,LASCO,C3,white-light,3,100]</td>\n",
       "      <td></td>\n",
       "      <td>300</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300</td>\n",
       "      <td>2017-09-06 22:03:21</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>705545</th>\n",
       "      <td>2016-10-24 18:55:58</td>\n",
       "      <td>2016-10-31 18:55:58</td>\n",
       "      <td>[SDO,AIA,193,1,100]</td>\n",
       "      <td></td>\n",
       "      <td>300</td>\n",
       "      <td>1.0</td>\n",
       "      <td>300</td>\n",
       "      <td>2016-10-31 14:55:56</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690995</th>\n",
       "      <td>2016-07-04 11:00:06</td>\n",
       "      <td>2016-08-01 11:00:06</td>\n",
       "      <td>[SDO,AIA,94,1,97]</td>\n",
       "      <td></td>\n",
       "      <td>300</td>\n",
       "      <td>0.1</td>\n",
       "      <td>300</td>\n",
       "      <td>2016-08-05 08:17:57</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>938749 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               reqStartDate          reqEndDate  \\\n",
       "503991  2014-03-01 13:43:57 2014-03-01 16:43:57   \n",
       "503997  2014-03-01 13:48:57 2014-03-01 16:48:57   \n",
       "503985  2014-03-01 13:27:57 2014-03-01 16:27:57   \n",
       "447834  2013-11-28 00:24:05 2013-11-28 01:24:05   \n",
       "124513  2012-04-27 08:17:06 2012-04-27 09:17:06   \n",
       "...                     ...                 ...   \n",
       "805205  2018-04-03 08:30:07 2018-04-10 08:30:07   \n",
       "927360  2020-03-02 02:05:35 2020-03-09 02:05:35   \n",
       "761589  2017-09-03 12:54:08 2017-09-10 12:54:08   \n",
       "705545  2016-10-24 18:55:58 2016-10-31 18:55:58   \n",
       "690995  2016-07-04 11:00:06 2016-08-01 11:00:06   \n",
       "\n",
       "                                         dataSourceString  \\\n",
       "503991  [STEREO_B,SECCHI,EUVI,284,2,100],[STEREO_B,SEC...   \n",
       "503997  [STEREO_B,SECCHI,EUVI,304,2,100],[STEREO_B,SEC...   \n",
       "503985  [STEREO_B,SECCHI,EUVI,171,2,100],[STEREO_B,SEC...   \n",
       "447834  [PROBA2,SWAP,SWAP,174,1,100],[SOHO,LASCO,C2,wh...   \n",
       "124513  [SOHO,LASCO,C2,white-light,1,100],[SOHO,LASCO,...   \n",
       "...                                                   ...   \n",
       "805205  [STEREO_A,SECCHI,EUVI,195,2,100,0,60,1,2018-04...   \n",
       "927360  [SOHO,LASCO,C3,white-light,3,100,1,60,1,2020-0...   \n",
       "761589                  [SOHO,LASCO,C3,white-light,3,100]   \n",
       "705545                                [SDO,AIA,193,1,100]   \n",
       "690995                                  [SDO,AIA,94,1,97]   \n",
       "\n",
       "                                        eventSourceString  numFrames  \\\n",
       "503991                                                             2   \n",
       "503997                                                             2   \n",
       "503985                                                             2   \n",
       "447834                                                             3   \n",
       "124513                                        [NA,none,1]          3   \n",
       "...                                                   ...        ...   \n",
       "805205                                                           300   \n",
       "927360  [AR,all,1],[CC,all,1],[CD,all,1],[CH,all,1],[C...        300   \n",
       "761589                                                           300   \n",
       "705545                                                           300   \n",
       "690995                                                           300   \n",
       "\n",
       "        frameRate  maxFrames                date  reqDuration  genDuration  \n",
       "503991       30.0        300 2014-03-05 12:11:19     0.125000     0.066667  \n",
       "503997       30.0        300 2014-03-05 12:24:47     0.125000     0.066667  \n",
       "503985       25.0        300 2014-03-05 11:56:20     0.125000     0.080000  \n",
       "447834       30.0        300 2013-11-27 21:45:50     0.041667     0.100000  \n",
       "124513       30.0        300 2012-05-14 16:24:51     0.041667     0.100000  \n",
       "...           ...        ...                 ...          ...          ...  \n",
       "805205        1.0        300 2018-04-05 21:03:16     7.000000   300.000000  \n",
       "927360        1.0        300 2020-05-31 10:39:40     7.000000   300.000000  \n",
       "761589        1.0        300 2017-09-06 22:03:21     7.000000   300.000000  \n",
       "705545        1.0        300 2016-10-31 14:55:56     7.000000   300.000000  \n",
       "690995        0.1        300 2016-08-05 08:17:57    28.000000          NaN  \n",
       "\n",
       "[938749 rows x 10 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = hv['hv_movies'].copy()\n",
    "\n",
    "df['reqDuration'] = pd.to_timedelta(df['reqDuration'], unit='s')/pd.Timedelta(days=1)\n",
    "df['reqDuration'].loc[df['reqDuration']>30] = np.nan\n",
    "df['genDuration'] = pd.to_timedelta((df['numFrames']/df['frameRate']), unit='s')/pd.Timedelta(seconds=1)\n",
    "outlier_count = df['genDuration'].loc[df['genDuration']>300]\n",
    "outlier_date = df['date'].loc[df['genDuration']>300].dt.strftime(\"%b %d %Y, %H:%M:%S\").values[0]\n",
    "df['genDuration'].loc[df['genDuration']>300] = np.nan\n",
    "df.sort_values('genDuration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing histogram for movie lengths...\n",
      "Histograms prepared.\n"
     ]
    }
   ],
   "source": [
    "# bin_size = 100# 0.5*24*60*60# np.arange(0,count.max(),) 30#.astype(int)#100\n",
    "print(\"Preparing histogram for movie lengths...\")\n",
    "\n",
    "directory = 'hv_movies'\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "    \n",
    "panels_pov=[]\n",
    "for pov, ref, bin_size, unit, unit2, conversion_factor in zip(['reqDuration','genDuration'], \n",
    "                                                              ['requested','generated'],\n",
    "                                                              [1, 10],['days','seconds'], ['years', 'days'], \n",
    "                                                              [365, 60*60*24]):\n",
    "\n",
    "    counts = df[pov]\n",
    "\n",
    "    arr_hist, edges = np.histogram(counts, bins=np.arange(0, counts.max()+bin_size, bin_size))\n",
    "    cum_bin_size = max(bin_size//10, 1)\n",
    "    cum_hist, cum_edges, patches = plt.hist(counts, bins=np.arange(0,counts.max()+cum_bin_size, cum_bin_size), cumulative=True)\n",
    "    plt.close()\n",
    "\n",
    "    # Column data source\n",
    "    df_hist = pd.DataFrame({'count': arr_hist, 'left': edges[:-1], 'right': edges[1:]})\n",
    "    total = df_hist['count'].sum()\n",
    "    df_hist['f_count'] = ['%d' % count for count in df_hist['count']]\n",
    "    df_hist['f_percent'] = ['%.3f%%' %(count/total*100) for count in df_hist['count']]\n",
    "    df_hist['f_interval'] = ['[%.1f %s,%.1f %s)' % (left, unit, right, unit) for left, right in zip(df_hist['left'], df_hist['right'])]\n",
    "    hist_src = ColumnDataSource(df_hist)\n",
    "\n",
    "    #cumulative data\n",
    "    cumulative_data = cum_hist#np.cumsum(arr_hist)\n",
    "    x_bins = cum_edges[1:]#edges[1:]# np.arange(0, counts.max(), bin_size)[1:]\n",
    "    df_cum = pd.DataFrame({'count_cum': cumulative_data, 'x': x_bins})\n",
    "    df_cum['f_percent'] = ['%.3f%%' %(count/total*100) for count in df_cum['count_cum']]\n",
    "    cum_src = ColumnDataSource(df_cum)\n",
    "\n",
    "    panels = []\n",
    "    for axis_type in [\"log\",\"linear\"]:\n",
    "        p = figure(y_axis_type = axis_type,\n",
    "                   x_axis_label = 'Length of movies (%s)'%(unit), y_axis_label = 'Movie count', \n",
    "                   background_fill_color=\"#fafafa\",\n",
    "                   y_range = (0.5, df_hist['count'].max() + df_hist['count'].max()//10)\n",
    "                  )\n",
    "\n",
    "        # Add a quad glyph with source this time\n",
    "        p_hist = p.quad(bottom=0.5, top='count', left='left', right='right', source=hist_src, fill_color='navy', alpha=0.5,\n",
    "               hover_fill_color='navy', hover_fill_alpha=0.2, line_color='white', legend_label='Histogram')\n",
    "        # Add style to the plot\n",
    "        p.title.align = 'center'\n",
    "        p.title.text_font_size = '18pt'\n",
    "        p.xaxis.axis_label_text_font_size = '12pt'\n",
    "        p.xaxis.major_label_text_font_size = '12pt'\n",
    "        p.yaxis.axis_label_text_font_size = '12pt'\n",
    "        p.yaxis.major_label_text_font_size = '12pt'\n",
    "#         p.yaxis[0].formatter = PrintfTickFormatter(format=\"%f\")\n",
    "        p.yaxis[0].formatter = NumeralTickFormatter(format='0,0')\n",
    "        \n",
    "    #         p.add_layout(Span(location=1800, dimension='height'))#, legend_label='Expected date file count'))\n",
    "        df_stats = pd.DataFrame({'height': np.linspace(min(df_hist['count'].min(),0.5),df_hist['count'].max(),2),\n",
    "                                 'mean':np.nanmean(counts), 'median': np.nanmedian(counts), 'mode':stats.mode(counts)[0][0]})\n",
    "        p.line(x='mean', y='height', line_color=\"black\", line_dash='solid', line_width = 4, legend_label=\"Mean (%.2f %s)\"%(df_stats['mean'][0], unit), source=df_stats)\n",
    "        p.line(x='median', y='height', line_color = \"red\", line_dash='dashed', line_width=3, legend_label=\"Median (%.2f %s)\"%(df_stats['median'][0],unit), source=df_stats)\n",
    "#         p.line(x='mode', y='height', line_color = \"lightgreen\", line_dash = 'dashdot',line_width=2,legend_label=\"Mode (%.2f %s)\"%(df_stats['mode'][0],unit), source=df_stats)\n",
    "\n",
    "        total_days = len(counts)\n",
    "        total_files = counts.sum()\n",
    "\n",
    "        p.add_layout(Title(text = \"Histogram for length of movies %s\"%(ref), text_font_size = \"16pt\", text_font_style=\"bold\"), \n",
    "                     place = 'above')\n",
    "        p.add_layout(Title(text=\"%s during: %s - %s\"%(ref, df['date'].min().strftime('%Y, %b %d'),df['date'].max().strftime('%Y, %b %d'))), \n",
    "                     place = 'above')\n",
    "        if(ref=='generated'):\n",
    "            p.add_layout(Title(text=\"(Movie of length %d seconds %s on %s was discarded)\"%(outlier_count, ref, outlier_date), text_font_style=\"italic\"), \n",
    "                          place = 'above')\n",
    "        p.add_layout(Title(text=\"Total length of movies {}: {:,.2f} {} ({:,.2f} {}) | Total Movies: {:,} \".format(ref, total_files, unit, total_files/conversion_factor, unit2, total_days), text_font_style=\"italic\"), \n",
    "                     place = 'above')\n",
    "\n",
    "        p.legend.location = \"top_right\"\n",
    "        p.grid.grid_line_color=\"white\"\n",
    "\n",
    "        # Add a hover tool referring to the formatted columns\n",
    "        hover = HoverTool(tooltips = [('Length of movies %s'%(ref), '@f_interval'),\n",
    "                                      ('Movie count', '@f_count{0,0}'),\n",
    "                                      ('Movie count percentage', '@f_percent')],\n",
    "#                           formatters={'f_count'      : 'printf', # use 'datetime' formatter for 'date' field\n",
    "#                         'count' : 'int',   # use 'printf' formatter for 'adj close' field\n",
    "#                                           use default 'numeral' formatter for other fields\n",
    "#                                      },\n",
    "                          mode= 'vline')\n",
    "\n",
    "        # Add the hover tool to the graph\n",
    "        p.add_tools(hover)\n",
    "        p.border_fill_color = \"whitesmoke\"\n",
    "        \n",
    "        p2 = figure(y_axis_type=axis_type,\n",
    "                           x_axis_label = 'Length of movies (%s)'%(unit), \n",
    "                           y_axis_label = 'Movie count',\n",
    "                           background_fill_color=\"#fafafa\")\n",
    "\n",
    "\n",
    "        p2_line = p2.line(x='x', y='count_cum', line_color='#036564', line_width=3, source=cum_src, legend_label=\"Cumulative distribution\")\n",
    "    #         p2_circle = p2.circle(x='x', y='count_cum', line_color='#036564', line_width=5, source=cum_src, hover_line_alpha=0.5, legend_label=\"Cumulative distribution\" )\n",
    "        p2.add_layout(Title(text = \"Cumulative distribution for length of movies %s\"%(ref), text_font_size = \"16pt\", text_font_style=\"bold\"), \n",
    "                      place = 'above')\n",
    "        p2.add_layout(Title(text=\"%s during: %s - %s\"%(ref, df['date'].min().strftime('%Y, %b %d'),df['date'].max().strftime('%Y, %b %d'))), \n",
    "                      place = 'above')\n",
    "        if(ref=='generated'):\n",
    "            p2.add_layout(Title(text=\"(Movie of length %d seconds %s on %s was discarded)\"%(outlier_count, ref, outlier_date), text_font_style=\"italic\"), \n",
    "                          place = 'above')\n",
    "        p2.add_layout(Title(text=\"Total length of movies {}: {:,.2f} {} ({:,.2f} {}) | Total Movies: {:,} \".format(ref, total_files, unit, total_files/conversion_factor, unit2, total_days), text_font_style=\"italic\"), \n",
    "                     place = 'above')\n",
    "\n",
    "        hover = HoverTool(line_policy='nearest', \n",
    "                          tooltips = [('Length of movies %s'%(ref), '<@x{0.2f} %s'%unit), \n",
    "                                      ('Percentage of %s'%(ref), '<@f_percent'),\n",
    "                                      ('Cumulative Day count', '@count_cum{0,0}')],\n",
    "                          mode='vline')\n",
    "\n",
    "        df_cumstats = pd.DataFrame({'height': np.linspace(df_cum['count_cum'].min(),df_cum['count_cum'].max(),2),\n",
    "                                 'mean':np.nanmean(counts), 'median': np.nanmedian(counts), 'mode':stats.mode(counts)[0][0]})\n",
    "        p2.line(x='mean', y='height', line_color=\"black\", line_dash='solid', line_width = 4, legend_label=\"Mean (%.2f %s)\"%(df_cumstats['mean'][0], unit), source=df_cumstats)\n",
    "        p2.line(x='median', y='height', line_color = \"red\", line_dash='dashed', line_width=3, legend_label=\"Median (%.2f %s)\"%(df_cumstats['median'][0], unit), source=df_cumstats)\n",
    "#         p2.line(x='mode', y='height', line_color = \"lightgreen\", line_dash = 'dashdot',line_width=2,legend_label=\"Mode (%.2f %s)\"%(df_cumstats['mode'][0], unit), source=df_cumstats)\n",
    "#         p2.add_layout(Span(location=10, dimension='height', legend_label='Expected date file count'))\n",
    "        \n",
    "        # Add the hover tool to the graph\n",
    "        p2.add_tools(hover)\n",
    "        p2.title.align = 'center'\n",
    "        p2.title.text_font_size = '18pt'\n",
    "        p2.xaxis.axis_label_text_font_size = '12pt'\n",
    "        p2.xaxis.major_label_text_font_size = '12pt'\n",
    "        p2.yaxis.axis_label_text_font_size = '12pt'\n",
    "        p2.yaxis.major_label_text_font_size = '12pt'\n",
    "        p2.legend.location = \"bottom_right\"\n",
    "#         p2.yaxis[0].formatter = PrintfTickFormatter(format=\"0,0%f\")\n",
    "        p2.yaxis[0].formatter = NumeralTickFormatter(format='0,0')\n",
    "        p2.border_fill_color = \"whitesmoke\"\n",
    "\n",
    "        grid = gridplot([[p, p2]], sizing_mode='stretch_both')# width_policy='max', height_policy='max')#,plot_width=1200, plot_height=1000, sizing_mode='scale_width')#, plot_width=250, plot_height=250)\n",
    "        panel = Panel(child=grid, title=axis_type)\n",
    "        panels.append(panel)\n",
    "    tabs = Tabs(tabs=panels)\n",
    "    panel_pov = Panel(child=tabs, title=ref)\n",
    "    panels_pov.append(panel_pov)\n",
    "\n",
    "tabs_pov = Tabs(tabs=panels_pov)\n",
    "# show(tabs_pov)\n",
    "save(tabs_pov, filename='./%s/histogram_length.html'%directory, title='Histogram for length of Helioviewer movies')\n",
    "print(\"Histograms prepared.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stats for movies made per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Stats for movies prepared per day ###\n"
     ]
    }
   ],
   "source": [
    "print(\"### Stats for movies prepared per day ###\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting SQL query in movies, screenshots, movies_jpx, statistics tables of hv database...\n",
      "Query completed in 90 seconds.\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting SQL query in movies, screenshots, movies_jpx, statistics tables of hv database...\")\n",
    "\n",
    "hv={}\n",
    "query = \"SELECT date_format(timestamp, '%Y-%m-%d 00:00:00') as date, count(*) as count FROM {} GROUP BY date_format(timestamp, '%Y-%m-%d 00:00:00');\"\n",
    "\n",
    "start_time=time.time()\n",
    "\n",
    "hv['hv_movies'] = sql_query(query.format('movies'))\n",
    "\n",
    "hv['hv_screenshots'] = sql_query(query.format('screenshots'))\n",
    "\n",
    "hv['Jhv_movies'] = sql_query(query.format('movies_jpx'))\n",
    "\n",
    "hv['embed_service'] = sql_query(query.format(\"statistics WHERE action=\\'embed\\'\"))\n",
    "\n",
    "hv['hv_student'] = sql_query(query.format(\"statistics WHERE action=\\'minimal\\'\"))\n",
    "\n",
    "print(\"Query completed in %d seconds.\"%(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = [\"Helioviewer.org Movies generated\", \"Helioviewer.org Screenshots generated\", \n",
    "          \"JHelioviewer Movies generated\", \"Times Embedded Helioviewer.org service was used\",\n",
    "         \"Student Helioviewer Movies generated\"]\n",
    "services= [\"Movies\", \"Screenshots\", \"Movies\", \"Embed usage\", \"Movies\"]\n",
    "\n",
    "for key in hv.keys():\n",
    "    hv[key] = hv[key].dropna()\n",
    "    hv[key]['date'] = pd.to_datetime(hv[key]['date'])\n",
    "    hv[key] = hv[key].sort_values(['date']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "server_shutdown_days = ((pd.Timestamp('2011/09/18') - pd.Timestamp('2011/08/11') + pd.Timedelta(days=1))+\n",
    "                        (pd.Timestamp('2013/10/16') - pd.Timestamp('2013/10/01') + pd.Timedelta(days=1))+\n",
    "                        (pd.Timestamp('2015/09/23') - pd.Timestamp('2015/02/04') + pd.Timedelta(days=1))).days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making time series of movies generated per day...\n",
      "Time series completed.\n"
     ]
    }
   ],
   "source": [
    "print(\"Making time series of movies generated per day...\")\n",
    "for key, title, service in zip(hv.keys(), titles, services):\n",
    "    directory = key\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        \n",
    "    df = hv[key].copy()\n",
    "    df = df.set_index('date')\n",
    "    df = df.reindex(pd.date_range(df.index.min(), df.index.max(), freq='D').to_period('D').to_timestamp(),\n",
    "                                  fill_value=0)\n",
    "    df['date'] = df.index\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    df_0 = df.loc[df['count']==0].reset_index(drop=True)\n",
    "\n",
    "    df.loc[(df['date'] >= pd.Timestamp('2011/08/11')) & (df['date'] <= pd.Timestamp('2011/09/18')), 'count'] = np.nan\n",
    "    df.loc[(df['date'] >= pd.Timestamp('2013/10/01')) & (df['date'] <= pd.Timestamp('2013/10/16')), 'count'] = np.nan\n",
    "    df.loc[(df['date'] >= pd.Timestamp('2015/02/04')) & (df['date'] <= pd.Timestamp('2015/09/23')), 'count'] = np.nan\n",
    "\n",
    "    TOOLS = \"save, pan, box_zoom, reset, wheel_zoom\"\n",
    "\n",
    "    df_src = ColumnDataSource(df)\n",
    "\n",
    "    p = figure(plot_height=250, x_axis_type=\"datetime\", \n",
    "               tools=TOOLS,\n",
    "               sizing_mode=\"scale_width\", min_border_left = 0)\n",
    "\n",
    "\n",
    "    p.add_layout(Title(text = \"Number of %s every day\"%title, text_font_size = \"16pt\", text_font_style=\"bold\"), \n",
    "                 place = 'above')\n",
    "    p.add_layout(Title(text = \"Date Range: %s - %s\"%(df['date'].min().strftime('%Y, %b %d'),df['date'].max().strftime('%Y, %b %d'))), \n",
    "                 place = 'above')\n",
    "    p.add_layout(Title(text=\"Total {}: {:,.0f} | Total Days: {:,} (excluding {:,} days of server downtime) \".format(title, df['count'].sum(), len(df.dropna()), len(df)-len(df.dropna())), text_font_style=\"italic\"), \n",
    "                 place = 'above')\n",
    "\n",
    "    p.background_fill_color=\"#f5f5f5\"\n",
    "    p.grid.grid_line_color=\"white\"\n",
    "    p.xaxis.axis_label = 'Date'\n",
    "    p.yaxis.axis_label = 'No. of %s'%title\n",
    "    p.axis.axis_line_color = None\n",
    "    \n",
    "    p.x_range.start = df['date'].min() - (df['date'].max()-df['date'].min())*0.02\n",
    "    p.x_range.end = df['date'].max() + (df['date'].max()-df['date'].min())*0.02\n",
    "    \n",
    "#     p.x_range.range_padding = 0.02\n",
    "    p.y_range.range_padding = 0.05\n",
    "    \n",
    "    p.yaxis[0].formatter = NumeralTickFormatter(format='0,0')\n",
    "#     p.xaxis[0].formatter = DatetimeTickFormatter(days=[\"%b %d, %Y %H\"])\n",
    "    p.xaxis.ticker = YearsTicker(desired_num_ticks=10)#, num_minor_ticks=12)\n",
    "#     p.xaxis[0].ticker.desired_num_ticks = 10\n",
    "\n",
    "    p_line = p.line(x='date', y='count', line_width=2, color='#ebbd5b', source=df_src)\n",
    "    p_0 = p.circle(x='date', y='count', size=2, color='red', source = df_0, legend_label='Zero %s'%service)\n",
    "    \n",
    "    service_pause(p, df)\n",
    "    major_features(p, df)\n",
    "    \n",
    "    p.add_tools(HoverTool(renderers=[p_line],\n",
    "                          tooltips=[( 'date',   '@date{%F}'),\n",
    "        #               ( 'close',  '$@{adj close}{%0.2f}' ), # use @{ } for field names with spaces\n",
    "                                    ( '#%s'%service, '@count{0,0}'),#{0.00 a}'      ),\n",
    "                                   ],\n",
    "                          formatters={'@date'      : 'datetime', # use 'datetime' formatter for 'date' field\n",
    "#                                       'count' : 'int',   # use 'printf' formatter for 'adj close' field\n",
    "                                      # use default 'numeral' formatter for other fields\n",
    "                                     },\n",
    "    #     display a tooltip whenever the cursor is vertically in line with a glyph\n",
    "    #     mode='vline'\n",
    "                         ))\n",
    "    df_stats = pd.DataFrame({'height': pd.date_range(df['date'].min(),df['date'].max(),periods=2),\n",
    "                             'mean':np.nanmean(df['count']), 'median': np.nanmedian(df['count']), 'mode':stats.mode(df['count'])[0][0]})\n",
    "    p.line(y='mean', x='height', line_color=\"blue\", line_dash='dotted', line_width = 1, legend_label=\"Mean ({:,.2f})\".format(df_stats['mean'][0]), source=df_stats)\n",
    "    p.line(y='median', x='height', line_color = \"black\", line_dash='dashed', line_width=1, legend_label=\"Median ({:,.2f})\".format(df_stats['median'][0]), source=df_stats)\n",
    "    p.legend.background_fill_alpha = 0.3\n",
    "    p.border_fill_color = \"whitesmoke\"\n",
    "    \n",
    "#     show(p)\n",
    "    save(p, filename='./%s/time_series.html'%key, title='%s every day'%title)\n",
    "print(\"Time series completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histogram of media per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making histogram of movies generated per day...\n",
      "Histograms completed.\n"
     ]
    }
   ],
   "source": [
    "print(\"Making histogram of movies generated per day...\")\n",
    "for key, title, service in zip(hv.keys(), titles, services):\n",
    "    directory = key\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        \n",
    "    df = hv[key].copy()\n",
    "    df = df.set_index('date')\n",
    "    df = df.reindex(pd.date_range(df.index.min(), df.index.max(), freq='D').to_period('D').to_timestamp(),\n",
    "                                  fill_value=0)\n",
    "    df['date'] = df.index\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    df.loc[(df['date'] >= pd.Timestamp('2011/08/11')) & (df['date'] <= pd.Timestamp('2011/09/18')), 'count'] = np.nan\n",
    "    df.loc[(df['date'] >= pd.Timestamp('2013/10/01')) & (df['date'] <= pd.Timestamp('2013/10/16')), 'count'] = np.nan\n",
    "    df.loc[(df['date'] >= pd.Timestamp('2015/02/04')) & (df['date'] <= pd.Timestamp('2015/09/23')), 'count'] = np.nan\n",
    "\n",
    "    bin_size = bin_width(df['count'].max())# np.arange(0,count.max(),) 30#.astype(int)#100\n",
    "    counts = df['count']\n",
    "\n",
    "    arr_hist, edges = np.histogram(counts, bins=np.arange(0, counts.max()+bin_size, bin_size))\n",
    "    cum_bin_size  = max(bin_size//10,1)\n",
    "    cum_hist, cum_edges, patches = plt.hist(counts, bins=np.arange(0,counts.max()+cum_bin_size, cum_bin_size), cumulative=True)\n",
    "    plt.close()\n",
    "\n",
    "    # Column data source\n",
    "    df_hist = pd.DataFrame({'count': arr_hist, 'left': edges[:-1], 'right': edges[1:]})\n",
    "    total = df_hist['count'].sum()\n",
    "    df_hist['f_count'] = ['%d' % count for count in df_hist['count']]\n",
    "    df_hist['f_percent'] = ['%.2f%%' %(count/total*100) for count in df_hist['count']]\n",
    "    df_hist['f_interval'] = ['[{:,.0f} - {:,.0f})'.format(left, right) for left, right in zip(df_hist['left'], df_hist['right'])]\n",
    "    hist_src = ColumnDataSource(df_hist)\n",
    "\n",
    "    #cumulative data\n",
    "    cumulative_data = cum_hist#np.cumsum(arr_hist)\n",
    "    x_bins = cum_edges[1:]#edges[1:]# np.arange(0, counts.max(), bin_size)[1:]\n",
    "    df_cum = pd.DataFrame({'count_cum': cumulative_data, 'x': x_bins})\n",
    "    df_cum['f_percent'] = ['%.2f%%' %(count/total*100) for count in df_cum['count_cum']]\n",
    "    cum_src = ColumnDataSource(df_cum)\n",
    "\n",
    "    panels = []\n",
    "    for axis_type in [\"log\",\"linear\"]:\n",
    "        p = figure(y_axis_type = axis_type,\n",
    "                   x_axis_label = 'No. of %s'%title, y_axis_label = 'Day count', \n",
    "                   background_fill_color=\"#fafafa\",\n",
    "                   y_range = (0.9, df_hist['count'].max() + df_hist['count'].max()//10))\n",
    "\n",
    "        # Add a quad glyph with source this time\n",
    "        p.quad(bottom=0.9, top='count', left='left', right='right', source=hist_src, fill_color='navy', alpha=0.5,\n",
    "               hover_fill_color='navy', hover_fill_alpha=0.2, line_color='white', legend_label='Histogram')\n",
    "    #         p.y_range(Range1d(0.8,df_hist['count'].max()))\n",
    "        # Add style to the plot\n",
    "        p.title.align = 'center'\n",
    "        p.title.text_font_size = '18pt'\n",
    "        p.xaxis.axis_label_text_font_size = '12pt'\n",
    "        p.xaxis.major_label_text_font_size = '12pt'\n",
    "        p.yaxis.axis_label_text_font_size = '12pt'\n",
    "        p.yaxis.major_label_text_font_size = '12pt'\n",
    "        \n",
    "        p.yaxis[0].formatter = NumeralTickFormatter(format='0,0')\n",
    "        p.xaxis[0].formatter = NumeralTickFormatter(format='0,0')\n",
    "        \n",
    "        df_stats = pd.DataFrame({'height': np.linspace(0.5, df_hist['count'].max(), 2),\n",
    "                                 'mean':np.nanmean(counts), 'median': np.nanmedian(counts), 'mode':stats.mode(counts)[0][0]})\n",
    "        p.line(x='mean', y='height', line_color=\"black\", line_dash='solid', line_width = 4, legend_label=\"Mean (%.2f)\"%(df_stats['mean'][0]), source=df_stats)\n",
    "        p.line(x='median', y='height', line_color = \"red\", line_dash='dashed', line_width=3, legend_label=\"Median (%.2f)\"%(df_stats['median'][0]), source=df_stats)\n",
    "#         p.line(x='mode', y='height', line_color = \"lightgreen\", line_dash = 'dashdot',line_width=2,legend_label=\"Mode (%.2f)\"%(df_stats['mode'][0]), source=df_stats)\n",
    "        \n",
    "        total_days = (counts>=0).sum()\n",
    "        total_files = counts.sum()\n",
    "\n",
    "        p.add_layout(Title(text = \"Histogram for %s \"%title, text_font_size = \"12pt\", text_font_style=\"bold\"), place = 'above')\n",
    "        p.add_layout(Title(text=\"Date range: %s - %s\"%(df['date'].min().strftime('%Y, %b %d'),df['date'].max().strftime('%Y, %b %d'))), 'above')\n",
    "        p.add_layout(Title(text=\"Total {} generated: {:,.0f} | Total Days: {:,} (excluding {:,} days of server downtime)\".format(service, total_files, total_days, len(df)-len(df.dropna())), text_font_style=\"italic\"), 'above')\n",
    "\n",
    "        p.legend.location = \"top_right\"\n",
    "        p.legend.background_fill_alpha = 0.3\n",
    "        p.border_fill_color = \"whitesmoke\"\n",
    "        \n",
    "    #     p.grid.grid_line_color=\"white\"\n",
    "\n",
    "    #     text_source = ColumnDataSource(dict(x=[x_bins.max()*3/4],y=[df_hist['count'].max()*3/4],text=['Total Day Count = \\n %d'%total]))\n",
    "    #     glyph = Text(x=\"x\", y=\"y\", text=\"text\", text_color=\"black\")\n",
    "    #     p.add_glyph(text_source, glyph)\n",
    "\n",
    "        # Add a hover tool referring to the formatted columns\n",
    "        hover = HoverTool(tooltips = [('#%s generated'%service, '@f_interval'),\n",
    "                                      ('Day count', '@f_count{0,0}'),\n",
    "                                      ('Day count percentage', '@f_percent')],\n",
    "                          mode= 'vline')\n",
    "\n",
    "        # Add the hover tool to the graph\n",
    "        p.add_tools(hover)\n",
    "        p2 = figure(y_axis_type=axis_type,\n",
    "                           x_axis_label = 'No. of %s'%key, \n",
    "                           y_axis_label = 'Day count',\n",
    "                           background_fill_color=\"#fafafa\")\n",
    "\n",
    "\n",
    "        p2_line = p2.line(x='x', y='count_cum', line_color='#036564', line_width=3, source=cum_src, legend_label=\"Cumulative distribution\")\n",
    "        p2.add_layout(Title(text = \"Cumulative distribution for %s\"%title, text_font_size = \"12pt\", text_font_style=\"bold\"), place = 'above')\n",
    "        p2.add_layout(Title(text=\"Date range: %s - %s\"%(df['date'].min().strftime('%Y, %b %d'),df['date'].max().strftime('%Y, %b %d'))), 'above')\n",
    "        p2.add_layout(Title(text=\"Total {} generated: {:,.0f} | Total Days: {:,} (excluding {:,} days of server downtime)\".format(service, total_files, total_days, len(df)-len(df.dropna())), text_font_style=\"italic\"), 'above')\n",
    "\n",
    "        hover = HoverTool(line_policy='nearest', \n",
    "                          tooltips = [('#%s generated'%service, '<@x{0,0}'), \n",
    "                                      ('Percentage of %s generated'%service, '<@f_percent'),\n",
    "                                      ('Cumulative Day count', '@count_cum{0,0}')],\n",
    "                          mode='vline')\n",
    "\n",
    "    #         p2.add_layout(Span(location=1800, dimension='height'))#, legend_label='Expected date file count'))\n",
    "        \n",
    "        df_cumstats = pd.DataFrame({'height': np.linspace(df_cum['count_cum'].min(),df_cum['count_cum'].max(),2),\n",
    "                                    'mean':np.nanmean(counts), 'median': np.nanmedian(counts), 'mode':stats.mode(counts)[0][0]})\n",
    "        p2.line(x='mean', y='height', line_color=\"black\", line_dash='solid', line_width = 4, legend_label=\"Mean ({:,.2f})\".format(df_cumstats['mean'][0]), source=df_cumstats)\n",
    "        p2.line(x='median', y='height', line_color = \"red\", line_dash='dashed', line_width=3, legend_label=\"Median ({:,.2f})\".format(df_cumstats['median'][0]), source=df_cumstats)\n",
    "#         p2.line(x='mode', y='height', line_color = \"lightgreen\", line_dash = 'dashdot',line_width=2,legend_label=\"Mode (%.2f)\"%(df_cumstats['mode'][0]), source=df_cumstats)\n",
    "        \n",
    "        # Add the hover tool to the graph\n",
    "        p2.add_tools(hover)\n",
    "        p2.title.align = 'center'\n",
    "        p2.title.text_font_size = '18pt'\n",
    "        p2.xaxis.axis_label_text_font_size = '12pt'\n",
    "        p2.xaxis.major_label_text_font_size = '12pt'\n",
    "        p2.yaxis.axis_label_text_font_size = '12pt'\n",
    "        p2.yaxis.major_label_text_font_size = '12pt'\n",
    "        p2.legend.location = \"bottom_right\"\n",
    "        p2.legend.background_fill_alpha = 0.3\n",
    "        \n",
    "        p2.yaxis[0].formatter = NumeralTickFormatter(format='0,0')\n",
    "        p2.xaxis[0].formatter = NumeralTickFormatter(format='0,0')\n",
    "        p2.border_fill_color = \"whitesmoke\"\n",
    "\n",
    "        grid = gridplot([[p, p2]], sizing_mode='stretch_both')# width_policy='max', height_policy='max')#,plot_width=1200, plot_height=1000, sizing_mode='scale_width')#, plot_width=250, plot_height=250)\n",
    "        panel = Panel(child=grid, title=axis_type)\n",
    "    #     panel = Panel(child=p, title=axis_type)\n",
    "        panels.append(panel)\n",
    "    tabs = Tabs(tabs=panels)\n",
    "#     show(tabs)\n",
    "#     break\n",
    "    save(tabs, filename='./%s/histogram.html'%key, title='Histogram and CDF for %s generated every day'%title)\n",
    "print(\"Histograms completed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weekday frequency distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making weekday frequency distribution of movies generated per day...\n",
      "Weekday frequency distribution done\n"
     ]
    }
   ],
   "source": [
    "print(\"Making weekday frequency distribution of movies generated per day...\")\n",
    "for key, title, service in zip(hv.keys(), titles, services):\n",
    "    directory = key\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        \n",
    "    df = hv[key].copy()\n",
    "    \n",
    "    df_na = df.copy()\n",
    "    df_na = df_na.set_index('date')\n",
    "    df_na = df_na.reindex(pd.date_range(df_na.index.min(),df_na.index.max(), freq='D').to_period('D').to_timestamp(),\n",
    "                                  fill_value=0)\n",
    "    df_na['date'] = df_na.index\n",
    "    df_na = df_na.reset_index(drop=True)\n",
    "    \n",
    "    df_na.loc[(df_na['date'] >= pd.Timestamp('2011/08/11')) & (df_na['date'] <= pd.Timestamp('2011/09/18')), 'count'] = np.nan\n",
    "    df_na.loc[(df_na['date'] >= pd.Timestamp('2013/10/01')) & (df_na['date'] <= pd.Timestamp('2013/10/16')), 'count'] = np.nan\n",
    "    df_na.loc[(df_na['date'] >= pd.Timestamp('2015/02/04')) & (df_na['date'] <= pd.Timestamp('2015/09/23')), 'count'] = np.nan\n",
    "    \n",
    "    server_downtime_days = len(df_na)-len(df_na.dropna())\n",
    "    \n",
    "    df['weekday'] = df['date'].dt.weekday_name\n",
    "    df = df.groupby('weekday').sum().reindex(weekdays)\n",
    "    df['weekday'] = df.index\n",
    "    df = df.reset_index(drop=True)\n",
    "    df['index'] = df.index\n",
    "    \n",
    "    # Column data source\n",
    "    df['percent'] = np.float64([\"%.2f\"%(count/df['count'].sum()*100) for count in df['count']])\n",
    "    df['percent%'] = df['percent'].astype(str)+\"%\"\n",
    "    df['vbar_top'] = df['count'].astype(str) + '\\n' + df['percent'].astype(str)+'%'\n",
    "    df_src = ColumnDataSource(df)\n",
    "    panels = []\n",
    "    for axis_type in [\"linear\",\"log\"]:\n",
    "        p = figure(#x_range = df['weekday'],\n",
    "                   y_axis_type = axis_type,\n",
    "                   x_axis_label = 'Weekdays', y_axis_label = '%s count'%service, \n",
    "                   background_fill_color=\"#fafafa\", aspect_ratio=16/9, plot_width=1000)\n",
    "\n",
    "        # Add a quad glyph with source this time\n",
    "        p.vbar(x='index', top='count', width=0.75, source=df_src, bottom=0.1,\n",
    "               hover_fill_alpha = 0.5, line_color='white', legend_field=\"weekday\",\n",
    "               fill_color = factor_cmap('weekday', palette=bp.Spectral7, factors=df['weekday']),\n",
    "               hover_fill_color=factor_cmap('weekday', palette=bp.Spectral7, factors=df['weekday']), \n",
    "              )\n",
    "        # Add style to the plot\n",
    "        p.title.align = 'center'\n",
    "        p.title.text_font_size = '18pt'\n",
    "        p.xaxis.axis_label_text_font_size = '12pt'\n",
    "        p.xaxis.major_label_text_font_size = '12pt'\n",
    "        p.yaxis.axis_label_text_font_size = '12pt'\n",
    "        p.yaxis.major_label_text_font_size = '12pt'\n",
    "        p.xgrid.grid_line_color = None\n",
    "        \n",
    "        p.y_range.start = 0.1\n",
    "        p.y_range.end = df['count'].max()*1.5\n",
    "        p.yaxis[0].formatter = NumeralTickFormatter(format='0,0')\n",
    "        \n",
    "        if(axis_type==\"log\"): p.y_range.end = df['count'].max()**1.5\n",
    "\n",
    "        p.add_layout(Title(text = \"Frequency of %s per weekday\"%title, text_font_size = \"16pt\", text_font_style=\"bold\"), place = 'above')\n",
    "        p.add_layout(Title(text=\"Date range: %s - %s\"%(hv[key]['date'].min().strftime('%Y, %b %d'),hv[key]['date'].max().strftime('%Y, %b %d'))), 'above')\n",
    "        p.add_layout(Title(text=\"Total {} generated: {:,} | Total Days: {:,} (excluding {:,} days of server downtime)\"\n",
    "                           .format(service, df['count'].sum(), len(df_na.dropna()), server_downtime_days), text_font_style=\"italic\"), 'above')\n",
    "\n",
    "        p.legend.orientation = \"horizontal\"\n",
    "        p.legend.location = \"top_center\"\n",
    "        p.grid.grid_line_color=\"white\"\n",
    "        \n",
    "        labels = LabelSet(x='index', y='count', text='percent%', level='glyph',\n",
    "                          x_offset=-30, y_offset=0, source=df_src)#, render_mode='canvas')\n",
    "        p.add_layout(labels)\n",
    "\n",
    "        # Add a hover tool referring to the formatted column\n",
    "\n",
    "        hover = HoverTool(tooltips = [('#%s generated'%service, '@count{0,0}'),\n",
    "                                      ('Percentage of %s generated'%service, '@percent%')],\n",
    "                          mode= 'vline')\n",
    "\n",
    "    #     Add the hover tool to the graph\n",
    "        p.add_tools(hover)\n",
    "        p.xaxis.major_label_overrides = {i: day for i, day in enumerate(df['weekday'])}\n",
    "        p.xaxis.minor_tick_line_color = None \n",
    "        \n",
    "        p.border_fill_color = \"whitesmoke\"\n",
    "        \n",
    "        panel = Panel(child=p, title=axis_type)\n",
    "        panels.append(panel)\n",
    "    tabs = Tabs(tabs=panels)\n",
    "#     show(tabs)\n",
    "#     break\n",
    "    save(tabs, filename='./%s/weekday_freq.html'%key, title='Histogram for %s generated every day'%title)\n",
    "print(\"Weekday frequency distribution done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weekday frequency against week number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>reason</th>\n",
       "      <th>weekday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-08-11</td>\n",
       "      <td>GSFC server repair \\n (2011/08/11 - 2011/09/18)</td>\n",
       "      <td>Thursday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-08-12</td>\n",
       "      <td>GSFC server repair \\n (2011/08/11 - 2011/09/18)</td>\n",
       "      <td>Friday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-08-13</td>\n",
       "      <td>GSFC server repair \\n (2011/08/11 - 2011/09/18)</td>\n",
       "      <td>Saturday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-08-14</td>\n",
       "      <td>GSFC server repair \\n (2011/08/11 - 2011/09/18)</td>\n",
       "      <td>Sunday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-08-15</td>\n",
       "      <td>GSFC server repair \\n (2011/08/11 - 2011/09/18)</td>\n",
       "      <td>Monday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>2015-09-19</td>\n",
       "      <td>GSFC server down   \\n (2015/02/04 - 2015/09/23)</td>\n",
       "      <td>Saturday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>2015-09-20</td>\n",
       "      <td>GSFC server down   \\n (2015/02/04 - 2015/09/23)</td>\n",
       "      <td>Sunday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>2015-09-21</td>\n",
       "      <td>GSFC server down   \\n (2015/02/04 - 2015/09/23)</td>\n",
       "      <td>Monday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>2015-09-22</td>\n",
       "      <td>GSFC server down   \\n (2015/02/04 - 2015/09/23)</td>\n",
       "      <td>Tuesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>2015-09-23</td>\n",
       "      <td>GSFC server down   \\n (2015/02/04 - 2015/09/23)</td>\n",
       "      <td>Wednesday</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>287 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date                                           reason    weekday\n",
       "0   2011-08-11  GSFC server repair \\n (2011/08/11 - 2011/09/18)   Thursday\n",
       "1   2011-08-12  GSFC server repair \\n (2011/08/11 - 2011/09/18)     Friday\n",
       "2   2011-08-13  GSFC server repair \\n (2011/08/11 - 2011/09/18)   Saturday\n",
       "3   2011-08-14  GSFC server repair \\n (2011/08/11 - 2011/09/18)     Sunday\n",
       "4   2011-08-15  GSFC server repair \\n (2011/08/11 - 2011/09/18)     Monday\n",
       "..         ...                                              ...        ...\n",
       "282 2015-09-19  GSFC server down   \\n (2015/02/04 - 2015/09/23)   Saturday\n",
       "283 2015-09-20  GSFC server down   \\n (2015/02/04 - 2015/09/23)     Sunday\n",
       "284 2015-09-21  GSFC server down   \\n (2015/02/04 - 2015/09/23)     Monday\n",
       "285 2015-09-22  GSFC server down   \\n (2015/02/04 - 2015/09/23)    Tuesday\n",
       "286 2015-09-23  GSFC server down   \\n (2015/02/04 - 2015/09/23)  Wednesday\n",
       "\n",
       "[287 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_service = pd.concat([pd.DataFrame({'date': pd.date_range('2011/08/11', '2011/09/18'), 'reason':\"GSFC server repair \\n (2011/08/11 - 2011/09/18)\"}),\n",
    "                        pd.DataFrame({'date': pd.date_range('2013/10/01', '2013/10/16'), 'reason':\"U.S. Fed. Gov. shutdown \\n  (2013/10/01 - 2013/10/16)\"}),\n",
    "                        pd.DataFrame({'date': pd.date_range('2015/02/04', '2015/09/23'), 'reason':\"GSFC server down   \\n (2015/02/04 - 2015/09/23)\"})],\n",
    "                       ignore_index=True)\n",
    "df_service['weekday'] = df_service['date'].dt.weekday_name\n",
    "df_service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making weekday frequency against weeknumber distribution of movies generated per day...\n",
      "Weekday frequency against weeknumber distribution done.\n"
     ]
    }
   ],
   "source": [
    "print(\"Making weekday frequency against weeknumber distribution of movies generated per day...\")\n",
    "for key, title, service in zip(hv.keys(), titles, services):\n",
    "    directory = key\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    \n",
    "    df = hv[key].copy()\n",
    "    \n",
    "    df = df.set_index('date')\n",
    "    df = df.reindex(pd.date_range(df.index.min(),df.index.max(), freq='D').to_period('D').to_timestamp(),\n",
    "                    fill_value=0)\n",
    "    \n",
    "#     df = df.reindex(pd.date_range(df.index.min() + pd.Timedelta(days=-df.index.min().weekday()), \n",
    "#                                   df.index.max() + pd.Timedelta(days=7-df.index.max().weekday())),\n",
    "#                    fill_value=np.nan)\n",
    "    \n",
    "    df.loc[(df.index >= pd.Timestamp('2011/08/11')) & (df.index <= pd.Timestamp('2011/09/18')), 'count'] = np.nan\n",
    "    df.loc[(df.index >= pd.Timestamp('2013/10/01')) & (df.index <= pd.Timestamp('2013/10/16')), 'count'] = np.nan\n",
    "    df.loc[(df.index >= pd.Timestamp('2015/02/04')) & (df.index <= pd.Timestamp('2015/09/23')), 'count'] = np.nan\n",
    "    \n",
    "    server_downtime_days = len(df)-len(df.dropna())\n",
    "    df_na = df.copy()\n",
    "    df = df.dropna()\n",
    "    \n",
    "    df = pd.concat([df.reindex(pd.date_range(df.index.min() + pd.Timedelta(days=-df.index.min().weekday()), \n",
    "                                             df.index.min() + pd.Timedelta(days=-1)),\n",
    "                          fill_value=np.nan), \n",
    "                    df,\n",
    "                    df.reindex(pd.date_range(df.index.max() + pd.Timedelta(days=1), \n",
    "                                             df.index.max() + pd.Timedelta(days=7-df.index.max().weekday())),\n",
    "                          fill_value=np.nan)])\n",
    "    \n",
    "    df['date'] = df.index\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    df['weekday'] = df['date'].dt.weekday_name\n",
    "    df['weeknumber'] = ((df['date']-df['date'][0]).dt.days/7).astype(int)\n",
    "    df_service['weeknumber'] = ((df_service['date']-df['date'][0]).dt.days/7).astype(int)\n",
    "    # df = df.groupby(['weeknumber','weekday']).sum().reset_index()\n",
    "\n",
    "    weeknumber = np.array(df['weeknumber'].unique()).astype(str)# hv_cov.index.values#.astype(str)\n",
    "    # weekdays = weekdays# df['weekday'].unique().astype(str) # np.arange(1,32).astype(str)\n",
    "\n",
    "    colors = bp.Viridis[256]# [\"#75968f\", \"#a5bab7\", \"#c9d9d3\", \"#e2e2e2\", \"#dfccce\", \"#ddb7b1\", \"#cc7878\", \"#933b41\", \"#550b1d\"]\n",
    "\n",
    "    TOOLS = \"save,pan,box_zoom,reset,wheel_zoom\"\n",
    "\n",
    "    # output_file('AIA1600_coverage.html')\n",
    "    panels = []\n",
    "    for mapper_type, mapper, ticker in zip([\"log\", \"linear\"],\n",
    "                                           [LogColorMapper, LinearColorMapper],\n",
    "                                           [LogTicker, BasicTicker]):\n",
    "        p = figure(y_range=list(reversed(weekdays)),#x_range=weeknumber, \n",
    "                   x_axis_location=None, sizing_mode='stretch_both',# width_policy='max', height_policy='max',#, \n",
    "    #                plot_width=2000,\n",
    "                   x_axis_label=\"Weeks since first data\", y_axis_label=\"Weekday\",\n",
    "                   tools=TOOLS)\n",
    "\n",
    "        p_rect = p.rect(x=\"weeknumber\", y=\"weekday\", width=1, height=1,\n",
    "                        source=df,\n",
    "                        color={'field': 'count', 'transform': mapper(palette=colors, low=0.1, high=np.nanmax(df['count']))},\n",
    "                        hover_fill_alpha=0.2)\n",
    "\n",
    "        p.add_tools(HoverTool(renderers = [p_rect], \n",
    "                              tooltips=[('Week Number', '@weeknumber'), \n",
    "                                        ('#%s'%service, '@count{0,0}'), \n",
    "                                        ('Date','@date{%F}')],\n",
    "                              formatters={'@date': 'datetime'}\n",
    "        ))\n",
    "        xaxis = LinearAxis(ticker=SingleIntervalTicker(interval=7, num_minor_ticks= 1))\n",
    "        p.add_layout(xaxis, 'above')\n",
    "        p.xaxis.axis_label = \"Weeks since first data\"\n",
    "        # p.grid.grid_line_color = None\n",
    "        p.axis.axis_line_color = None\n",
    "        p.axis.major_tick_line_color = None\n",
    "#         p.axis.major_label_text_font_size = \"300pt\"\n",
    "        p.axis.major_label_standoff = 0\n",
    "        p.xaxis.major_label_orientation = np.pi / 3\n",
    "        p.xaxis.axis_label_text_font_size = \"12pt\"\n",
    "    #     p.xaxis.major_label_text_color = {'field': 'weeknumber', 'transform': mapper(palette=bp.Spectral6, low=0.1, high=np.nanmax(df['count']))}\n",
    "        p.yaxis.axis_label_text_font_size = \"12pt\"\n",
    "        p.xaxis.visible = True\n",
    "        p.xgrid.visible = False\n",
    "        p.ygrid.visible = False\n",
    "        p.x_range.range_padding = 0.0\n",
    "        p.y_range.range_padding = 0.0  \n",
    "        \n",
    "\n",
    "        p.xaxis.major_label_text_font_size = \"8pt\"\n",
    "        p.yaxis.major_label_text_font_size = \"10pt\"\n",
    "\n",
    "        \n",
    "        p.add_layout(Title(text = \"Weekday frequency against week number for %s\"%title, text_font_size = \"16pt\", text_font_style=\"bold\"), place = 'above')\n",
    "        p.add_layout(Title(text=\"Date range: %s - %s\"%(hv[key]['date'].min().strftime('%Y, %b %d'),hv[key]['date'].max().strftime('%Y, %b %d'))), 'above')\n",
    "        p.add_layout(Title(text=\"Total {} generated: {:,} | Total days: {:,} (excluding {:,} days of server downtime)\"\n",
    "                           .format(service, df['count'].sum(), len(df_na.dropna()), server_downtime_days), text_font_style=\"italic\"), 'above')\n",
    "        \n",
    "        p_service = p.rect(x=\"weeknumber\", y=\"weekday\", width=1, height=1,\n",
    "                           source=df_service,\n",
    "                           fill_color='red', fill_alpha=0.5, hover_fill_alpha=0.2, line_color=None)\n",
    "        p.add_tools(HoverTool(renderers = [p_service], \n",
    "                              tooltips=[('Week Number', '@weeknumber'), \n",
    "                                        ('Shutdown', '@reason'), \n",
    "                                        ('Date','@date{%F}')],\n",
    "                              formatters={'@date': 'datetime'}))\n",
    "\n",
    "#         num_ticks=10\n",
    "#         if (len(df[df['count']>0]['count'].unique()) <= 10):\n",
    "#             num_ticks = len(df[df['count']>0]['count'].unique())\n",
    "        color_bar = ColorBar(color_mapper = mapper(palette=colors, low=0.1, high=np.nanmax(df['count'])), \n",
    "                             major_label_text_font_size=\"10px\",\n",
    "                             ticker=ticker(desired_num_ticks=num_ticks),\n",
    "                             formatter=NumeralTickFormatter(format=\"0,0\"),\n",
    "                             label_standoff=6, border_line_color=None, location=(0, 0))\n",
    "        p.add_layout(color_bar, 'right')\n",
    "        p.border_fill_color = \"whitesmoke\"\n",
    "    #             p.width_policy = 'fit'\n",
    "    #             p.height_policy = 'fit'\n",
    "        panel = Panel(child=p, title=mapper_type)\n",
    "        panels.append(panel)\n",
    "    tabs = Tabs(tabs=panels)\n",
    "#     show(tabs)\n",
    "#     break\n",
    "    save(tabs, filename='./%s/weeknumber_frequency.html'%key, title='Weekday frequency against weeknumber for %s'%title)\n",
    "print(\"Weekday frequency against weeknumber distribution done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weekly weekday distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making weekly weekday distribution of movies generated per day...\n",
      "Weekly weekday distribution done.\n"
     ]
    }
   ],
   "source": [
    "print(\"Making weekly weekday distribution of movies generated per day...\")\n",
    "TOOLS = \"save, pan, box_zoom, reset, wheel_zoom\"\n",
    "for key, title, service in zip(hv.keys(), titles, services):\n",
    "    \n",
    "    directory = key\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        \n",
    "    df = hv[key].copy()\n",
    "    df = df.set_index('date')\n",
    "    df = df.reindex(pd.date_range(df.index.min(), df.index.max(), freq='D').to_period('D').to_timestamp(),\n",
    "                                  fill_value=0)\n",
    "    df['date'] = df.index\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    df_0 = df.loc[df['count']==0].reset_index(drop=True)\n",
    "    \n",
    "    df.loc[(df['date'] >= pd.Timestamp('2011/08/11')) & (df['date'] <= pd.Timestamp('2011/09/18')), 'count'] = np.nan\n",
    "    df.loc[(df['date'] >= pd.Timestamp('2013/10/01')) & (df['date'] <= pd.Timestamp('2013/10/16')), 'count'] = np.nan\n",
    "    df.loc[(df['date'] >= pd.Timestamp('2015/02/04')) & (df['date'] <= pd.Timestamp('2015/09/23')), 'count'] = np.nan\n",
    "    \n",
    "#     df = df.dropna()\n",
    "    \n",
    "    df['weekday'] = df['date'].dt.weekday_name\n",
    "    df['weeknumber'] = ((df['date']-df['date'][0]).dt.days/7).astype(int)\n",
    "    \n",
    "    df_0['weekday'] = df_0['date'].dt.weekday_name\n",
    "    df_0['weeknumber'] = ((df_0['date']-df_0['date'][0]).dt.days/7).astype(int)\n",
    "    \n",
    "    df_service['weeknumber'] = ((df_service['date']-df['date'][0]).dt.days/7).astype(int)\n",
    "    # df = df.groupby(['weeknumber','weekday']).sum().reset_index()\n",
    "    weeknumber = np.array(df['weeknumber'].unique())# hv_cov.index.values#.astype(str)\n",
    "   \n",
    "    color = {weekdays[i]:bp.Spectral7[i] for i in range(len(weekdays))}\n",
    "    p_wd=[]\n",
    "    panels=[]\n",
    "    for wd in weekdays:\n",
    "        df_wd = df.loc[df['weekday']==wd]\n",
    "        df_0_wd = df_0.loc[df_0['weekday']==wd]\n",
    "        p = figure(plot_height=250, x_axis_type=\"datetime\", \n",
    "                   tools=TOOLS,\n",
    "                   sizing_mode=\"scale_width\", min_border_left = 0,\n",
    "                   x_axis_label=\"Date\", \n",
    "                   y_axis_label=\"No. of %s\"%service)\n",
    "        \n",
    "        p.background_fill_color=\"#f5f5f5\"\n",
    "        p.grid.grid_line_color=\"white\"\n",
    "    \n",
    "        server_downtime_days = len(df_wd)-len(df_wd.dropna())\n",
    "        \n",
    "        p.add_layout(Title(text = \"Weekly coverage of %s for %s\"%(title, wd), text_font_size = \"16pt\", text_font_style=\"bold\"), place = 'above')\n",
    "        p.add_layout(Title(text=\"Date range: %s - %s\"%(hv[key]['date'].min().strftime('%Y, %b %d'),hv[key]['date'].max().strftime('%Y, %b %d'))), 'above')\n",
    "        p.add_layout(Title(text=\"Total {} generated on {}: {:,} | Total {}s: {:,} (excluding {:,} {}s of server downtime)\"\n",
    "                           .format(service, wd, df_wd['count'].sum(), wd, len(df_wd.dropna()), server_downtime_days, wd), text_font_style=\"italic\"), 'above')\n",
    "        \n",
    "        p_0 = p.circle(x='date', y='count', size=2, color='red', source = df_0_wd, legend_label='Zero %s'%service)\n",
    "        \n",
    "        \n",
    "        p.title.text_font_size = '16pt'\n",
    "        \n",
    "        p.x_range.start = df_wd['date'].min() - (df_wd['date'].max()-df_wd['date'].min())*0.02\n",
    "        p.x_range.end = df_wd['date'].max() + (df_wd['date'].max()-df_wd['date'].min())*0.02\n",
    "\n",
    "#         p.x_range.range_padding = 0.02\n",
    "        p.y_range.range_padding = 0.05       \n",
    "        \n",
    "        service_pause(p, df_wd)\n",
    "        major_features(p, df_wd)\n",
    "        \n",
    "        p.line(x='date', y='count', source=df_wd, legend_label=\"#%s on %s\"%(service, wd), color='#ebbd5b')\n",
    "        \n",
    "        p.add_tools(HoverTool(tooltips=[('Week Number', '@weeknumber'), \n",
    "                                        ('Date','@date{%F}'),\n",
    "                                        ('#%s'%service,'@count')],\n",
    "                              formatters={'@date': 'datetime'},\n",
    "                              mode='vline'))\n",
    "        p.legend.background_fill_alpha = 0.3\n",
    "        p.border_fill_color = \"whitesmoke\"\n",
    "        \n",
    "        panel=Panel(child = p, title=wd)\n",
    "        panels.append(panel)\n",
    "    tabs=Tabs(tabs=panels)\n",
    "#     grid = gridplot(list(np.array([p_wd]).T), sizing_mode=\"scale_width\")\n",
    "#     show(tabs)\n",
    "#     break\n",
    "    save(tabs, filename='%s/weekly_weekday.html'%key, title='Weekly coverage of %s per weekday'%(title))\n",
    "print(\"Weekly weekday distribution done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Stats for movies per day done. ###\n"
     ]
    }
   ],
   "source": [
    "print(\"### Stats for movies per day done. ###\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Popularity plots ###\n"
     ]
    }
   ],
   "source": [
    "print(\"### Popularity plots ###\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Popularity of solar time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def obs_popularity(database, df_obs):\n",
    "    hv={}\n",
    "    obs = df_obs['OBS']\n",
    "    \n",
    "    sid = df_obs['SOURCE_ID']\n",
    "    if(sql_query(\"SELECT count(*) from data WHERE sourceId=%d\"%(sid)).values==0):\n",
    "        return pd.DataFrame(columns=['date','count']), 0\n",
    "    \n",
    "    if(database=='movies'):\n",
    "        query = \"SELECT startDate, endDate FROM movies WHERE dataSourceString LIKE '%{}%' OR dataSourceString='[{}]';\".format(obs.replace(' ','%'), sid)\n",
    "        hv = sql_query(query)\n",
    "    if(database=='movies_jpx'):\n",
    "        query = \"SELECT reqstartDate as startDate, reqEndDate as endDate FROM movies_jpx WHERE sourceId={};\".format(df_obs['SOURCE_ID'])\n",
    "        hv = sql_query(query)\n",
    "        \n",
    "    hv = hv.dropna().reset_index(drop=True)\n",
    "    \n",
    "    first_obs, last_obs = sql_query(\"SELECT min(date) as min_date, max(date) as max_date from data WHERE sourceId=%d\"%sid).iloc[0]\n",
    "    \n",
    "    hv = hv.loc[((hv['startDate'] >= first_obs) & (hv['startDate'] <= last_obs)) & ((hv['endDate'] >=first_obs) & (hv['endDate'] <= last_obs))]\n",
    "    \n",
    "    if(hv.empty):\n",
    "        return hv, len(hv)\n",
    "#         df = pd.DataFrame({'date': pd.date_range(first_obs, last_obs, freq='M')})\n",
    "#         df['count'] = 0\n",
    "#         return df, len(hv)\n",
    "\n",
    "    hv = hv.sort_values('startDate').reset_index(drop=True).dropna()\n",
    "    hv['startDate'] = hv['startDate'].dt.to_period('H').dt.to_timestamp()\n",
    "    hv['endDate'] = hv['endDate'].dt.to_period('H').dt.to_timestamp()\n",
    "\n",
    "#     df = pd.DataFrame({'date' : pd.date_range(hv['startDate'].min(), hv['endDate'].max(), freq='H').to_period('H').to_timestamp()})\n",
    "#     df['count'] = np.zeros(len(df), dtype=int)\n",
    "#     for ind, h in hv.iterrows():\n",
    "#         df.loc[(df['date']>=h['startDate']) & (df['date']<=h['endDate']), 'count']+=1\n",
    "\n",
    "    df = (pd.concat([pd.Series(pd.date_range(r.startDate, r.endDate, freq='H')) for r in hv.itertuples()]).to_frame('date'))\n",
    "    df = df.groupby('date').size().to_frame('count')\n",
    "    df = df.reindex(pd.date_range(df.index.min(), df.index.max(), freq='H'), fill_value=0).rename_axis('date').reset_index()\n",
    "\n",
    "    if len(df)==1:\n",
    "#         return pd.DataFrame(), len(hv)\n",
    "        df = df.set_index('date')\n",
    "        df = df.reindex(pd.date_range(df.index.min()-pd.Timedelta(hours=2), df.index.max() + pd.Timedelta(hours=2), freq='H').to_period('H').to_timestamp(),\n",
    "                                      fill_value=0)\n",
    "        df['date'] = df.index\n",
    "        df = df.reset_index(drop=True)\n",
    "    return df, len(hv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def popularity_plot(df_obs, df, size, service):\n",
    "    \n",
    "    key='movies'\n",
    "    name = df_obs['OBS']\n",
    "    name_ = name.replace(\" \",\"_\")\n",
    "    \n",
    "    df_0 = df.loc[df['count']==0].reset_index(drop=True)\n",
    "\n",
    "#     df.loc[(df['date'] >= pd.Timestamp('2011/08/11')) & (df['date'] <= pd.Timestamp('2011/09/18')), 'count'] = np.nan\n",
    "#     df.loc[(df['date'] >= pd.Timestamp('2013/10/01')) & (df['date'] <= pd.Timestamp('2013/10/16')), 'count'] = np.nan\n",
    "#     df.loc[(df['date'] >= pd.Timestamp('2015/02/04')) & (df['date'] <= pd.Timestamp('2015/09/23')), 'count'] = np.nan\n",
    "    \n",
    "    TOOLS = \"save, pan, box_zoom, reset, wheel_zoom\"\n",
    "\n",
    "    p = figure(plot_height=250, x_axis_type=\"datetime\", \n",
    "               tools=TOOLS, output_backend='webgl',\n",
    "               sizing_mode=\"scale_width\", min_border_left = 0)\n",
    "\n",
    "    p.add_layout(Title(text = \"Popularity of %s data in %s %s\"%(name, service, key), text_font_size = \"16pt\", text_font_style=\"bold\"), \n",
    "                 place = 'above')\n",
    "    p.add_layout(Title(text = \"Date Range: %s - %s\"%(df['date'].min().strftime('%Y, %b %d'),df['date'].max().strftime('%Y, %b %d'))), \n",
    "                 place ='above')\n",
    "    p.add_layout(Title(text=\"Total (solar hour) occurrences in {}: {:,} | Total hours of data observed: {:,} | Total number of movies generated: {:,} \"\n",
    "                       .format(key,df['count'].sum(), len(df.loc[df['count']!=0]), size), text_font_style=\"italic\"), \n",
    "                 place = 'above')\n",
    "\n",
    "    p.background_fill_color=\"#f5f5f5\"\n",
    "    p.grid.grid_line_color=\"white\"\n",
    "    p.xaxis.axis_label = 'Date (hourly)'\n",
    "    p.yaxis.axis_label = 'Occurences in %s'%key\n",
    "    p.axis.axis_line_color = None\n",
    "    p.x_range.range_padding = 0.02\n",
    "    p.x_range.range_padding = 0.02\n",
    "    p.y_range.range_padding = 0.02\n",
    "    \n",
    "    p.yaxis.formatter = NumeralTickFormatter(format='0,0')\n",
    "#     p.xaxis.formatter = DatetimeTickFormatter(minutes=[\"%d %b %Y\"],\n",
    "#                                               hours=[\"%d %b %Y\"],\n",
    "#                                               days=[\"%d %b %Y\"],\n",
    "#                                               months=[\"%d %b %Y\"],\n",
    "#                                               years=[\"%d %b %Y\"])\n",
    "#     p.xaxis.formatter = DatetimeTickFormatter()\n",
    "#     p.xaxis.ticker = YearsTicker(desired_num_ticks=10, num_minor_ticks=12)\n",
    "    major_features(p, df)\n",
    "    service_pause(p, df)\n",
    "\n",
    "    p_line = p.line(x='date', line_width=2, y='count', color='#ebbd5b', source=df, legend_label=\"Data Popularity\")\n",
    "    p_0 = p.circle(x='date', y='count', size=2, color='red', source = df_0, legend_label='Zero movie occurences')\n",
    "\n",
    "    p.add_tools(HoverTool(renderers=[p_line],\n",
    "                          tooltips=[('date', '@date{%F %T}'),\n",
    "                                    #( 'close',  '$@{adj close}{%0.2f}' ), # use @{ } for field names with spaces\n",
    "                                    ('#occurences in movies', '@count'),#{0.00 a}'      ),\n",
    "                                   ],\n",
    "                          formatters={'@date' : 'datetime', # use 'datetime' formatter for 'date' field\n",
    "#                                           'count' : 'int',   # use 'printf' formatter for 'adj close' field\n",
    "#                                           use default 'numeral' formatter for other fields\n",
    "                                     },\n",
    "#                           mode='vline'\n",
    "                         ))\n",
    "    df_stats = pd.DataFrame({'height': pd.date_range(df['date'].min(),df['date'].max(),periods=2),\n",
    "                             'mean':np.nanmean(df['count']), 'median': np.nanmedian(df['count']), 'mode':stats.mode(df['count'])[0][0]})\n",
    "    \n",
    "    p.line(y='mean', x='height', line_color = \"blue\", line_dash='dotted', line_width= 1, alpha=0.5, legend_label=\"Mean (%.2f)\"%(df_stats['mean'][0]), source=df_stats)\n",
    "    p.line(y='median', x='height', line_color = \"black\", line_dash='dashed', line_width=1, alpha=0.5, legend_label=\"Median (%.2f)\"%(df_stats['median'][0]), source=df_stats)\n",
    "    \n",
    "    p.x_range.start = df['date'].min() - (df['date'].max()-df['date'].min())*0.02\n",
    "    p.x_range.end = df['date'].max() + (df['date'].max()-df['date'].min())*0.02\n",
    "    \n",
    "#     p.x_range.range_padding = 0.02\n",
    "    p.y_range.range_padding = 0.05\n",
    "    p.legend.background_fill_alpha = 0.3\n",
    "    p.legend.location='top_right'\n",
    "    p.border_fill_color = \"whitesmoke\"\n",
    "    \n",
    "    panel = Panel(child=p, title=name.replace(name.split(\" \")[0]+' ', ''))\n",
    "    return panel\n",
    "#     show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solar popularity in Helioviewer movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making solar time popularity plots for helioviewer.org movies...\n",
      "SDO popularity done in 212 seconds\n",
      "SOHO popularity done in 41 seconds\n",
      "STEREO_A popularity done in 15 seconds\n",
      "STEREO_B popularity done in 8 seconds\n",
      "<=1 movies prepared with TRACE 284\n",
      "<=1 movies prepared with TRACE 1550\n",
      "<=1 movies prepared with TRACE 1600\n",
      "<=1 movies prepared with TRACE 1700\n",
      "TRACE popularity done in 4 seconds\n",
      "Yohkoh popularity done in 3 seconds\n",
      "<=1 movies prepared with Hinode XRT Al_med Be_thick\n",
      "<=1 movies prepared with Hinode XRT Al_med Ti_poly\n",
      "<=1 movies prepared with Hinode XRT C_poly Al_mesh\n",
      "<=1 movies prepared with Hinode XRT C_poly Al_thick\n",
      "<=1 movies prepared with Hinode XRT Any Any\n",
      "<=1 movies prepared with Hinode XRT Any Al_mesh\n",
      "<=1 movies prepared with Hinode XRT Any Al_thick\n",
      "<=1 movies prepared with Hinode XRT Any Be_thick\n",
      "<=1 movies prepared with Hinode XRT Any Gband\n",
      "<=1 movies prepared with Hinode XRT Any Open\n",
      "<=1 movies prepared with Hinode XRT Any Ti_poly\n",
      "<=1 movies prepared with Hinode XRT Al_med Any\n",
      "<=1 movies prepared with Hinode XRT Al_poly Any\n",
      "<=1 movies prepared with Hinode XRT Be_med Any\n",
      "<=1 movies prepared with Hinode XRT Be_thin Any\n",
      "<=1 movies prepared with Hinode XRT C_poly Any\n",
      "<=1 movies prepared with Hinode XRT Open Any\n",
      "Hinode popularity done in 10 seconds\n",
      "MLSO popularity done in 1 seconds\n",
      "PROBA2 popularity done in 7 seconds\n",
      "Popularity plot done.\n"
     ]
    }
   ],
   "source": [
    "par = Parallel(n_jobs=20)\n",
    "directory=\"hv_movies\"\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "if not os.path.exists(\"./%s/popularity\"%directory):\n",
    "    os.makedirs(\"./%s/popularity\"%directory)\n",
    "\n",
    "\n",
    "print(\"Making solar time popularity plots for helioviewer.org movies...\")\n",
    "for observatory in hv_keys.keys():\n",
    "    start_time=time.time()\n",
    "    h = hv_sid.loc[hv_sid['OBS'].str.match(observatory)].iloc[:].reset_index(drop=True)\n",
    "    popularity = par(delayed(obs_popularity)('movies', df_obs) for ind, df_obs in h.iterrows())\n",
    "    panels=[]\n",
    "    tabs=[]\n",
    "    for ind, df_obs in h.iterrows():\n",
    "        if(popularity[ind][0].empty):\n",
    "            print(\"<=1 movies prepared with %s\"%(df_obs['OBS']))\n",
    "            continue\n",
    "        panels.append(popularity_plot(df_obs, popularity[ind][0], popularity[ind][1], 'Helioviewer.org'))\n",
    "        tabs = Tabs(tabs=panels)\n",
    "#     show(tabs)\n",
    "    save(tabs, filename='./%s/popularity/%s_popularity.html'%(directory, observatory), title='Data Popularity of %s in Helioviewer.org movies'%(observatory))\n",
    "    print(\"%s popularity done in %d seconds\"%(observatory, time.time()-start_time))\n",
    "print(\"Popularity plot done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solar popularity in JHelioviewer movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making solar time popularity plots for Jhelioviewer movies...\n",
      "SDO popularity done in 117 seconds\n",
      "SOHO popularity done in 236 seconds\n",
      "STEREO_A popularity done in 45 seconds\n",
      "STEREO_B popularity done in 12 seconds\n",
      "<=1 movies prepared with TRACE 1550\n",
      "<=1 movies prepared with TRACE 1700\n",
      "TRACE popularity done in 3 seconds\n",
      "Yohkoh popularity done in 2 seconds\n",
      "<=1 movies prepared with Hinode XRT Al_med Be_thick\n",
      "<=1 movies prepared with Hinode XRT Al_med Ti_poly\n",
      "<=1 movies prepared with Hinode XRT Al_poly Al_mesh\n",
      "<=1 movies prepared with Hinode XRT C_poly Al_mesh\n",
      "<=1 movies prepared with Hinode XRT Any Any\n",
      "<=1 movies prepared with Hinode XRT Any Al_mesh\n",
      "<=1 movies prepared with Hinode XRT Any Al_thick\n",
      "<=1 movies prepared with Hinode XRT Any Be_thick\n",
      "<=1 movies prepared with Hinode XRT Any Gband\n",
      "<=1 movies prepared with Hinode XRT Any Open\n",
      "<=1 movies prepared with Hinode XRT Any Ti_poly\n",
      "<=1 movies prepared with Hinode XRT Al_med Any\n",
      "<=1 movies prepared with Hinode XRT Al_poly Any\n",
      "<=1 movies prepared with Hinode XRT Be_med Any\n",
      "<=1 movies prepared with Hinode XRT Be_thin Any\n",
      "<=1 movies prepared with Hinode XRT C_poly Any\n",
      "<=1 movies prepared with Hinode XRT Open Any\n",
      "Hinode popularity done in 9 seconds\n",
      "MLSO popularity done in 0 seconds\n",
      "PROBA2 popularity done in 2 seconds\n",
      "Popularity plot done.\n"
     ]
    }
   ],
   "source": [
    "par = Parallel(n_jobs=20)\n",
    "directory=\"Jhv_movies\"\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "if not os.path.exists(\"./%s/popularity\"%directory):\n",
    "    os.makedirs(\"./%s/popularity\"%directory)\n",
    "\n",
    "print(\"Making solar time popularity plots for Jhelioviewer movies...\")\n",
    "for observatory in hv_keys.keys():\n",
    "    start_time=time.time()\n",
    "    h = hv_sid.loc[hv_sid['OBS'].str.match(observatory)].iloc[:].reset_index(drop=True)\n",
    "    popularity = par(delayed(obs_popularity)('movies_jpx', df_obs) for ind, df_obs in h.iterrows())\n",
    "    panels=[]\n",
    "    tabs=[]\n",
    "    for ind, df_obs in h.iterrows():\n",
    "        if(popularity[ind][0].empty):\n",
    "            print(\"<=1 movies prepared with %s\"%(df_obs['OBS']))\n",
    "            continue\n",
    "        panels.append(popularity_plot(df_obs, popularity[ind][0], popularity[ind][1], 'JHelioviewer'))\n",
    "        tabs = Tabs(tabs=panels)\n",
    "#     show(tabs)\n",
    "    save(tabs, filename='./%s/popularity/%s_popularity.html'%(directory, observatory), title='Data Popularity of %s in JHelioviewer movies'%(observatory))\n",
    "    print(\"%s popularity done in %d seconds\"%(observatory, time.time()-start_time))\n",
    "print(\"Popularity plot done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Popularity of THE data in helioviewer.org movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obs_popularity(database, df_obs):\n",
    "    hv={}\n",
    "    obs = df_obs['OBS']\n",
    "    sid = df_obs['SOURCE_ID']\n",
    "    if(sql_query(\"SELECT count(*) from data WHERE sourceId=%d\"%(sid)).values==0):\n",
    "        return pd.DataFrame(columns=['date','count']), 0\n",
    "    \n",
    "    if(database=='movies'):\n",
    "        query = \"SELECT startDate, endDate FROM movies WHERE dataSourceString LIKE '%{}%' OR dataSourceString='[{}]';\".format(obs.replace(' ','%'), sid)\n",
    "        hv = sql_query(query)\n",
    "    if(database=='movies_jpx'):\n",
    "        query = \"SELECT reqstartDate as startDate, reqEndDate as endDate FROM movies_jpx WHERE sourceId={};\".format(df_obs['SOURCE_ID'])\n",
    "        hv = sql_query(query)\n",
    "\n",
    "    hv = hv.dropna().reset_index(drop=True)\n",
    "\n",
    "    first_obs, last_obs = sql_query(\"SELECT min(date) AS min_date, max(date) AS max_date FROM data WHERE sourceId=%d\"%sid).iloc[0]\n",
    "    hv = hv.loc[((hv['startDate'] >= first_obs) & (hv['startDate'] <= last_obs)) & ((hv['endDate'] >=first_obs) & (hv['endDate'] <= last_obs))]\n",
    "    hv = hv.sort_values(['startDate', 'endDate']).reset_index(drop=True).dropna()\n",
    "\n",
    "    if(hv.empty):\n",
    "        return hv, len(hv)\n",
    "    hv['duration'] = (hv['endDate']-hv['startDate']).dt.total_seconds()\n",
    "    hv['frames'] = (hv['duration']/36).astype(int)\n",
    "    hv.loc[hv['frames']>300, 'frames'] = 300\n",
    "    df = (pd.concat([pd.Series(pd.date_range(r.startDate, r.endDate, periods=r.frames+1)) for r in hv.iloc[:].itertuples()]).to_frame('date'))\n",
    "    df = df['date'].dt.to_period('H').dt.to_timestamp().to_frame('date')\n",
    "    df = df.groupby('date').size().to_frame('count')\n",
    "    df = df.reindex(pd.date_range(df.index.min(), df.index.max(), freq='H'), fill_value=0).rename_axis('date').reset_index()\n",
    "#     return df\n",
    "    if len(df)==1:\n",
    "#         return pd.DataFrame(), len(hv)\n",
    "        df = df.set_index('date')\n",
    "        df = df.reindex(pd.date_range(df.index.min()-pd.Timedelta(hours=2), df.index.max() + pd.Timedelta(hours=2), freq='H').to_period('H').to_timestamp(),\n",
    "                                      fill_value=0)\n",
    "        df['date'] = df.index\n",
    "        df = df.reset_index(drop=True)\n",
    "    return df, len(hv) #len(hv) is the actual number of movies created since df will also have a lot of zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def popularity_plot(df_obs, df, size, service):\n",
    "    \n",
    "    key='movies'\n",
    "    name = df_obs['OBS']\n",
    "    name_ = name.replace(\" \",\"_\")\n",
    "    \n",
    "    df_0 = df.loc[df['count']==0].reset_index(drop=True)\n",
    "\n",
    "#     df.loc[(df['date'] >= pd.Timestamp('2011/08/11')) & (df['date'] <= pd.Timestamp('2011/09/18')), 'count'] = np.nan\n",
    "#     df.loc[(df['date'] >= pd.Timestamp('2013/10/01')) & (df['date'] <= pd.Timestamp('2013/10/16')), 'count'] = np.nan\n",
    "#     df.loc[(df['date'] >= pd.Timestamp('2015/02/04')) & (df['date'] <= pd.Timestamp('2015/09/23')), 'count'] = np.nan\n",
    "    \n",
    "    TOOLS = \"save, pan, box_zoom, reset, wheel_zoom\"\n",
    "\n",
    "    p = figure(plot_height=250, x_axis_type=\"datetime\", \n",
    "               tools=TOOLS, output_backend='webgl',\n",
    "               sizing_mode=\"scale_width\", min_border_left = 0)\n",
    "\n",
    "    p.add_layout(Title(text = \"Popularity of %s data in %s %s\"%(name, service, key), text_font_size = \"16pt\", text_font_style=\"bold\"), \n",
    "                 place = 'above')\n",
    "    p.add_layout(Title(text = \"Date Range: %s - %s\"%(df['date'].min().strftime('%Y, %b %d'),df['date'].max().strftime('%Y, %b %d'))), \n",
    "                 place ='above')\n",
    "    p.add_layout(Title(text=\"Total frames used in all {}: {:,} | Total hours of data observed: {:,} | Total number of movies generated: {:,} \"\n",
    "                       .format(key,df['count'].sum(), len(df.loc[df['count']!=0]), size), text_font_style=\"italic\"), \n",
    "                 place = 'above')\n",
    "\n",
    "    p.background_fill_color=\"#f5f5f5\"\n",
    "    p.grid.grid_line_color=\"white\"\n",
    "    p.xaxis.axis_label = 'Date (hourly)'\n",
    "    p.yaxis.axis_label = 'No. of frames used in %s per hour'%key\n",
    "    p.axis.axis_line_color = None\n",
    "    p.x_range.range_padding = 0.02\n",
    "    p.x_range.range_padding = 0.02\n",
    "    p.y_range.range_padding = 0.02\n",
    "    \n",
    "    p.yaxis.formatter = NumeralTickFormatter(format='0,0')\n",
    "#     p.xaxis.formatter = DatetimeTickFormatter(minutes=[\"%d %b %Y\"],\n",
    "#                                               hours=[\"%d %b %Y\"],\n",
    "#                                               days=[\"%d %b %Y\"],\n",
    "#                                               months=[\"%d %b %Y\"],\n",
    "#                                               years=[\"%d %b %Y\"])\n",
    "#     p.xaxis.formatter = DatetimeTickFormatter()\n",
    "#     p.xaxis.ticker = YearsTicker(desired_num_ticks=10, num_minor_ticks=12)\n",
    "    major_features(p, df)\n",
    "    service_pause(p, df)\n",
    "\n",
    "    p_line = p.line(x='date', line_width=2, y='count', color='#ebbd5b', source=df, legend_label=\"Data Popularity\")\n",
    "    p_0 = p.circle(x='date', y='count', size=2, color='red', source = df_0, legend_label='Zero movie occurences')\n",
    "\n",
    "    p.add_tools(HoverTool(renderers=[p_line],\n",
    "                          tooltips=[('date', '@date{%F %T}'),\n",
    "                                    #( 'close',  '$@{adj close}{%0.2f}' ), # use @{ } for field names with spaces\n",
    "                                    ('#occurences in movies', '@count'),#{0.00 a}'      ),\n",
    "                                   ],\n",
    "                          formatters={'@date' : 'datetime', # use 'datetime' formatter for 'date' field\n",
    "#                                           'count' : 'int',   # use 'printf' formatter for 'adj close' field\n",
    "#                                           use default 'numeral' formatter for other fields\n",
    "                                     },\n",
    "#                           mode='vline'\n",
    "                         ))\n",
    "    df_stats = pd.DataFrame({'height': pd.date_range(df['date'].min(),df['date'].max(),periods=2),\n",
    "                             'mean':np.nanmean(df['count']), 'median': np.nanmedian(df['count']), 'mode':stats.mode(df['count'])[0][0]})\n",
    "    \n",
    "    p.line(y='mean', x='height', line_color = \"blue\", line_dash='dotted', line_width= 1, alpha=0.5, legend_label=\"Mean (%.2f)\"%(df_stats['mean'][0]), source=df_stats)\n",
    "    p.line(y='median', x='height', line_color = \"black\", line_dash='dashed', line_width=1, alpha=0.5, legend_label=\"Median (%.2f)\"%(df_stats['median'][0]), source=df_stats)\n",
    "    \n",
    "    p.x_range.start = df['date'].min() - (df['date'].max()-df['date'].min())*0.02\n",
    "    p.x_range.end = df['date'].max() + (df['date'].max()-df['date'].min())*0.02\n",
    "    \n",
    "#     p.x_range.range_padding = 0.02\n",
    "    p.y_range.range_padding = 0.05\n",
    "    p.legend.background_fill_alpha = 0.3\n",
    "    p.legend.location='top_right'\n",
    "    p.border_fill_color = \"whitesmoke\"\n",
    "    \n",
    "    panel = Panel(child=p, title=name.replace(name.split(\" \")[0]+' ', ''))\n",
    "    return panel\n",
    "#     show(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data popularity in Helioviewer.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making data popularity plots for helioviewer movies...\n",
      "SDO popularity done in 281 seconds\n",
      "SOHO popularity done in 0 seconds\n",
      "STEREO_A popularity done in 0 seconds\n",
      "STEREO_B popularity done in 0 seconds\n",
      "TRACE popularity done in 0 seconds\n",
      "Yohkoh popularity done in 0 seconds\n",
      "Hinode popularity done in 0 seconds\n",
      "MLSO popularity done in 0 seconds\n",
      "PROBA2 popularity done in 0 seconds\n",
      "Popularity plot done.\n"
     ]
    }
   ],
   "source": [
    "directory=\"hv_movies\"\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "if not os.path.exists(\"./%s/popularity_data\"%directory):\n",
    "    os.makedirs(\"./%s/popularity_data\"%directory)\n",
    "    \n",
    "print(\"Making data popularity plots for helioviewer movies...\")\n",
    "\n",
    "for observatory in hv_keys.keys():\n",
    "    start_time=time.time()\n",
    "    h = hv_sid.loc[hv_sid['OBS'].str.match(\"%s AIA\"%observatory)].iloc[:].reset_index(drop=True)\n",
    "#     popularity = par(delayed(obs_popularity)('movies', df_obs) for ind, df_obs in h.iterrows())\n",
    "    panels=[]\n",
    "    for ind, df_obs in h.iterrows():\n",
    "        popularity = obs_popularity(database='movies', df_obs=df_obs)\n",
    "        if(popularity[0].empty):\n",
    "            print(\"<=1 movies prepared with %s\"%(df_obs['OBS']))\n",
    "            continue\n",
    "        panel = popularity_plot(df_obs, popularity[0], popularity[1], 'Helioviewer.org')\n",
    "        panels.append(panel)\n",
    "    tabs = Tabs(tabs=panels)\n",
    "#     show(tabs)\n",
    "    save(tabs, filename='./%s/popularity_data/%s_popularity.html'%(directory, observatory), title='Data Popularity of %s in Helioviewer.org movies'%(observatory))\n",
    "    print(\"%s popularity done in %d seconds\"%(observatory, time.time()-start_time))\n",
    "    break\n",
    "print(\"Popularity plot done.\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data popularity in Jhelioviewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# directory=\"Jhv_movies\"\n",
    "# if not os.path.exists(directory):\n",
    "#     os.makedirs(directory)\n",
    "# if not os.path.exists(\"./%s/popularity_data\"%directory):\n",
    "#     os.makedirs(\"./%s/popularity_data\"%directory)\n",
    "    \n",
    "# print(\"Making data popularity plots for Jhelioviewer movies...\")\n",
    "\n",
    "# for observatory in hv_keys.keys():\n",
    "#     start_time=time.time()\n",
    "#     h = hv_sid.loc[hv_sid['OBS'].str.match(\"%s AIA\"%observatory)].iloc[:].reset_index(drop=True)\n",
    "# #     popularity = par(delayed(obs_popularity)('movies', df_obs) for ind, df_obs in h.iterrows())\n",
    "#     panels=[]\n",
    "#     for ind, df_obs in h.iterrows():\n",
    "#         popularity = obs_popularity(database='movies_jpx', df_obs=df_obs)\n",
    "#         if(popularity[0].empty):\n",
    "#             print(\"<=1 movies prepared with %s\"%(df_obs['OBS']))\n",
    "#             continue\n",
    "#         panel = popularity_plot(df_obs, popularity[0], popularity[1], 'JHelioviewer')\n",
    "#         panels.append(panel)\n",
    "#     tabs = Tabs(tabs=panels)\n",
    "# #     show(tabs)\n",
    "#     save(tabs, filename='./%s/popularity_data/%s_popularity.html'%(directory, observatory), title='Data Popularity of %s in JHelioviewer movies'%(observatory))\n",
    "#     print(\"%s popularity done in %d seconds\"%(observatory, time.time()-start_time))\n",
    "#     break\n",
    "# print(\"Popularity plot done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ALL popularity plots done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Service Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Service comparison...\n"
     ]
    }
   ],
   "source": [
    "print(\"Service comparison...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting SQL query in movies and statistics table of hv database...\n",
      "Query completed in 65 seconds.\n"
     ]
    }
   ],
   "source": [
    "start_time=time.time()\n",
    "hv={}\n",
    "print(\"Starting SQL query in movies and statistics table of hv database...\")\n",
    "\n",
    "query = \"SELECT date_format(timestamp, '%Y-%m-%d 00:00:00') as date, count(*) as count FROM {} GROUP BY date_format(timestamp, '%Y-%m-%d 00:00:00');\"\n",
    "hv['hv_movies'] = sql_query(query.format('movies'))\n",
    "\n",
    "hv['embed'] = sql_query(query.format(\"statistics WHERE action=\\'embed\\'\"))\n",
    "\n",
    "hv['Jhv_movies'] = sql_query(query.format(\"statistics WHERE action=\\'getJPX\\'\"))\n",
    "\n",
    "for key in hv.keys():\n",
    "    hv[key]['date'] = pd.to_datetime(hv[key]['date'])\n",
    "\n",
    "print(\"Query completed in %d seconds.\"%(time.time()-start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_em = pd.read_csv('embed.csv')\n",
    "df_em['timestamp'] = pd.to_datetime(df_em['timestamp'])\n",
    "df_em = pd.DataFrame(df_em.groupby(by=df_em['timestamp'].dt.date).count()['id'])\n",
    "hv['embed'].index = hv['embed']['date']\n",
    "hv['embed'] = df_em.join(hv['embed'], how='outer')\n",
    "hv['embed'] = pd.DataFrame(hv['embed'][['id','count']].max(axis=1), columns=['count'])\n",
    "\n",
    "hv['embed']['date'] = hv['embed'].index\n",
    "hv['embed'] = hv['embed'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_start = min(hv['hv_movies']['date'].min(), hv['embed']['date'].min(), hv['Jhv_movies']['date'].min())\n",
    "date_end = max(hv['hv_movies']['date'].max(), hv['embed']['date'].max(), hv['Jhv_movies']['date'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hv_movies\n",
      "embed\n",
      "Jhv_movies\n"
     ]
    }
   ],
   "source": [
    "for key in hv.keys():\n",
    "    print(key)\n",
    "    df = hv[key].copy()\n",
    "    df = df.set_index('date')\n",
    "    df = df.reindex(pd.date_range(date_start, date_end, freq='D').to_period('D').to_timestamp(),\n",
    "                                  fill_value=0)\n",
    "    df['date'] = df.index\n",
    "    df = df.reset_index(drop=True)\n",
    "    hv[key] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in hv.keys():\n",
    "    hv[key].loc[(hv['Jhv_movies']['count']==0) & (hv['embed']['count']==0) & (hv['hv_movies']['count']==0), 'bottom_frac'] = np.nan\n",
    "    hv[key].loc[(hv['Jhv_movies']['count']==0) & (hv['embed']['count']==0) & (hv['hv_movies']['count']==0), 'top_frac'] = np.nan    \n",
    "    hv[key].loc[(hv['Jhv_movies']['count']==0) & (hv['embed']['count']==0) & (hv['hv_movies']['count']==0), 'fraction'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# total_count = (hv['hv_movies']['count'] + hv['embed']['count'] + hv['Jhv_movies']['count'])\n",
    "\n",
    "# hv['hv_movies']['bottom_frac'] = 0\n",
    "# hv['hv_movies']['top_frac'] = hv['hv_movies']['count']/total_count\n",
    "# hv['hv_movies']['fraction'] = hv['hv_movies']['top_frac'] - hv['hv_movies']['bottom_frac']\n",
    "\n",
    "# hv['embed']['bottom_frac'] = hv['hv_movies']['top_frac'] \n",
    "# hv['embed']['top_frac'] = hv['embed']['bottom_frac'] + hv['embed']['count']/total_count\n",
    "# hv['embed']['fraction'] = hv['embed']['top_frac'] - hv['embed']['bottom_frac']\n",
    "\n",
    "# hv['Jhv_movies']['bottom_frac'] = hv['embed']['top_frac']\n",
    "# hv['Jhv_movies']['top_frac'] = 1\n",
    "# hv['Jhv_movies']['fraction'] = hv['Jhv_movies']['top_frac'] - hv['Jhv_movies']['bottom_frac']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "frac = pd.DataFrame()\n",
    "\n",
    "frac['date'] = pd.date_range(date_start, date_end, freq='D').to_period('D').to_timestamp()\n",
    "\n",
    "frac['total_count'] = (hv['hv_movies']['count'] + hv['embed']['count'] + hv['Jhv_movies']['count'])\n",
    "\n",
    "frac['hv_frac'] = hv['hv_movies']['count']/frac['total_count']\n",
    "frac['hv_perc'] = frac['hv_frac']*100\n",
    "frac['em_frac'] = hv['embed']['count']/frac['total_count']\n",
    "frac['em_perc'] = frac['em_frac']*100\n",
    "frac['Jhv_frac'] = hv['Jhv_movies']['count']/frac['total_count']\n",
    "frac['Jhv_perc'] = frac['Jhv_frac']*100\n",
    "\n",
    "frac['hv_bottom'] = 1e-6\n",
    "frac['hv_top'] = frac['hv_frac']\n",
    "\n",
    "frac['em_bottom'] = frac['hv_top'] \n",
    "frac['em_top'] = frac['em_bottom'] + frac['em_frac']\n",
    "\n",
    "frac['Jhv_bottom'] = frac['em_top']\n",
    "frac['Jhv_top'] = frac['Jhv_bottom'] + frac['Jhv_frac']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>total_count</th>\n",
       "      <th>hv_frac</th>\n",
       "      <th>hv_perc</th>\n",
       "      <th>em_frac</th>\n",
       "      <th>em_perc</th>\n",
       "      <th>Jhv_frac</th>\n",
       "      <th>Jhv_perc</th>\n",
       "      <th>hv_bottom</th>\n",
       "      <th>hv_top</th>\n",
       "      <th>em_bottom</th>\n",
       "      <th>em_top</th>\n",
       "      <th>Jhv_bottom</th>\n",
       "      <th>Jhv_top</th>\n",
       "      <th>date_str</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-02-07</td>\n",
       "      <td>377.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2011-02-07</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-02-08</td>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2011-02-08</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-02-09</td>\n",
       "      <td>749.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2011-02-09</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-02-10</td>\n",
       "      <td>772.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2011-02-10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-02-11</td>\n",
       "      <td>1003.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2011-02-11</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3504</th>\n",
       "      <td>2020-09-11</td>\n",
       "      <td>73.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-09-11</td>\n",
       "      <td>3504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3505</th>\n",
       "      <td>2020-09-12</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-09-12</td>\n",
       "      <td>3505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3506</th>\n",
       "      <td>2020-09-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-09-13</td>\n",
       "      <td>3506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3507</th>\n",
       "      <td>2020-09-14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2020-09-14</td>\n",
       "      <td>3507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3508</th>\n",
       "      <td>2020-09-15</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2020-09-15</td>\n",
       "      <td>3508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3509 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           date  total_count  hv_frac  hv_perc  em_frac  em_perc  Jhv_frac  \\\n",
       "0    2011-02-07        377.0      0.0      0.0      0.0      0.0       1.0   \n",
       "1    2011-02-08        540.0      0.0      0.0      0.0      0.0       1.0   \n",
       "2    2011-02-09        749.0      0.0      0.0      0.0      0.0       1.0   \n",
       "3    2011-02-10        772.0      0.0      0.0      0.0      0.0       1.0   \n",
       "4    2011-02-11       1003.0      0.0      0.0      0.0      0.0       1.0   \n",
       "...         ...          ...      ...      ...      ...      ...       ...   \n",
       "3504 2020-09-11         73.0      0.0      0.0      0.0      0.0       1.0   \n",
       "3505 2020-09-12         36.0      0.0      0.0      0.0      0.0       1.0   \n",
       "3506 2020-09-13          0.0      0.0      0.0      0.0      0.0       0.0   \n",
       "3507 2020-09-14          0.0      0.0      0.0      0.0      0.0       0.0   \n",
       "3508 2020-09-15          3.0      0.0      0.0      0.0      0.0       1.0   \n",
       "\n",
       "      Jhv_perc  hv_bottom  hv_top  em_bottom  em_top  Jhv_bottom  Jhv_top  \\\n",
       "0        100.0   0.000001     0.0        0.0     0.0         0.0      1.0   \n",
       "1        100.0   0.000001     0.0        0.0     0.0         0.0      1.0   \n",
       "2        100.0   0.000001     0.0        0.0     0.0         0.0      1.0   \n",
       "3        100.0   0.000001     0.0        0.0     0.0         0.0      1.0   \n",
       "4        100.0   0.000001     0.0        0.0     0.0         0.0      1.0   \n",
       "...        ...        ...     ...        ...     ...         ...      ...   \n",
       "3504     100.0   0.000001     0.0        0.0     0.0         0.0      1.0   \n",
       "3505     100.0   0.000001     0.0        0.0     0.0         0.0      1.0   \n",
       "3506       0.0   0.000001     0.0        0.0     0.0         0.0      0.0   \n",
       "3507       0.0   0.000001     0.0        0.0     0.0         0.0      0.0   \n",
       "3508     100.0   0.000001     0.0        0.0     0.0         0.0      1.0   \n",
       "\n",
       "        date_str  index  \n",
       "0     2011-02-07      0  \n",
       "1     2011-02-08      1  \n",
       "2     2011-02-09      2  \n",
       "3     2011-02-10      3  \n",
       "4     2011-02-11      4  \n",
       "...          ...    ...  \n",
       "3504  2020-09-11   3504  \n",
       "3505  2020-09-12   3505  \n",
       "3506  2020-09-13   3506  \n",
       "3507  2020-09-14   3507  \n",
       "3508  2020-09-15   3508  \n",
       "\n",
       "[3509 rows x 16 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frac['date_str'] = frac['date'].astype(str)\n",
    "frac = frac.fillna(0)\n",
    "frac['index'] = frac.index\n",
    "frac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "frac['year_dec'] = frac['date'].dt.year + frac['date'].dt.day/pd.to_datetime(dict(year=frac['date'].dt.year, month=12, day=31)).dt.strftime('%j').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing plot for service comparison...\n",
      "Service comparison plot done.\n"
     ]
    }
   ],
   "source": [
    "print(\"Preparing plot for service comparison...\")\n",
    "TOOLS = \"save, pan, box_zoom, reset, wheel_zoom\"\n",
    "\n",
    "p = figure(plot_height=250, output_backend='webgl',\n",
    "           tools=TOOLS,\n",
    "           sizing_mode=\"scale_width\", min_border_left = 0,\n",
    "#            tooltips=\"$name @date: @$name\"\n",
    "#            y_axis_type=\"log\", #y_range = (1, 10**(-4))\n",
    "          )\n",
    "\n",
    "p.add_layout(Title(text = \"Service Usage expressed as fraction of daily total usage\", text_font_size = \"16pt\", text_font_style=\"bold\"), \n",
    "             place = 'above')\n",
    "p.add_layout(Title(text = \"Date Range: %s - %s\"%(date_start.strftime('%Y, %b %d'),date_end.strftime('%Y, %b %d'))), \n",
    "             place = 'above')\n",
    "\n",
    "p.background_fill_color=\"#f5f5f5\"\n",
    "p.grid.grid_line_color=\"white\"\n",
    "p.xaxis.axis_label = 'Date'\n",
    "p.yaxis.axis_label = 'Fractional usage'\n",
    "p.axis.axis_line_color = None\n",
    "\n",
    "# p_hv = p.vbar_stack(stackers=['hv_frac', 'em_frac', 'Jhv_frac'],\n",
    "#                     x='index', width=0.75, \n",
    "# #                     alpha = 0.5,\n",
    "#                     color = bp.Viridis[3],\n",
    "# #                     hover_color = bp.Viridis[3],\n",
    "#                     source=ColumnDataSource(frac), \n",
    "#                     legend_label=[\"Fraction of Helioviewer.org movie requests\",\n",
    "#                                   \"Fraction of Embedded Helioviewer.org requests\",\n",
    "#                                   \"Fraction of JHelioviewer movie requests\"])\n",
    "\n",
    "p_hv = p.vbar(x='index', width=0.75,\n",
    "              bottom='hv_bottom', \n",
    "              top='hv_top',\n",
    "#               hover_alpha = 0.5,\n",
    "              color = 'blue',\n",
    "#               hover_color='blue',\n",
    "              source=frac, legend_label=\"Fraction of Helioviewer.org requests\")\n",
    "\n",
    "p_em = p.vbar(x='index', width=0.75, \n",
    "              bottom='em_bottom', top='em_top',\n",
    "              hover_alpha = 0.5,\n",
    "              color = 'orange',\n",
    "              hover_color='orange',\n",
    "              source=frac, legend_label=\"Fraction of embedded Helioviewer.org requests\")\n",
    "\n",
    "p_Jh = p.vbar(x='index', width=0.75, \n",
    "              bottom='Jhv_bottom', top='Jhv_top',\n",
    "              hover_alpha = 0.5,\n",
    "              color = 'green',\n",
    "              hover_color='green',\n",
    "              source=frac, legend_label=\"Fraction of JHelioviewer movie requests\")\n",
    "\n",
    "\n",
    "p.add_tools(HoverTool(renderers=[p_hv, p_em, p_Jh],\n",
    "                      tooltips=[('Date', '@date_str'),\n",
    "                                ('JHelioviewer', '@Jhv_perc{0.00}%'),\n",
    "                                ('Embed Helioviewer.org', '@em_perc{0.00}%'),\n",
    "                                ('Helioviewer.org', '@hv_perc{0.00}%'),\n",
    "                                ('Total hits', '@total_count')\n",
    "                               ],\n",
    "#                       formatters={'@date' : 'datetime', # use 'datetime' formatter for 'date' field\n",
    "#                                  },\n",
    "                     ))\n",
    "\n",
    "# frac['date'].dt.year + frac['date'].dt.day/pd.to_datetime(dict(year=frac['date'].dt.year, month=12, day=31)).dt.strftime('%j').astype(int)\n",
    "\n",
    "def dt2ind(dt):\n",
    "#     y = dt.year + dt.day/int(pd.Timestamp(dt.year,12,31).strftime('%j'))\n",
    "    return frac.loc[frac['date']==dt].index[0]\n",
    "\n",
    "p.line(y=[0,1], x=dt2ind(pd.Timestamp('2011/06/07')), line_width=1.5, line_dash='dotdash', color='red', alpha=1, legend_label= \"failed eruption (2011/06/07)\")\n",
    "p.line(y=[0,1], x=dt2ind(pd.Timestamp('2013/11/28')), line_width=1.5, line_dash='dotdash', color='purple', alpha=1, legend_label= \"Comet ISON (2013/11/28)\")\n",
    "p.harea(y=[0,1], x1=dt2ind(pd.Timestamp('2017/09/06')), x2=dt2ind(pd.Timestamp('2017/09/10')), fill_color='teal', fill_alpha=1, legend_label= \"large flares (2017/09/06-09)\")\n",
    "\n",
    "p.harea(y=[0,1], x1=dt2ind(pd.Timestamp('2011/08/11')), x2=dt2ind(pd.Timestamp('2011/09/18')), fill_color='gray', fill_alpha=0.3, legend_label= \"GSFC server repair (2011/08/11 - 2011/09/18)\")\n",
    "p.harea(y=[0,1], x1=dt2ind(pd.Timestamp('2013/10/01')), x2=dt2ind(pd.Timestamp('2013/10/16')), fill_color='green', fill_alpha=0.3, legend_label= \"U.S. Fed. Gov. shutdown (2013/10/01 - 2013/10/16)\")\n",
    "p.harea(y=[0,1], x1=dt2ind(pd.Timestamp('2015/02/04')), x2=dt2ind(pd.Timestamp('2015/09/23')), fill_color='red', fill_alpha=0.3, legend_label= \"GSFC server down (2015/02/04 - 2015/09/23)\")\n",
    "\n",
    "\n",
    "df_stats = pd.DataFrame({'width': np.linspace(frac['index'].min(), frac['index'].max(), 2),\n",
    "                         'mean_hv':np.nanmean(frac['hv_frac']), 'mean_embed':np.nanmean(frac['em_frac']), 'mean_Jhv':np.nanmean(frac['Jhv_frac'])})\n",
    "\n",
    "p.line(y='mean_hv', x='width', line_color = \"red\", line_dash='dotted', line_width= 2, alpha=0.5,\n",
    "       legend_label=\"Mean fraction of Helioviewer.org movie requests (%.3f)\"%(df_stats['mean_hv'][0]), source=df_stats)\n",
    "\n",
    "p.line(y='mean_embed', x='width', line_color = \"pink\", line_dash='dotted', line_width= 2, alpha=0.5, \n",
    "       legend_label=\"Mean fraction of Helioviewer.org Embed requests (%.3f)\"%(df_stats['mean_embed'][0]), source=df_stats)\n",
    "\n",
    "p.line(y='mean_Jhv', x='width', line_color = \"cyan\", line_dash='dotted', line_width= 2, alpha=0.5, \n",
    "       legend_label=\"Mean fraction of JHelioviewer movie requests (%.3f)\"%(df_stats['mean_Jhv'][0]), source=df_stats)\n",
    "\n",
    "# p.xaxis.ticks = frac['index'].iloc[::]\n",
    "p.xaxis.major_label_overrides = {i: date.strftime('%Y %b %d') for i, date in enumerate(frac['date'])}\n",
    "\n",
    "p.x_range.range_padding = 0.02\n",
    "p.y_range.range_padding = 0.02\n",
    "\n",
    "p.legend.background_fill_alpha = 0.3\n",
    "p.legend.location='top_left'\n",
    "p.border_fill_color = \"whitesmoke\"\n",
    "\n",
    "# show(p)\n",
    "save(p, filename='service_usage_fraction.html', title='Helioviewer service usage')\n",
    "print(\"Service comparison plot done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALL PROCSESSES COMPLETED in 33 minutes\n"
     ]
    }
   ],
   "source": [
    "print(\"ALL PROCSESSES COMPLETED in %d minutes\" %((time.time()-master_time)/60))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics table: Fractional usage of all endpoints "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting SQL query in redis_stats table of hv database...\")\n",
    "start_time=time.time()\n",
    "query = \"SELECT date_format(datetime, '%Y-%m-%d 00:00:00') as date, action, count(date_format(datetime, '%Y-%m-%d 00:00:00')) as count FROM {} GROUP BY date_format(datetime, '%Y-%m-%d 00:00:00'), action\"\n",
    "hv = sql_query(query.format('redis_stats WHERE datetime>\\'2020-07-01\\''))\n",
    "print(\"Query completed in %d seconds\"%(time.time()-start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heirarchy = {\n",
    "    \"Total\":[\"total\",\"rate_limit_exceeded\"],\n",
    "    \"Client Sites\":[\"standard\",\"embed\",\"minimal\"],\n",
    "    \"Images\":[\"takeScreenshot\",\"getTile\",\"getClosestImage\",\"getJP2Image-web\",\"getJP2Image-jpip\",\"getJP2Image\",\"downloadScreenshot\",\"getJPX\",\"getJPXClosestToMidPoint\"],\n",
    "    \"Movies\":[\"buildMovie\",\"getMovieStatus\",\"queueMovie\",\"reQueueMovie\",\"playMovie\",\"downloadMovie\",\"getUserVideos\",\"getObservationDateVideos\",\"uploadMovieToYouTube\",\"checkYouTubeAuth\",\"getYouTubeAuth\"],\n",
    "    \"Events\":[\"getEventGlossary\",\"getEvents\",\"getFRMs\",\"getEvent\",\"getEventFRMs\",\"getDefaultEventTypes\",\"getEventsByEventLayers\",\"importEvents\"],\n",
    "    \"Data\":[\"getRandomSeed\",\"getDataSources\",\"getJP2Header\",\"getDataCoverage\",\"getStatus\",\"getNewsFeed\",\"getDataCoverageTimeline\",\"getClosestData\",\"getSolarBodiesGlossary\",\"getSolarBodies\",\"getTrajectoryTime\",\"sciScript-SSWIDL\",\"sciScript-SunPy\",\"getSciDataScript\",\"updateDataCoverage\"],\n",
    "    \"Other\":[\"shortenURL\",\"getUsageStatistics\",\"movie-notifications-granted\",\"movie-notifications-denied\",\"logNotificationStatistics\",\"launchJHelioviewer\"],\n",
    "    \"WebGL\":[\"getTexture\",\"getGeometryServiceData\"]\n",
    "};"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv['date'] = pd.to_datetime(hv['date'])\n",
    "\n",
    "hv = hv.pivot_table(values='count', columns='action', index = ['date'])\n",
    "hv.columns.name = None\n",
    "hv=hv.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for stat in heirarchy:\n",
    "    for action in heirarchy[stat]:\n",
    "        if action not in hv.columns:\n",
    "            hv[action]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "frac={}\n",
    "for stat in heirarchy.keys():\n",
    "    df = pd.DataFrame()\n",
    "    if(stat=='Total'):\n",
    "            df['total'] = hv.sum(axis=1)\n",
    "            df['total_count'] = hv.sum(axis=1)\n",
    "    else:\n",
    "        df['total'] = hv[heirarchy[stat]].sum(axis=1).values\n",
    "        df.index = hv.index\n",
    "        df[heirarchy[stat]] = hv[heirarchy[stat]].div(df['total'], axis=0)*100\n",
    "        df= df.fillna(0)\n",
    "    df = df.reindex(pd.date_range(df.index.min(), df.index.max(), freq='D'), fill_value=0).reset_index().rename(columns = {'index':'date'})\n",
    "    #     df['date_str'] = df['date'].astype(str)\n",
    "    df.index = df['date']\n",
    "    df.index.name = None\n",
    "    df = df.reset_index().rename(columns={'index':'date_str'}).reset_index()\n",
    "    df['date_str'] = df['date_str'].astype(str)\n",
    "    frac[stat]=df.copy()\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "panels=[]\n",
    "for stat in frac.keys():\n",
    "    df=frac[stat]\n",
    "    TOOLS = \"save, pan, box_zoom, reset, wheel_zoom\"\n",
    "\n",
    "    p = figure(plot_height=250, output_backend='webgl',\n",
    "               tools=TOOLS,\n",
    "               sizing_mode=\"scale_width\", min_border_left = 0,\n",
    "    #            tooltips=\"$name @date: @$name\"\n",
    "              )\n",
    "\n",
    "    p.add_layout(Title(text = \"Service Usage expressed as fraction of daily total usage\", text_font_size = \"16pt\", text_font_style=\"bold\"), \n",
    "                 place = 'above')\n",
    "    p.add_layout(Title(text = \"Date Range: %s - %s\"%(df['date'].min().strftime('%Y, %b %d'),df['date'].max().strftime('%Y, %b %d'))), \n",
    "                 place = 'above')\n",
    "\n",
    "    p.background_fill_color=\"#f5f5f5\"\n",
    "    p.grid.grid_line_color=\"white\"\n",
    "    p.xaxis.axis_label = 'Date'\n",
    "    p.yaxis.axis_label = 'Fractional usage (%)'\n",
    "    p.axis.axis_line_color = None\n",
    "    \n",
    "    \n",
    "    \n",
    "    stacks = df.columns.values[4:]\n",
    "\n",
    "    p_hv = p.vbar_stack(stackers=stacks,\n",
    "                        x='index', width=0.75, \n",
    "                        color = bp.Category20[max(3,len(stacks))][:len(stacks)],\n",
    "                        source=ColumnDataSource(df),\n",
    "                        legend_label=[\"%s\"%string for string in stacks])\n",
    "\n",
    "    p.add_tools(HoverTool(renderers=p_hv,\n",
    "                          tooltips=[('Date', '@date_str'), ('Total', '@total')] + [(string, '@{%s}{0.00}%%'%string) for string in stacks],\n",
    "                          formatters={'@date_str' : 'datetime', # use 'datetime' formatter for 'date' field\n",
    "                                     },\n",
    "                         ))\n",
    "\n",
    "    # def dt2ind(dt):\n",
    "    # #     y = dt.year + dt.day/int(pd.Timestamp(dt.year,12,31).strftime('%j'))\n",
    "    #     return df.loc[df['date']==dt].index[0]\n",
    "\n",
    "    # p.line(y=[0,1], x=dt2ind(pd.Timestamp('2011/06/07')), line_width=1.5, line_dash='dotdash', color='red', alpha=1, legend_label= \"failed eruption (2011/06/07)\")\n",
    "    # p.line(y=[0,1], x=dt2ind(pd.Timestamp('2013/11/28')), line_width=1.5, line_dash='dotdash', color='purple', alpha=1, legend_label= \"Comet ISON (2013/11/28)\")\n",
    "    # p.harea(y=[0,1], x1=dt2ind(pd.Timestamp('2017/09/06')), x2=dt2ind(pd.Timestamp('2017/09/10')), fill_color='teal', fill_alpha=1, legend_label= \"large flares (2017/09/06-09)\")\n",
    "\n",
    "    # p.harea(y=[0,1], x1=dt2ind(pd.Timestamp('2011/08/11')), x2=dt2ind(pd.Timestamp('2011/09/18')), fill_color='gray', fill_alpha=0.3, legend_label= \"GSFC server repair (2011/08/11 - 2011/09/18)\")\n",
    "    # p.harea(y=[0,1], x1=dt2ind(pd.Timestamp('2013/10/01')), x2=dt2ind(pd.Timestamp('2013/10/16')), fill_color='green', fill_alpha=0.3, legend_label= \"U.S. Fed. Gov. shutdown (2013/10/01 - 2013/10/16)\")\n",
    "    # p.harea(y=[0,1], x1=dt2ind(pd.Timestamp('2015/02/04')), x2=dt2ind(pd.Timestamp('2015/09/23')), fill_color='red', fill_alpha=0.3, legend_label= \"GSFC server down (2015/02/04 - 2015/09/23)\")\n",
    "\n",
    "\n",
    "    # df_stats = pd.DataFrame({'width': np.linspace(df['index'].min(), df['index'].max(), 2),\n",
    "    #                          'mean_hv':np.nanmean(df['hv_frac']), 'mean_embed':np.nanmean(df['em_frac']), 'mean_Jhv':np.nanmean(df['Jhv_frac'])})\n",
    "\n",
    "    # p.line(y='mean_hv', x='width', line_color = \"red\", line_dash='dotted', line_width= 2, alpha=0.5,\n",
    "    #        legend_label=\"Mean fraction of Helioviewer.org movie requests (%.3f)\"%(df_stats['mean_hv'][0]), source=df_stats)\n",
    "\n",
    "    # p.line(y='mean_embed', x='width', line_color = \"pink\", line_dash='dotted', line_width= 2, alpha=0.5, \n",
    "    #        legend_label=\"Mean fraction of Helioviewer.org Embed requests (%.3f)\"%(df_stats['mean_embed'][0]), source=df_stats)\n",
    "\n",
    "    # p.line(y='mean_Jhv', x='width', line_color = \"cyan\", line_dash='dotted', line_width= 2, alpha=0.5, \n",
    "    #        legend_label=\"Mean fraction of JHelioviewer movie requests (%.3f)\"%(df_stats['mean_Jhv'][0]), source=df_stats)\n",
    "\n",
    "    p.xaxis.major_label_overrides = {i: date.strftime('%Y %b %d') for i, date in enumerate(df['date'])}\n",
    "\n",
    "    p.x_range.range_padding = 0.02\n",
    "    p.y_range.range_padding = 0.02\n",
    "\n",
    "    p.legend.background_fill_alpha = 0.6\n",
    "    p.border_fill_color = \"whitesmoke\"\n",
    "    # p.y_range.start = 0\n",
    "    # p.y_range.end=200\n",
    "    p.legend.location='top_left'\n",
    "    # p.legend.orientation = 'horizontal'\n",
    "    panel = Panel(child=p, title=stat)\n",
    "    panels.append(panel)\n",
    "tabs = Tabs(tabs=panels)\n",
    "show(tabs)\n",
    "save(tabs, filename='service_usage_all_july2020.html', title='Helioviewer service usage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fraction usage grouped by categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot=pd.DataFrame()\n",
    "frac=pd.DataFrame()\n",
    "for stat in heirarchy.keys():\n",
    "    if(stat=='Total'): continue\n",
    "    tot[stat] = hv[heirarchy[stat]].sum(axis=1).values\n",
    "    frac[stat] = tot[stat]/hv.sum(axis=1).values * 100\n",
    "#     break\n",
    "\n",
    "tot.insert(0, 'date', hv.index)\n",
    "frac.insert(0, 'date', hv.index)\n",
    "tot.insert(1, 'total', hv.sum(axis=1).values)\n",
    "frac.insert(1, 'total', hv.sum(axis=1).values)\n",
    "tot.index = hv.index\n",
    "frac.index = hv.index\n",
    "tot.index.name = None\n",
    "frac.index.name = None\n",
    "tot = tot.reset_index().rename(columns={'index':'date_str'}).reset_index()\n",
    "frac = frac.reset_index().rename(columns={'index':'date_str'}).reset_index()\n",
    "tot['date_str'] = tot['date_str'].astype(str)\n",
    "frac['date_str'] = frac['date_str'].astype(str)\n",
    "# tot.fillna(0)\n",
    "# frac.fillna(0)\n",
    "# tot = tot.reindex(pd.date_range(tot['date'].min(), tot['date'].max(), freq='D'), fill_value=0).reset_index().rename(columns = {'index':'date'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "panels=[]\n",
    "df=tot\n",
    "TOOLS = \"save, pan, box_zoom, reset, wheel_zoom\"\n",
    "\n",
    "p = figure(plot_height=250, output_backend='webgl',\n",
    "           tools=TOOLS,\n",
    "           sizing_mode=\"scale_width\", min_border_left = 0,\n",
    "#            tooltips=\"$name @date: @$name\"\n",
    "          )\n",
    "\n",
    "p.add_layout(Title(text = \"Total daily service usage\", text_font_size = \"16pt\", text_font_style=\"bold\"), \n",
    "             place = 'above')\n",
    "p.add_layout(Title(text = \"Date Range: %s - %s\"%(df['date'].min().strftime('%Y, %b %d'),df['date'].max().strftime('%Y, %b %d'))), \n",
    "             place = 'above')\n",
    "\n",
    "p.background_fill_color=\"#f5f5f5\"\n",
    "p.grid.grid_line_color=\"white\"\n",
    "p.xaxis.axis_label = 'Date'\n",
    "p.yaxis.axis_label = 'Total usage'\n",
    "p.axis.axis_line_color = None\n",
    "\n",
    "\n",
    "\n",
    "stacks = df.columns.values[4:]\n",
    "\n",
    "p_hv = p.vbar_stack(stackers=stacks,\n",
    "                    x='index', width=0.75, \n",
    "                    color = bp.Category20[max(3,len(stacks))][:len(stacks)],\n",
    "                    source=ColumnDataSource(df),\n",
    "                    legend_label=[\"%s\"%string for string in stacks])\n",
    "\n",
    "p.add_tools(HoverTool(renderers=p_hv,\n",
    "                      tooltips=[('Date', '@date_str'), ('Total', '@total')] + [(string, '@{%s}{0}'%string) for string in stacks],\n",
    "#                       formatters={'@date_str' : 'datetime', # use 'datetime' formatter for 'date' field\n",
    "#                                  },\n",
    "                     ))\n",
    "\n",
    "# def dt2ind(dt):\n",
    "# #     y = dt.year + dt.day/int(pd.Timestamp(dt.year,12,31).strftime('%j'))\n",
    "#     return df.loc[df['date']==dt].index[0]\n",
    "\n",
    "# p.line(y=[0,1], x=dt2ind(pd.Timestamp('2011/06/07')), line_width=1.5, line_dash='dotdash', color='red', alpha=1, legend_label= \"failed eruption (2011/06/07)\")\n",
    "# p.line(y=[0,1], x=dt2ind(pd.Timestamp('2013/11/28')), line_width=1.5, line_dash='dotdash', color='purple', alpha=1, legend_label= \"Comet ISON (2013/11/28)\")\n",
    "# p.harea(y=[0,1], x1=dt2ind(pd.Timestamp('2017/09/06')), x2=dt2ind(pd.Timestamp('2017/09/10')), fill_color='teal', fill_alpha=1, legend_label= \"large flares (2017/09/06-09)\")\n",
    "\n",
    "# p.harea(y=[0,1], x1=dt2ind(pd.Timestamp('2011/08/11')), x2=dt2ind(pd.Timestamp('2011/09/18')), fill_color='gray', fill_alpha=0.3, legend_label= \"GSFC server repair (2011/08/11 - 2011/09/18)\")\n",
    "# p.harea(y=[0,1], x1=dt2ind(pd.Timestamp('2013/10/01')), x2=dt2ind(pd.Timestamp('2013/10/16')), fill_color='green', fill_alpha=0.3, legend_label= \"U.S. Fed. Gov. shutdown (2013/10/01 - 2013/10/16)\")\n",
    "# p.harea(y=[0,1], x1=dt2ind(pd.Timestamp('2015/02/04')), x2=dt2ind(pd.Timestamp('2015/09/23')), fill_color='red', fill_alpha=0.3, legend_label= \"GSFC server down (2015/02/04 - 2015/09/23)\")\n",
    "\n",
    "\n",
    "# df_stats = pd.DataFrame({'width': np.linspace(df['index'].min(), df['index'].max(), 2),\n",
    "#                          'mean_hv':np.nanmean(df['hv_frac']), 'mean_embed':np.nanmean(df['em_frac']), 'mean_Jhv':np.nanmean(df['Jhv_frac'])})\n",
    "\n",
    "# p.line(y='mean_hv', x='width', line_color = \"red\", line_dash='dotted', line_width= 2, alpha=0.5,\n",
    "#        legend_label=\"Mean fraction of Helioviewer.org movie requests (%.3f)\"%(df_stats['mean_hv'][0]), source=df_stats)\n",
    "\n",
    "# p.line(y='mean_embed', x='width', line_color = \"pink\", line_dash='dotted', line_width= 2, alpha=0.5, \n",
    "#        legend_label=\"Mean fraction of Helioviewer.org Embed requests (%.3f)\"%(df_stats['mean_embed'][0]), source=df_stats)\n",
    "\n",
    "# p.line(y='mean_Jhv', x='width', line_color = \"cyan\", line_dash='dotted', line_width= 2, alpha=0.5, \n",
    "#        legend_label=\"Mean fraction of JHelioviewer movie requests (%.3f)\"%(df_stats['mean_Jhv'][0]), source=df_stats)\n",
    "\n",
    "p.xaxis.major_label_overrides = {i: date.strftime('%Y %b %d') for i, date in enumerate(df['date'])}\n",
    "\n",
    "p.x_range.range_padding = 0.02\n",
    "p.y_range.range_padding = 0.02\n",
    "\n",
    "p.legend.background_fill_alpha = 0.6\n",
    "p.border_fill_color = \"whitesmoke\"\n",
    "p.legend.location='top_left'\n",
    "# show(p)\n",
    "panel = Panel(child=p, title='Total')\n",
    "panels.append(panel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df = frac\n",
    "TOOLS = \"save, pan, box_zoom, reset, wheel_zoom\"\n",
    "\n",
    "p = figure(plot_height=250, output_backend='webgl',\n",
    "           tools=TOOLS,\n",
    "           sizing_mode=\"scale_width\", min_border_left = 0,\n",
    "#            tooltips=\"$name @date: @$name\"\n",
    "          )\n",
    "\n",
    "p.add_layout(Title(text = \"Service Usage expressed as fraction of daily total usage\", text_font_size = \"16pt\", text_font_style=\"bold\"), \n",
    "             place = 'above')\n",
    "p.add_layout(Title(text = \"Date Range: %s - %s\"%(df['date'].min().strftime('%Y, %b %d'),df['date'].max().strftime('%Y, %b %d'))), \n",
    "             place = 'above')\n",
    "\n",
    "p.background_fill_color=\"#f5f5f5\"\n",
    "p.grid.grid_line_color=\"white\"\n",
    "p.xaxis.axis_label = 'Date'\n",
    "p.yaxis.axis_label = 'Fractional usage (%)'\n",
    "p.axis.axis_line_color = None\n",
    "\n",
    "\n",
    "\n",
    "stacks = df.columns.values[4:]\n",
    "color_palette = bp.Category20[max(3,len(stacks))][:len(stacks)]\n",
    "\n",
    "p_hv = p.vbar_stack(stackers=stacks,\n",
    "                    x='index', width=0.75, \n",
    "                    color = color_palette,\n",
    "                    source=ColumnDataSource(df),\n",
    "                    legend_label=[\"%s\"%string for string in stacks])\n",
    "\n",
    "p.add_tools(HoverTool(renderers=p_hv,\n",
    "                      tooltips=[('Date', '@date_str'), ('Total', '@total')] + [(string, '@{%s}{0.00}%%'%string) for string in stacks],\n",
    "#                       formatters={'@date_str' : 'datetime', # use 'datetime' formatter for 'date' field\n",
    "#                                  },\n",
    "                     ))\n",
    "\n",
    "# def dt2ind(dt):\n",
    "# #     y = dt.year + dt.day/int(pd.Timestamp(dt.year,12,31).strftime('%j'))\n",
    "#     return df.loc[df['date']==dt].index[0]\n",
    "\n",
    "# p.line(y=[0,1], x=dt2ind(pd.Timestamp('2011/06/07')), line_width=1.5, line_dash='dotdash', color='red', alpha=1, legend_label= \"failed eruption (2011/06/07)\")\n",
    "# p.line(y=[0,1], x=dt2ind(pd.Timestamp('2013/11/28')), line_width=1.5, line_dash='dotdash', color='purple', alpha=1, legend_label= \"Comet ISON (2013/11/28)\")\n",
    "# p.harea(y=[0,1], x1=dt2ind(pd.Timestamp('2017/09/06')), x2=dt2ind(pd.Timestamp('2017/09/10')), fill_color='teal', fill_alpha=1, legend_label= \"large flares (2017/09/06-09)\")\n",
    "\n",
    "# p.harea(y=[0,1], x1=dt2ind(pd.Timestamp('2011/08/11')), x2=dt2ind(pd.Timestamp('2011/09/18')), fill_color='gray', fill_alpha=0.3, legend_label= \"GSFC server repair (2011/08/11 - 2011/09/18)\")\n",
    "# p.harea(y=[0,1], x1=dt2ind(pd.Timestamp('2013/10/01')), x2=dt2ind(pd.Timestamp('2013/10/16')), fill_color='green', fill_alpha=0.3, legend_label= \"U.S. Fed. Gov. shutdown (2013/10/01 - 2013/10/16)\")\n",
    "# p.harea(y=[0,1], x1=dt2ind(pd.Timestamp('2015/02/04')), x2=dt2ind(pd.Timestamp('2015/09/23')), fill_color='red', fill_alpha=0.3, legend_label= \"GSFC server down (2015/02/04 - 2015/09/23)\")\n",
    "\n",
    "\n",
    "# df_stats = pd.DataFrame({'width': np.linspace(df['index'].min(), df['index'].max(), 2),\n",
    "#                          'mean_hv':np.nanmean(df['hv_frac']), 'mean_embed':np.nanmean(df['em_frac']), 'mean_Jhv':np.nanmean(df['Jhv_frac'])})\n",
    "\n",
    "# p.line(y='mean_hv', x='width', line_color = \"red\", line_dash='dotted', line_width= 2, alpha=0.5,\n",
    "#        legend_label=\"Mean fraction of Helioviewer.org movie requests (%.3f)\"%(df_stats['mean_hv'][0]), source=df_stats)\n",
    "\n",
    "# p.line(y='mean_embed', x='width', line_color = \"pink\", line_dash='dotted', line_width= 2, alpha=0.5, \n",
    "#        legend_label=\"Mean fraction of Helioviewer.org Embed requests (%.3f)\"%(df_stats['mean_embed'][0]), source=df_stats)\n",
    "\n",
    "# p.line(y='mean_Jhv', x='width', line_color = \"cyan\", line_dash='dotted', line_width= 2, alpha=0.5, \n",
    "#        legend_label=\"Mean fraction of JHelioviewer movie requests (%.3f)\"%(df_stats['mean_Jhv'][0]), source=df_stats)\n",
    "\n",
    "p.xaxis.major_label_overrides = {i: date.strftime('%Y %b %d') for i, date in enumerate(df['date'])}\n",
    "\n",
    "p.x_range.range_padding = 0.02\n",
    "p.y_range.range_padding = 0.02\n",
    "\n",
    "p.legend.background_fill_alpha = 0.6\n",
    "p.border_fill_color = \"whitesmoke\"\n",
    "p.legend.location='top_left'\n",
    "\n",
    "panel = Panel(child=p, title='Fractional')\n",
    "# panels.append(panel)\n",
    "panels[1] = panel\n",
    "tabs = Tabs(tabs=panels)\n",
    "show(tabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(tabs, filename='service_usage_all_july2020_categorical.html', title='Helioviewer service usage')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
