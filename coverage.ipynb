{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "\n",
    "from bokeh.plotting import *\n",
    "from bokeh.layouts import gridplot\n",
    "from bokeh.models import *# Span, ColumnDataSource, LogColorMapper, ColorMapper, LogTicker, ColorBar, BasicTicker, LinearColorMapper, PrintfTickFormatter, HoverTool, CategoricalColorMapper, Range1d, Title\n",
    "from bokeh.models.widgets import Tabs, Panel\n",
    "from bokeh.io import show, output_notebook, reset_output\n",
    "output_notebook()\n",
    "from bokeh.models.glyphs import Text\n",
    "import bokeh.palettes as bp\n",
    "\n",
    "# import hail as hl\n",
    "import json\n",
    "import urllib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import (MultipleLocator, FormatStrFormatter, AutoMinorLocator)\n",
    "\n",
    "from pathlib import Path\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_url = urllib.request.urlopen('https://api.helioviewer.org/?action=getDataSources')\n",
    "hv_keys = json.loads(json_url.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv_sid = pd.DataFrame(columns=['OBS','SOURCE_ID'])\n",
    "\n",
    "# while sid=='sourceId':\n",
    "#     key=hv_keys.keys()\n",
    "\n",
    "for key1 in hv_keys.keys():\n",
    "    for key2 in hv_keys[key1].keys():\n",
    "        if 'sourceId' in hv_keys[key1][key2].keys(): \n",
    "            hv_sid.loc[len(hv_sid)] = \" \".join([key1, key2]), hv_keys[key1][key2]['sourceId']\n",
    "        else:\n",
    "            for key3 in hv_keys[key1][key2].keys():\n",
    "                if 'sourceId' in hv_keys[key1][key2][key3].keys(): \n",
    "                    hv_sid.loc[len(hv_sid)] = \" \".join([key1, key2, key3]), hv_keys[key1][key2][key3]['sourceId']\n",
    "                else:\n",
    "                    for key4 in hv_keys[key1][key2][key3].keys():\n",
    "                        if 'sourceId' in hv_keys[key1][key2][key3][key4].keys(): \n",
    "                            hv_sid.loc[len(hv_sid)] = \" \".join([key1, key2, key3, key4]), hv_keys[key1][key2][key3][key4]['sourceId']\n",
    "                        else:\n",
    "                            for key5 in hv_keys[key1][key2][key3][key4].keys():\n",
    "                                if 'sourceId' in hv_keys[key1][key2][key3][key4][key5].keys(): \n",
    "                                    hv_sid.loc[len(hv_sid)] = \" \".join([key1, key2, key3, key4, key5]), hv_keys[key1][key2][key3][key4][key5]['sourceId']\n",
    "                                else:\n",
    "                                    for key6 in hv_keys[key1][key2][key3][key4][key5].keys():\n",
    "                                        if 'sourceId' in hv_keys[key1][key2][key3][key4][key5][key6].keys(): \n",
    "                                            hv_sid.loc[len(hv_sid)] = \" \".join([key1, key2, key3, key4, key5,key6]), hv_keys[key1][key2][key3][key4][key5][key6]['sourceId']    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hv_sid = hv_sid.sort_values(['SOURCE_ID']).reset_index(drop=True)\n",
    "hv_sid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hv_prepare(cursor, sourceId, obs=None):\n",
    "    hv = pd.DataFrame(cursor.fetchall(), columns=cursor.column_names)\n",
    "    if(hv.empty):\n",
    "        hv['SOURCE_ID']=[]\n",
    "        return hv\n",
    "    hv = hv.sort_values('date').reset_index(drop=True)\n",
    "    hv['date'] = pd.to_datetime(hv['date'])\n",
    "    hv = hv.set_index('date')\n",
    "    hv = hv.reindex(pd.date_range(hv.index.min(), hv.index.max(), freq='D').to_period('D').to_timestamp(), \n",
    "                fill_value=0)\n",
    "    hv = hv.reindex(pd.date_range(hv.index.min().replace(day=1), (hv.index.max() + pd.tseries.offsets.MonthEnd(1)), freq='D').to_period('D').to_timestamp(), \n",
    "                fill_value=-1)\n",
    "    hv['count'] = hv['count'].astype(int)\n",
    "    hv['date'] = hv.index\n",
    "    hv = hv.reset_index(drop=True)\n",
    "    hv.loc[hv['count']<0, 'count'] = np.nan\n",
    "    hv['Year'] = hv['date'].dt.year.astype(str) + ' ' + hv['date'].dt.month_name()\n",
    "    hv['Day'] = hv['date'].dt.day.astype(str)\n",
    "    hv['SOURCE_ID'] = sourceId\n",
    "    hv['OBS'] = obs\n",
    "    return hv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def sql_query(sourceId, obs=None):\n",
    "    try:\n",
    "        connection = mysql.connector.connect(host='localhost',\n",
    "                                             database='hv',\n",
    "                                             user='hv_varun',\n",
    "                                             password='Helioviewer@2020')\n",
    "\n",
    "#         sql_select_Query = \"SELECT filepath, date, sourceid FROM data WHERE sourceId=%d LIMIT 20;\" %sourceId\n",
    "    #     sql_select_Query = \"SELECT sourceId, date_format(date, '%Y-%m-%d 00:00:00') as date, count(*) as count FROM data FORCE INDEX (date_index) WHERE sourceId=8 GROUP BY date_format(date, '%Y-%m-%d 00:00:00'), sourceId;\"\n",
    "        sql_select_Query = \"SELECT date_format(date, '%Y-%m-%d 00:00:00') as date, count(*) as count FROM data FORCE INDEX (date_index) WHERE sourceId={} GROUP BY date_format(date, '%Y-%m-%d 00:00:00');\".format(sourceId)\n",
    "    #     sql_select_Query = \"SELECT date_format(date, '%Y-%m-%d 00:00:00') as date, count(*) as count FROM data FORCE INDEX (date_index) GROUP BY date_format(date, '%Y-%m-%d 00:00:00');\"\n",
    "    #     sql_select_Query = \"SELECT count(*) FROM data WHERE filepath LIKE '/AIA/1600/%';\"\n",
    "    #    sql_select_Query = \"SELECT * FROM data LIMIT 20;\"\n",
    "        cursor = connection.cursor()\n",
    "        cursor.execute(sql_select_Query)\n",
    "        return hv_prepare(cursor, sourceId, obs)\n",
    "#         records = cursor.fetchall()\n",
    "    except Error as e:\n",
    "        return 'ERROR at SOURCE ID %s: %s'%(sourceId, e)\n",
    "        print(\"Error reading data from MySQL table\", e)\n",
    "    finally:\n",
    "        print('asdf')\n",
    "        if (connection.is_connected()):\n",
    "            connection.close()\n",
    "            cursor.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "par = Parallel(n_jobs=20)\n",
    "start_time=time.time()\n",
    "results = par(delayed(sql_query)(df['SOURCE_ID'], df['OBS']) for ind, df in hv_sid.iterrows())\n",
    "print(time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hv_obs = {}\n",
    "for i in range(len(hv_sid)):\n",
    "    if results[i].empty:\n",
    "        hv_sid = hv_sid.drop(index = hv_sid.index[hv_sid.index == i])\n",
    "        continue\n",
    "    hv_obs[hv_sid.iloc[i]['SOURCE_ID']] = results[i]\n",
    "hv_obs[np.random.choice(list(hv_obs.keys()))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for ind, df in hv_sid[16:17].iterrows():\n",
    "#     start_time=time.time()\n",
    "#     print('INFO:', ind, df['SOURCE_ID'])\n",
    "#     results = [sql_query(df['SOURCE_ID'])]\n",
    "#     print(time.time()-start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = hv_obs[sid].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['YYYY', 'MMMM']] = df['Year'].str.split(expand=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv_sid[hv_sid['OBS'].str.match('Hinode')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df['SOURCE_ID'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(df[df['count']>0]['count'].unique()), df[df['count']>0]['count'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for observatory in hv_keys.keys():\n",
    "    panels_obs=[]\n",
    "    for ind, df_obs in hv_sid[hv_sid['OBS'].str.match(observatory)].iterrows():\n",
    "        \n",
    "        df = hv_obs[df_obs['SOURCE_ID']].copy()\n",
    "        sid = df['SOURCE_ID'].unique()[0]\n",
    "        name = df['OBS'][0]\n",
    "        name_ = name.replace(\" \", \"_\")\n",
    "\n",
    "        years = np.array(df['Year'].unique()).astype(str)# hv_cov.index.values#.astype(str)\n",
    "        days = df['Day'].unique().astype(str) # np.arange(1,32).astype(str)\n",
    "\n",
    "        colors = bp.Viridis[256]# [\"#75968f\", \"#a5bab7\", \"#c9d9d3\", \"#e2e2e2\", \"#dfccce\", \"#ddb7b1\", \"#cc7878\", \"#933b41\", \"#550b1d\"]\n",
    "\n",
    "        TOOLS = \"hover,save,pan,box_zoom,reset,wheel_zoom\"\n",
    "\n",
    "        # output_file('AIA1600_coverage.html')\n",
    "        panels = []\n",
    "        for mapper_type, mapper, ticker in zip([\"log\", \"linear\"],\n",
    "                                               [LogColorMapper, LinearColorMapper],\n",
    "                                               [LogTicker, BasicTicker]):\n",
    "            p = figure(#x_axis_type='datetime',\n",
    "                       x_range=years, y_range=list(reversed(days)),\n",
    "                       x_axis_location=\"above\", sizing_mode='stretch_both',# width_policy='max', height_policy='max',#, plot_width=1400,\n",
    "                       x_axis_label=\"Year Month\", y_axis_label=\"Date\",\n",
    "                       tools=TOOLS,\n",
    "                       tooltips=[('Date', '@Year @Day'), ('#Data Files', '@count')])\n",
    "                       \n",
    "\n",
    "            total_days = (hv_obs[sid]['count']>=0).sum()\n",
    "            total_files = (hv_obs[sid]['count']).sum()\n",
    "            \n",
    "            p.add_layout(Title(text=\"%s Coverage\"%(name), text_font_size='14pt'), 'above')\n",
    "            p.add_layout(Title(text=\"Date Range: %s - %s\"%(df.dropna()['date'].min().strftime(\"%Y, %b %d\"), df.dropna()['date'].max().strftime(\"%Y, %b %d\"))), 'above')\n",
    "            p.add_layout(Title(text=\"Total Files: %d | Total Days: %d | Source ID: %d\"%(total_files, total_days, df['SOURCE_ID'].unique()[0]), text_font_style=\"italic\"), 'above')\n",
    "#             p.add_layout(Title(text=\"Total Days: %d\"%total_days, text_font_style=\"italic\"), 'above')\n",
    "#             p.add_layout(Title(text=\"Source ID: %d\"%df['SOURCE_ID'].unique()[0], text_font_style=\"italic\"), 'above')\n",
    "\n",
    "            # p.grid.grid_line_color = None\n",
    "            p.axis.axis_line_color = None\n",
    "            p.axis.major_tick_line_color = None\n",
    "            p.axis.major_label_text_font_size = \"7px\"\n",
    "            p.axis.major_label_standoff = 0\n",
    "            p.xaxis.major_label_orientation = np.pi / 3\n",
    "            p.xaxis.axis_label_text_font_size = \"12pt\"\n",
    "            p.yaxis.axis_label_text_font_size = \"12pt\"\n",
    "            p.xaxis.visible = True\n",
    "            p.xgrid.visible = True\n",
    "\n",
    "            p.xaxis.major_label_text_font_size = \"7pt\"\n",
    "            p.yaxis.major_label_text_font_size = \"8pt\"\n",
    "\n",
    "\n",
    "            p.rect(x=\"Year\", y=\"Day\", width=1, height=1,\n",
    "                   source=df,\n",
    "                   fill_color={'field': 'count', 'transform': mapper(palette=colors, low=0.1, high=np.nanmax(df['count']))},\n",
    "                   line_color=None)\n",
    "            \n",
    "            num_ticks=10\n",
    "            if (len(df[df['count']>0]['count'].unique()) <= 10):\n",
    "                num_ticks = len(df[df['count']>0]['count'].unique())\n",
    "            color_bar = ColorBar(color_mapper = mapper(palette=colors, low=0.1, high=np.nanmax(df['count'])), \n",
    "                                 major_label_text_font_size=\"10px\",\n",
    "                                 ticker=ticker(desired_num_ticks=num_ticks),\n",
    "                                 formatter=PrintfTickFormatter(format=\"%d\"),\n",
    "                                 label_standoff=6, border_line_color=None, location=(0, 0))\n",
    "            p.add_layout(color_bar, 'right')\n",
    "#             p.width_policy = 'fit'\n",
    "#             p.height_policy = 'fit'\n",
    "            panel = Panel(child=p, title=mapper_type)\n",
    "            panels.append(panel)\n",
    "        tabs = Tabs(tabs=panels)\n",
    "#         show(tabs)\n",
    "        panel_obs = Panel(child=tabs, title=name.replace(observatory+' ',''))\n",
    "        panels_obs.append(panel_obs)\n",
    "    tabs_obs = Tabs(tabs=panels_obs)\n",
    "#     show(tabs_obs)\n",
    "    save(tabs_obs, filename='./coverages/%s_coverage.html'%observatory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for observatory in hv_keys.keys():\n",
    "    panels_obs=[]\n",
    "    for ind, df_obs in hv_sid[hv_sid['OBS'].str.match(observatory)].iterrows():\n",
    "        \n",
    "        df = hv_obs[df_obs['SOURCE_ID']].copy()\n",
    "        sid = df['SOURCE_ID'].unique()[0]\n",
    "        name = df['OBS'][0]\n",
    "        name_ = name.replace(\" \", \"_\")\n",
    "\n",
    "        df = hv_obs[sid].copy()\n",
    "        df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "        name = df['OBS'].unique()[0]\n",
    "        name_ = name.replace(\" \", \"_\")\n",
    "\n",
    "        bin_size = bin_width(df['count'].max())# np.arange(0,count.max(),) 30#.astype(int)#100\n",
    "        btabs = interactive_histogram(df['count'], sid, name, bin_size)\n",
    "        counts = df['count']\n",
    "        title=name\n",
    "\n",
    "        arr_hist, edges, patches = plt.hist(counts, bins=np.arange(0, counts.max()+bin_size, bin_size))\n",
    "        cum_bin_size  = max(bin_size//10,1)\n",
    "        cum_hist, cum_edges, patches = plt.hist(counts, bins=np.arange(0,counts.max()+cum_bin_size, cum_bin_size), cumulative=True)\n",
    "        plt.close()\n",
    "\n",
    "        # Column data source\n",
    "        df_hist = pd.DataFrame({'count': arr_hist, 'left': edges[:-1], 'right': edges[1:]})\n",
    "        total = df_hist['count'].sum()\n",
    "        df_hist['f_count'] = ['%d' % count for count in df_hist['count']]\n",
    "        df_hist['f_percent'] = ['%.2f%%' %(count/total*100) for count in df_hist['count']]\n",
    "        df_hist['f_interval'] = ['[%d,%d) ' % (left, right) for left, right in zip(df_hist['left'], df_hist['right'])]\n",
    "        # column data source\n",
    "        hist_src = ColumnDataSource(df_hist)\n",
    "\n",
    "        #cumulative data\n",
    "        cumulative_data = cum_hist#np.cumsum(arr_hist)\n",
    "        x_bins = cum_edges[1:]#edges[1:]# np.arange(0, counts.max(), bin_size)[1:]\n",
    "        df_cum = pd.DataFrame({'count_cum': cumulative_data, 'x': x_bins})\n",
    "        cum_src = ColumnDataSource(df_cum)\n",
    "    #     df_hist['f_count'] = np.log10(df_hist['f_count']+1)\n",
    "        # Set up the figure same as before\n",
    "        panels = []\n",
    "\n",
    "        for axis_type in [\"log\",\"linear\"]:\n",
    "            p = figure(y_axis_type = axis_type,\n",
    "                       x_axis_label = 'No. of Data files', y_axis_label = 'Day count', \n",
    "                       background_fill_color=\"#fafafa\",\n",
    "                       y_range = (0.9, df_hist['count'].max() + df_hist['count'].max()//10))\n",
    "\n",
    "            # Add a quad glyph with source this time\n",
    "            p.quad(bottom=0.9, top='count', left='left', right='right', source=hist_src, fill_color='navy', alpha=0.5,\n",
    "                   hover_fill_color='navy', hover_fill_alpha=0.2, line_color='white', legend='Histogram')\n",
    "    #         p.y_range(Range1d(0.8,df_hist['count'].max()))\n",
    "            # Add style to the plot\n",
    "            p.title.align = 'center'\n",
    "            p.title.text_font_size = '18pt'\n",
    "            p.xaxis.axis_label_text_font_size = '12pt'\n",
    "            p.xaxis.major_label_text_font_size = '12pt'\n",
    "            p.yaxis.axis_label_text_font_size = '12pt'\n",
    "            p.yaxis.major_label_text_font_size = '12pt'\n",
    "    #         p.add_layout(Span(location=1800, dimension='height'))#, legend='Expected date file count'))\n",
    "            p.line(x=np.nanmean(counts), y=df_hist['count'], line_color=\"black\", line_dash='solid', line_width = 4, legend=\"Mean # Data files\")\n",
    "            p.line(x=np.nanmedian(counts), y=df_hist['count'], line_color = \"red\", line_dash='dashed', line_width=3, legend=\"Median # Data files\")\n",
    "            p.line(x=stats.mode(counts)[0][0], y=df_hist['count'], line_color = \"lightgreen\", line_dash = 'dashdot',line_width=2,legend=\"Mode # Data files\")\n",
    "\n",
    "            total_days = (counts>=0).sum()\n",
    "            total_files = counts.sum()\n",
    "            \n",
    "            p.add_layout(Title(text = \"Histogram for %s\"%title, text_font_size = \"16pt\", text_font_style=\"bold\"), place = 'above')\n",
    "            p.add_layout(Title(text=\"Date range: %s - %s\"%, 'above')\n",
    "            p.add_layout(Title(text=\"Total Files: %d | Total Days: %d | Source ID: %d\"%(total_files, total_days, sid), text_font_style=\"italic\"), 'above')\n",
    "#             p.add_layout(Title(text=\"Total Days: %d\"%total_days, text_font_style=\"italic\"), 'above')\n",
    "#             p.add_layout(Title(text=\"Source ID: %d\"%sid, text_font_style=\"italic\"), 'above')\n",
    "\n",
    "    #         p.legend.location = \"top_left\"\n",
    "    #         p.grid.grid_line_color=\"white\"\n",
    "\n",
    "    #         text_source = ColumnDataSource(dict(x=[x_bins.max()*3/4],y=[df_hist['count'].max()*3/4],text=['Total Day Count = \\n %d'%total]))\n",
    "    #         glyph = Text(x=\"x\", y=\"y\", text=\"text\", text_color=\"black\")\n",
    "    #         p.add_glyph(text_source, glyph)\n",
    "\n",
    "            # Add a hover tool referring to the formatted columns\n",
    "            hover = HoverTool(tooltips = [('#Data files', '@f_interval'),\n",
    "                                          ('Day count', '@f_count'),\n",
    "                                          ('Day count percentage', '@f_percent')],\n",
    "                              mode= 'vline')\n",
    "\n",
    "            # Add the hover tool to the graph\n",
    "            p.add_tools(hover)\n",
    "\n",
    "\n",
    "            p2 = figure(y_axis_type=axis_type,\n",
    "                       x_axis_label = 'No. of Data files', \n",
    "                       y_axis_label = 'Day count',\n",
    "                       background_fill_color=\"#fafafa\")\n",
    "                       \n",
    "\n",
    "            p2_line = p2.line(x='x', y='count_cum', line_color='#036564', line_width=3, source=cum_src, legend=\"Cumulative distribution\")\n",
    "    #         p2_circle = p2.circle(x='x', y='count_cum', line_color='#036564', line_width=5, source=cum_src, hover_line_alpha=0.5, legend=\"Cumulative distribution\" )\n",
    "            p2.add_layout(Title(text = \"Cumulative Distribution for %s\"%title, text_font_size = \"16pt\", text_font_style=\"bold\"), place = 'above')\n",
    "            p2.add_layout(Title(text=\"Date range: %s - %s\"%(df['date'].min().strftime('%Y, %b %d'),df['date'].max().strftime('%Y, %b %d'))), 'above')\n",
    "            p2.add_layout(Title(text=\"Total Files: %d | Total Days: %d | Source ID: %d\"%(total_files, total_days, sid), text_font_style=\"italic\"), 'above')\n",
    "#             p2.add_layout(Title(text=\"Total Days: %d\"%total_days, text_font_style=\"italic\"), 'above')\n",
    "#             p2.add_layout(Title(text=\"Source ID: %d\"%sid, text_font_style=\"italic\"), 'above')\n",
    "            \n",
    "            hover = HoverTool(line_policy='nearest', tooltips = [('#Data files', '<@x'), ('Cumulative Day count', '@count_cum')], mode='vline')\n",
    "\n",
    "    #         p2.add_layout(Span(location=1800, dimension='height'))#, legend='Expected date file count'))\n",
    "            p2.line(x=np.mean(counts), y=df_cum['count_cum'], line_color=\"black\", line_dash='solid', line_width = 4, legend=\"Mean # Data files\")\n",
    "            p2.line(x=np.median(counts), y=df_cum['count_cum'], line_color = \"red\", line_dash='dashed', line_width=3, legend=\"Median # Data files\")\n",
    "            p2.line(x=stats.mode(counts)[0][0], y=df_cum['count_cum'], line_color = \"lightgreen\", line_dash = 'dashdot',line_width=2,legend=\"Mode # Data files\")\n",
    "\n",
    "            # Add the hover tool to the graph\n",
    "            p2.add_tools(hover)\n",
    "            p2.title.align = 'center'\n",
    "            p2.title.text_font_size = '18pt'\n",
    "            p2.xaxis.axis_label_text_font_size = '12pt'\n",
    "            p2.xaxis.major_label_text_font_size = '12pt'\n",
    "            p2.yaxis.axis_label_text_font_size = '12pt'\n",
    "            p2.yaxis.major_label_text_font_size = '12pt'\n",
    "            p2.legend.location = \"bottom_right\"\n",
    "\n",
    "\n",
    "            grid = gridplot([[p, p2]], sizing_mode='stretch_both')# width_policy='max', height_policy='max')#,plot_width=1200, plot_height=1000, sizing_mode='scale_width')#, plot_width=250, plot_height=250)\n",
    "            panel = Panel(child=grid, title=axis_type)\n",
    "            panels.append(panel)\n",
    "        tabs = Tabs(tabs=panels)\n",
    "#         show(tabs)\n",
    "        panel_obs = Panel(child=tabs, title=name.replace(observatory+' ',''))\n",
    "        panels_obs.append(panel_obs)\n",
    "    tabs_obs = Tabs(tabs=panels_obs)\n",
    "#     show(tabs_obs)\n",
    "    save(tabs_obs, filename='./histograms/%s_histogram.html'%observatory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_width(m):\n",
    "    n = np.int(np.log10(m+1))\n",
    "    n = 10**(n-1)\n",
    "    q = np.ceil(m/(n*(36))).astype(int)\n",
    "    bw = max(q*n,1)\n",
    "    return bw#, m//n+1\n",
    "\n",
    "def interactive_histogram(counts, sid, title, bin_size=None):\n",
    "    \n",
    "    arr_hist, edges, patches = plt.hist(counts, bins=np.arange(0, counts.max()+bin_size, bin_size))\n",
    "    cum_bin_size  = max(bin_size//10,1)\n",
    "    cum_hist, cum_edges, patches = plt.hist(counts, bins=np.arange(0,counts.max()+cum_bin_size, cum_bin_size), cumulative=True)\n",
    "    plt.close()\n",
    "    \n",
    "    # Column data source\n",
    "    df_hist = pd.DataFrame({'count': arr_hist, 'left': edges[:-1], 'right': edges[1:]})\n",
    "    total = df_hist['count'].sum()\n",
    "    df_hist['f_count'] = ['%d' % count for count in df_hist['count']]\n",
    "    df_hist['f_percent'] = ['%.2f%%' %(count/total*100) for count in df_hist['count']]\n",
    "    df_hist['f_interval'] = ['[%d,%d) ' % (left, right) for left, right in zip(df_hist['left'], df_hist['right'])]\n",
    "    # column data source\n",
    "    hist_src = ColumnDataSource(df_hist)\n",
    "    \n",
    "    #cumulative data\n",
    "    cumulative_data = cum_hist#np.cumsum(arr_hist)\n",
    "    x_bins = cum_edges[1:]#edges[1:]# np.arange(0, counts.max(), bin_size)[1:]\n",
    "    df_cum = pd.DataFrame({'count_cum': cumulative_data, 'x': x_bins})\n",
    "    cum_src = ColumnDataSource(df_cum)\n",
    "#     df_hist['f_count'] = np.log10(df_hist['f_count']+1)\n",
    "    # Set up the figure same as before\n",
    "    panels = []\n",
    "    \n",
    "    for axis_type in [\"log\",\"linear\"]:\n",
    "        p = figure(y_axis_type = axis_type,\n",
    "                   title = \"Histogram for %s\"%title,\n",
    "                   x_axis_label = 'No. of Data files', \n",
    "                   y_axis_label = 'Day count',\n",
    "                   background_fill_color=\"#fafafa\",\n",
    "                   y_range = (0.9, df_hist['count'].max() + df_hist['count'].max()//10))\n",
    "        \n",
    "        # Add a quad glyph with source this time\n",
    "        p.quad(bottom=0.9, top='count', left='left', right='right', source=hist_src, fill_color='navy', alpha=0.5,\n",
    "               hover_fill_color='navy', hover_fill_alpha=0.2, line_color='white', legend='Histogram')\n",
    "#         p.y_range(Range1d(0.8,df_hist['count'].max()))\n",
    "        # Add style to the plot\n",
    "        p.title.align = 'center'\n",
    "        p.title.text_font_size = '18pt'\n",
    "        p.xaxis.axis_label_text_font_size = '12pt'\n",
    "        p.xaxis.major_label_text_font_size = '12pt'\n",
    "        p.yaxis.axis_label_text_font_size = '12pt'\n",
    "        p.yaxis.major_label_text_font_size = '12pt'\n",
    "#         p.add_layout(Span(location=1800, dimension='height'))#, legend='Expected date file count'))\n",
    "        p.line(x=np.mean(counts), y=df_hist['count'], line_color=\"black\", line_dash='solid', line_width = 4, legend=\"Mean # Data files\")\n",
    "        p.line(x=np.median(counts), y=df_hist['count'], line_color = \"red\", line_dash='dashed', line_width=3, legend=\"Median # Data files\")\n",
    "        p.line(x=stats.mode(counts)[0][0], y=df_hist['count'], line_color = \"lightgreen\", line_dash = 'dashdot',line_width=2,legend=\"Mode # Data files\")\n",
    "        \n",
    "        total_days = (counts>=0).sum()\n",
    "        total_files = counts.sum()\n",
    "        \n",
    "        p.add_layout(Title(text=\"Total Files: %d\"%total_files, text_font_style=\"italic\"), 'above')\n",
    "        p.add_layout(Title(text=\"Total Days: %d\"%total_days, text_font_style=\"italic\"), 'above')\n",
    "        p.add_layout(Title(text=\"Source ID: %d\"%sid, text_font_style=\"italic\"), 'above')\n",
    "        \n",
    "#         p.legend.location = \"top_left\"\n",
    "#         p.grid.grid_line_color=\"white\"\n",
    "        \n",
    "#         text_source = ColumnDataSource(dict(x=[x_bins.max()*3/4],y=[df_hist['count'].max()*3/4],text=['Total Day Count = \\n %d'%total]))\n",
    "#         glyph = Text(x=\"x\", y=\"y\", text=\"text\", text_color=\"black\")\n",
    "#         p.add_glyph(text_source, glyph)\n",
    "\n",
    "        # Add a hover tool referring to the formatted columns\n",
    "        hover = HoverTool(tooltips = [('#Data files', '@f_interval'),\n",
    "                                      ('Day count', '@f_count'),\n",
    "                                      ('Day count percentage', '@f_percent')],\n",
    "                          mode= 'vline')\n",
    "\n",
    "        # Add the hover tool to the graph\n",
    "        p.add_tools(hover)\n",
    "        \n",
    "        \n",
    "        p2 = figure(y_axis_type=axis_type,\n",
    "                   title = \"Cumulative distribution for %s\"%title,\n",
    "                   x_axis_label = 'No. of Data files', \n",
    "                   y_axis_label = 'Day count',\n",
    "                   background_fill_color=\"#fafafa\")\n",
    "        \n",
    "        p2_line = p2.line(x='x', y='count_cum', line_color='#036564', line_width=3, source=cum_src, legend=\"Cumulative distribution\")\n",
    "#         p2_circle = p2.circle(x='x', y='count_cum', line_color='#036564', line_width=5, source=cum_src, hover_line_alpha=0.5, legend=\"Cumulative distribution\" )\n",
    "        hover = HoverTool(line_policy='nearest', tooltips = [('#Data files', '<@x'), ('Cumulative Day count', '@count_cum')], mode='vline')\n",
    "        \n",
    "#         p2.add_layout(Span(location=1800, dimension='height'))#, legend='Expected date file count'))\n",
    "        p2.line(x=np.mean(counts), y=df_cum['count_cum'], line_color=\"black\", line_dash='solid', line_width = 4, legend=\"Mean # Data files\")\n",
    "        p2.line(x=np.median(counts), y=df_cum['count_cum'], line_color = \"red\", line_dash='dashed', line_width=3, legend=\"Median # Data files\")\n",
    "        p2.line(x=stats.mode(counts)[0][0], y=df_cum['count_cum'], line_color = \"lightgreen\", line_dash = 'dashdot',line_width=2,legend=\"Mode # Data files\")\n",
    "    \n",
    "        # Add the hover tool to the graph\n",
    "        p2.add_tools(hover)\n",
    "        p2.title.align = 'center'\n",
    "        p2.title.text_font_size = '18pt'\n",
    "        p2.xaxis.axis_label_text_font_size = '12pt'\n",
    "        p2.xaxis.major_label_text_font_size = '12pt'\n",
    "        p2.yaxis.axis_label_text_font_size = '12pt'\n",
    "        p2.yaxis.major_label_text_font_size = '12pt'\n",
    "        p2.legend.location = \"top_left\"\n",
    "        \n",
    "        \n",
    "        grid = gridplot([[p, p2]])#, plot_width=250, plot_height=250)\n",
    "        panel = Panel(child=grid, title=axis_type)\n",
    "        panels.append(panel)\n",
    "    \n",
    "    tabs = Tabs(tabs=panels)\n",
    "    return tabs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sid in hv_obs.keys()\n",
    "    df = hv_obs[sid].copy()\n",
    "    name = df['OBS'].unique()[0]\n",
    "    name_ = name.replace(\" \", \"_\")\n",
    "    \n",
    "    df = df.dropna().reset_index(drop=True)\n",
    "    f = open(\"./csv_files/%d_%s.csv\"%(sid, name_), mode='w')\n",
    "    f.write(\"# %s\\n\"%name)\n",
    "    f.write(\"# %d\\n\"%sid)\n",
    "    df.to_csv(f, columns=[\"date\", \"count\", \"SOURCE_ID\", \"OBS\"], index=False)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hv_obs[62].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hv_obs[40].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hv_obs[43].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for key in hv_obs.keys():\n",
    "    if len(hv_obs[key]) < 100: \n",
    "        plt.scatter(key, len(hv_obs[key].dropna().reset_index(drop=True)))\n",
    "        print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
