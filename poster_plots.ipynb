{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.pydata.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1001\">Loading BokehJS ...</span>\n",
       "    </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "(function(root) {\n",
       "  function now() {\n",
       "    return new Date();\n",
       "  }\n",
       "\n",
       "  var force = true;\n",
       "\n",
       "  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n",
       "    root._bokeh_onload_callbacks = [];\n",
       "    root._bokeh_is_loading = undefined;\n",
       "  }\n",
       "\n",
       "  var JS_MIME_TYPE = 'application/javascript';\n",
       "  var HTML_MIME_TYPE = 'text/html';\n",
       "  var EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n",
       "  var CLASS_NAME = 'output_bokeh rendered_html';\n",
       "\n",
       "  /**\n",
       "   * Render data to the DOM node\n",
       "   */\n",
       "  function render(props, node) {\n",
       "    var script = document.createElement(\"script\");\n",
       "    node.appendChild(script);\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when an output is cleared or removed\n",
       "   */\n",
       "  function handleClearOutput(event, handle) {\n",
       "    var cell = handle.cell;\n",
       "\n",
       "    var id = cell.output_area._bokeh_element_id;\n",
       "    var server_id = cell.output_area._bokeh_server_id;\n",
       "    // Clean up Bokeh references\n",
       "    if (id != null && id in Bokeh.index) {\n",
       "      Bokeh.index[id].model.document.clear();\n",
       "      delete Bokeh.index[id];\n",
       "    }\n",
       "\n",
       "    if (server_id !== undefined) {\n",
       "      // Clean up Bokeh references\n",
       "      var cmd = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n",
       "      cell.notebook.kernel.execute(cmd, {\n",
       "        iopub: {\n",
       "          output: function(msg) {\n",
       "            var id = msg.content.text.trim();\n",
       "            if (id in Bokeh.index) {\n",
       "              Bokeh.index[id].model.document.clear();\n",
       "              delete Bokeh.index[id];\n",
       "            }\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "      // Destroy server and session\n",
       "      var cmd = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n",
       "      cell.notebook.kernel.execute(cmd);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  /**\n",
       "   * Handle when a new output is added\n",
       "   */\n",
       "  function handleAddOutput(event, handle) {\n",
       "    var output_area = handle.output_area;\n",
       "    var output = handle.output;\n",
       "\n",
       "    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n",
       "    if ((output.output_type != \"display_data\") || (!output.data.hasOwnProperty(EXEC_MIME_TYPE))) {\n",
       "      return\n",
       "    }\n",
       "\n",
       "    var toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n",
       "\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n",
       "      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n",
       "      // store reference to embed id on output_area\n",
       "      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n",
       "    }\n",
       "    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n",
       "      var bk_div = document.createElement(\"div\");\n",
       "      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n",
       "      var script_attrs = bk_div.children[0].attributes;\n",
       "      for (var i = 0; i < script_attrs.length; i++) {\n",
       "        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n",
       "      }\n",
       "      // store reference to server id on output_area\n",
       "      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n",
       "    }\n",
       "  }\n",
       "\n",
       "  function register_renderer(events, OutputArea) {\n",
       "\n",
       "    function append_mime(data, metadata, element) {\n",
       "      // create a DOM node to render to\n",
       "      var toinsert = this.create_output_subarea(\n",
       "        metadata,\n",
       "        CLASS_NAME,\n",
       "        EXEC_MIME_TYPE\n",
       "      );\n",
       "      this.keyboard_manager.register_events(toinsert);\n",
       "      // Render to node\n",
       "      var props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n",
       "      render(props, toinsert[toinsert.length - 1]);\n",
       "      element.append(toinsert);\n",
       "      return toinsert\n",
       "    }\n",
       "\n",
       "    /* Handle when an output is cleared or removed */\n",
       "    events.on('clear_output.CodeCell', handleClearOutput);\n",
       "    events.on('delete.Cell', handleClearOutput);\n",
       "\n",
       "    /* Handle when a new output is added */\n",
       "    events.on('output_added.OutputArea', handleAddOutput);\n",
       "\n",
       "    /**\n",
       "     * Register the mime type and append_mime function with output_area\n",
       "     */\n",
       "    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n",
       "      /* Is output safe? */\n",
       "      safe: true,\n",
       "      /* Index of renderer in `output_area.display_order` */\n",
       "      index: 0\n",
       "    });\n",
       "  }\n",
       "\n",
       "  // register the mime type if in Jupyter Notebook environment and previously unregistered\n",
       "  if (root.Jupyter !== undefined) {\n",
       "    var events = require('base/js/events');\n",
       "    var OutputArea = require('notebook/js/outputarea').OutputArea;\n",
       "\n",
       "    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n",
       "      register_renderer(events, OutputArea);\n",
       "    }\n",
       "  }\n",
       "\n",
       "  \n",
       "  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n",
       "    root._bokeh_timeout = Date.now() + 5000;\n",
       "    root._bokeh_failed_load = false;\n",
       "  }\n",
       "\n",
       "  var NB_LOAD_WARNING = {'data': {'text/html':\n",
       "     \"<div style='background-color: #fdd'>\\n\"+\n",
       "     \"<p>\\n\"+\n",
       "     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n",
       "     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n",
       "     \"</p>\\n\"+\n",
       "     \"<ul>\\n\"+\n",
       "     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n",
       "     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n",
       "     \"</ul>\\n\"+\n",
       "     \"<code>\\n\"+\n",
       "     \"from bokeh.resources import INLINE\\n\"+\n",
       "     \"output_notebook(resources=INLINE)\\n\"+\n",
       "     \"</code>\\n\"+\n",
       "     \"</div>\"}};\n",
       "\n",
       "  function display_loaded() {\n",
       "    var el = document.getElementById(\"1001\");\n",
       "    if (el != null) {\n",
       "      el.textContent = \"BokehJS is loading...\";\n",
       "    }\n",
       "    if (root.Bokeh !== undefined) {\n",
       "      if (el != null) {\n",
       "        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n",
       "      }\n",
       "    } else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(display_loaded, 100)\n",
       "    }\n",
       "  }\n",
       "\n",
       "\n",
       "  function run_callbacks() {\n",
       "    try {\n",
       "      root._bokeh_onload_callbacks.forEach(function(callback) {\n",
       "        if (callback != null)\n",
       "          callback();\n",
       "      });\n",
       "    } finally {\n",
       "      delete root._bokeh_onload_callbacks\n",
       "    }\n",
       "    console.debug(\"Bokeh: all callbacks have finished\");\n",
       "  }\n",
       "\n",
       "  function load_libs(css_urls, js_urls, callback) {\n",
       "    if (css_urls == null) css_urls = [];\n",
       "    if (js_urls == null) js_urls = [];\n",
       "\n",
       "    root._bokeh_onload_callbacks.push(callback);\n",
       "    if (root._bokeh_is_loading > 0) {\n",
       "      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n",
       "      return null;\n",
       "    }\n",
       "    if (js_urls == null || js_urls.length === 0) {\n",
       "      run_callbacks();\n",
       "      return null;\n",
       "    }\n",
       "    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n",
       "    root._bokeh_is_loading = css_urls.length + js_urls.length;\n",
       "\n",
       "    function on_load() {\n",
       "      root._bokeh_is_loading--;\n",
       "      if (root._bokeh_is_loading === 0) {\n",
       "        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n",
       "        run_callbacks()\n",
       "      }\n",
       "    }\n",
       "\n",
       "    function on_error() {\n",
       "      console.error(\"failed to load \" + url);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < css_urls.length; i++) {\n",
       "      var url = css_urls[i];\n",
       "      const element = document.createElement(\"link\");\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.rel = \"stylesheet\";\n",
       "      element.type = \"text/css\";\n",
       "      element.href = url;\n",
       "      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n",
       "      document.body.appendChild(element);\n",
       "    }\n",
       "\n",
       "    for (var i = 0; i < js_urls.length; i++) {\n",
       "      var url = js_urls[i];\n",
       "      var element = document.createElement('script');\n",
       "      element.onload = on_load;\n",
       "      element.onerror = on_error;\n",
       "      element.async = false;\n",
       "      element.src = url;\n",
       "      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n",
       "      document.head.appendChild(element);\n",
       "    }\n",
       "  };var element = document.getElementById(\"1001\");\n",
       "  if (element == null) {\n",
       "    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n",
       "    return false;\n",
       "  }\n",
       "\n",
       "  function inject_raw_css(css) {\n",
       "    const element = document.createElement(\"style\");\n",
       "    element.appendChild(document.createTextNode(css));\n",
       "    document.body.appendChild(element);\n",
       "  }\n",
       "\n",
       "  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.2.0.min.js\"];\n",
       "  var css_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.2.0.min.css\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.2.0.min.css\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.2.0.min.css\"];\n",
       "\n",
       "  var inline_js = [\n",
       "    function(Bokeh) {\n",
       "      Bokeh.set_log_level(\"info\");\n",
       "    },\n",
       "    \n",
       "    function(Bokeh) {\n",
       "      \n",
       "    },\n",
       "    function(Bokeh) {} // ensure no trailing comma for IE\n",
       "  ];\n",
       "\n",
       "  function run_inline_js() {\n",
       "    \n",
       "    if ((root.Bokeh !== undefined) || (force === true)) {\n",
       "      for (var i = 0; i < inline_js.length; i++) {\n",
       "        inline_js[i].call(root, root.Bokeh);\n",
       "      }if (force === true) {\n",
       "        display_loaded();\n",
       "      }} else if (Date.now() < root._bokeh_timeout) {\n",
       "      setTimeout(run_inline_js, 100);\n",
       "    } else if (!root._bokeh_failed_load) {\n",
       "      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n",
       "      root._bokeh_failed_load = true;\n",
       "    } else if (force !== true) {\n",
       "      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n",
       "      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n",
       "    }\n",
       "\n",
       "  }\n",
       "\n",
       "  if (root._bokeh_is_loading === 0) {\n",
       "    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n",
       "    run_inline_js();\n",
       "  } else {\n",
       "    load_libs(css_urls, js_urls, function() {\n",
       "      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n",
       "      run_inline_js();\n",
       "    });\n",
       "  }\n",
       "}(window));"
      ],
      "application/vnd.bokehjs_load.v0+json": "\n(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  var force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\n  \n\n  \n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  var NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    var el = document.getElementById(\"1001\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error() {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (var i = 0; i < css_urls.length; i++) {\n      var url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (var i = 0; i < js_urls.length; i++) {\n      var url = js_urls[i];\n      var element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error;\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };var element = document.getElementById(\"1001\");\n  if (element == null) {\n    console.error(\"Bokeh: ERROR: autoload.js configured with elementid '1001' but no matching script tag was found. \")\n    return false;\n  }\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  var js_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.2.0.min.js\", \"https://cdn.pydata.org/bokeh/release/bokeh-gl-1.2.0.min.js\"];\n  var css_urls = [\"https://cdn.pydata.org/bokeh/release/bokeh-1.2.0.min.css\", \"https://cdn.pydata.org/bokeh/release/bokeh-widgets-1.2.0.min.css\", \"https://cdn.pydata.org/bokeh/release/bokeh-tables-1.2.0.min.css\"];\n\n  var inline_js = [\n    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\n    \n    function(Bokeh) {\n      \n    },\n    function(Bokeh) {} // ensure no trailing comma for IE\n  ];\n\n  function run_inline_js() {\n    \n    if ((root.Bokeh !== undefined) || (force === true)) {\n      for (var i = 0; i < inline_js.length; i++) {\n        inline_js[i].call(root, root.Bokeh);\n      }if (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      var cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "import time\n",
    "import datetime\n",
    "import pandas as pd\n",
    "\n",
    "import mysql.connector\n",
    "from mysql.connector import Error\n",
    "\n",
    "from bokeh.plotting import *\n",
    "from bokeh.layouts import gridplot\n",
    "from bokeh.models import *# Span, ColumnDataSource, LogColorMapper, ColorMapper, LogTicker, ColorBar, BasicTicker, LinearColorMapper, PrintfTickFormatter, HoverTool, CategoricalColorMapper, Range1d, Title\n",
    "from bokeh.models.widgets import Tabs, Panel\n",
    "from bokeh.io import show, output_notebook, reset_output\n",
    "output_notebook()\n",
    "from bokeh.models.glyphs import Text\n",
    "import bokeh.palettes as bp\n",
    "from bokeh.transform import factor_cmap\n",
    "\n",
    "# import hail as hl\n",
    "import json\n",
    "import urllib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import (MultipleLocator, FormatStrFormatter, AutoMinorLocator)\n",
    "\n",
    "from pathlib import Path\n",
    "from joblib import Parallel, delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hv_setup import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie length histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bin_width(m):\n",
    "    n = np.int(np.log10(m+1))\n",
    "    n = 10**(n-1)\n",
    "    q = np.ceil(m/(n*(36))).astype(int)\n",
    "    bw = max(q*n,1)\n",
    "    return bw#, m//n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hv={}\n",
    "# query=\"SELECT dataSourceString FROM movies\"\n",
    "# query = \"SELECT DATE_FORMAT(reqStartDate, '%1980-%m-%d %H:%i:%S') AS reqStartDate, timestamp, reqEndDate, startDate, endDate, dataSourceString FROM movies\"\n",
    "# date_format(reqStartDate, '%Y-%m-%d %H:%i:%s') AS REQ_START, date_format(reqEndDate, '%Y-%m-%d %H:%i:%s')\n",
    "query = \"SELECT reqStartDate, reqEndDate, dataSourceString, eventSourceString, numFrames, frameRate, maxFrames, timestamp as date, TIMESTAMPDIFF(second, reqStartDate, reqEndDate) AS reqDuration, TIMESTAMPDIFF(second, startDate, endDate) AS genDuration FROM movies WHERE reqEndDate!='None' AND reqStartDate!='None' AND startDate!='None' AND endDate!='None';\"\n",
    "# query = \"SELECT ROUND(TIMESTAMPDIFF(second, reqStartDate, reqEndDate)/60/60/24, 3) AS reqDuration, ROUND(TIMESTAMPDIFF(second, startDate, endDate)/60/60/24, 3) AS genDuration FROM movies;\"\n",
    "hv['movies'] = sql_query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = hv['movies'].copy()\n",
    "\n",
    "df['reqDuration'] = pd.to_timedelta(df['reqDuration'], unit='s')/pd.Timedelta(days=1)\n",
    "df['reqDuration'].loc[df['reqDuration']>30] = np.nan\n",
    "df['genDuration'] = pd.to_timedelta((df['numFrames']/df['frameRate']), unit='s')/pd.Timedelta(seconds=1)\n",
    "outlier_count = df['genDuration'].loc[df['genDuration']>300]\n",
    "outlier_date = df['date'].loc[df['genDuration']>300].dt.strftime(\"%b %d %Y, %H:%M:%S\").values[0]\n",
    "df['genDuration'].loc[df['genDuration']>300] = np.nan\n",
    "df.sort_values('genDuration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "key='movies'\n",
    "# bin_size = 100# 0.5*24*60*60# np.arange(0,count.max(),) 30#.astype(int)#100\n",
    "panels_pov=[]\n",
    "for pov, ref, bin_size, unit in zip(['reqDuration','genDuration'], \n",
    "                                    ['requested','generated'],\n",
    "                                    [0.5, 10],\n",
    "                                    ['days','seconds']):\n",
    "\n",
    "    counts = df[pov]\n",
    "\n",
    "    arr_hist, edges = np.histogram(counts, bins=np.arange(0, counts.max()+bin_size, bin_size))\n",
    "    cum_bin_size = max(bin_size//10, 1)\n",
    "    cum_hist, cum_edges, patches = plt.hist(counts, bins=np.arange(0,counts.max()+cum_bin_size, cum_bin_size), cumulative=True)\n",
    "    plt.close()\n",
    "\n",
    "    # Column data source\n",
    "    df_hist = pd.DataFrame({'count': arr_hist, 'left': edges[:-1], 'right': edges[1:]})\n",
    "    total = df_hist['count'].sum()\n",
    "    df_hist['f_count'] = ['%d' % count for count in df_hist['count']]\n",
    "    df_hist['f_percent'] = ['%.3f%%' %(count/total*100) for count in df_hist['count']]\n",
    "    df_hist['f_interval'] = ['[%.1f %s,%.1f %s)' % (left, unit, right, unit) for left, right in zip(df_hist['left'], df_hist['right'])]\n",
    "    hist_src = ColumnDataSource(df_hist)\n",
    "\n",
    "    #cumulative data\n",
    "    cumulative_data = cum_hist#np.cumsum(arr_hist)\n",
    "    x_bins = cum_edges[1:]#edges[1:]# np.arange(0, counts.max(), bin_size)[1:]\n",
    "    df_cum = pd.DataFrame({'count_cum': cumulative_data, 'x': x_bins})\n",
    "    df_cum['f_percent'] = ['%.3f%%' %(count/total*100) for count in df_cum['count_cum']]\n",
    "    cum_src = ColumnDataSource(df_cum)\n",
    "\n",
    "    panels = []\n",
    "    for axis_type in [\"log\",\"linear\"]:\n",
    "        p = figure(y_axis_type = axis_type,\n",
    "                   x_axis_label = 'Length of %s (%s)'%(key, unit), y_axis_label = 'Movie count', \n",
    "                   background_fill_color=\"#fafafa\",\n",
    "                   y_range = (0.5, df_hist['count'].max() + df_hist['count'].max()//10)\n",
    "                  )\n",
    "\n",
    "        # Add a quad glyph with source this time\n",
    "        p_hist = p.quad(bottom=0.5, top='count', left='left', right='right', source=hist_src, fill_color='navy', alpha=0.5,\n",
    "               hover_fill_color='navy', hover_fill_alpha=0.2, line_color='white', legend='Histogram')\n",
    "        # Add style to the plot\n",
    "        p.title.align = 'center'\n",
    "        p.title.text_font_size = '18pt'\n",
    "        p.xaxis.axis_label_text_font_size = '12pt'\n",
    "        p.xaxis.major_label_text_font_size = '12pt'\n",
    "        p.yaxis.axis_label_text_font_size = '12pt'\n",
    "        p.yaxis.major_label_text_font_size = '12pt'\n",
    "#         p.yaxis[0].formatter = PrintfTickFormatter(format=\"%f\")\n",
    "        p.yaxis[0].formatter = NumeralTickFormatter(format='0,0')\n",
    "        \n",
    "    #         p.add_layout(Span(location=1800, dimension='height'))#, legend='Expected date file count'))\n",
    "        df_stats = pd.DataFrame({'height': np.linspace(min(df_hist['count'].min(),0.5),df_hist['count'].max(),2),\n",
    "                                 'mean':np.nanmean(counts), 'median': np.nanmedian(counts), 'mode':stats.mode(counts)[0][0]})\n",
    "        p.line(x='mean', y='height', line_color=\"black\", line_dash='solid', line_width = 4, legend=\"Mean (%.2f %s)\"%(df_stats['mean'][0], unit), source=df_stats)\n",
    "        p.line(x='median', y='height', line_color = \"red\", line_dash='dashed', line_width=3, legend=\"Median (%.2f %s)\"%(df_stats['median'][0],unit), source=df_stats)\n",
    "        p.line(x='mode', y='height', line_color = \"lightgreen\", line_dash = 'dashdot',line_width=2,legend=\"Mode (%.2f %s)\"%(df_stats['mode'][0],unit), source=df_stats)\n",
    "\n",
    "        total_days = len(counts)\n",
    "        total_files = counts.sum()\n",
    "\n",
    "        p.add_layout(Title(text = \"Histogram for length of %s %s\"%(key, ref), text_font_size = \"16pt\", text_font_style=\"bold\"), \n",
    "                     place = 'above')\n",
    "        p.add_layout(Title(text=\"%s during: %s - %s\"%(ref, df['date'].min().strftime('%Y, %b %d'),df['date'].max().strftime('%Y, %b %d'))), \n",
    "                     place = 'above')\n",
    "        if(ref=='generated'):\n",
    "            p.add_layout(Title(text=\"(Movie of length %d seconds %s on %s was discarded)\"%(outlier_count, ref, outlier_date), text_font_style=\"italic\"), \n",
    "                          place = 'above')\n",
    "        p.add_layout(Title(text=\"Total length of {} {} ({}): {:,.2f} | Total Movies: {:,} \".format(key, ref, unit, total_files, total_days), text_font_style=\"italic\"), \n",
    "                     place = 'above')\n",
    "\n",
    "        p.legend.location = \"top_right\"\n",
    "        p.grid.grid_line_color=\"white\"\n",
    "\n",
    "        # Add a hover tool referring to the formatted columns\n",
    "        hover = HoverTool(tooltips = [('Length of %s %s'%(key, ref), '@f_interval'),\n",
    "                                      ('Movie count', '@f_count{0,0}'),\n",
    "                                      ('Movie count percentage', '@f_percent')],\n",
    "#                           formatters={'f_count'      : 'printf', # use 'datetime' formatter for 'date' field\n",
    "#                         'count' : 'int',   # use 'printf' formatter for 'adj close' field\n",
    "#                                           use default 'numeral' formatter for other fields\n",
    "#                                      },\n",
    "                          mode= 'vline')\n",
    "\n",
    "        # Add the hover tool to the graph\n",
    "        p.add_tools(hover)\n",
    "        p2 = figure(y_axis_type=axis_type,\n",
    "                           x_axis_label = 'Length of %s (%s)'%(key, unit), \n",
    "                           y_axis_label = 'Movie count',\n",
    "                           background_fill_color=\"#fafafa\")\n",
    "\n",
    "\n",
    "        p2_line = p2.line(x='x', y='count_cum', line_color='#036564', line_width=3, source=cum_src, legend=\"Cumulative distribution\")\n",
    "    #         p2_circle = p2.circle(x='x', y='count_cum', line_color='#036564', line_width=5, source=cum_src, hover_line_alpha=0.5, legend=\"Cumulative distribution\" )\n",
    "        p2.add_layout(Title(text = \"Cumulative distribution for length of %s %s\"%(key, ref), text_font_size = \"16pt\", text_font_style=\"bold\"), \n",
    "                      place = 'above')\n",
    "        p2.add_layout(Title(text=\"%s during: %s - %s\"%(ref, df['date'].min().strftime('%Y, %b %d'),df['date'].max().strftime('%Y, %b %d'))), \n",
    "                      place = 'above')\n",
    "        if(ref=='generated'):\n",
    "            p2.add_layout(Title(text=\"(Movie of length %d seconds %s on %s was discarded)\"%(outlier_count, ref, outlier_date), text_font_style=\"italic\"), \n",
    "                          place = 'above')\n",
    "        p2.add_layout(Title(text=\"Total length of {} {} ({}): {:,.2f} | Total Movies: {:,} \".format(key, ref, unit, total_files, total_days), text_font_style=\"italic\"), \n",
    "                      place= 'above')\n",
    "\n",
    "        hover = HoverTool(line_policy='nearest', \n",
    "                          tooltips = [('Length of %s %s'%(key, ref), '<@x{0.2f} %s'%unit), \n",
    "                                      ('Percentage of %s %s'%(key,ref), '<@f_percent'),\n",
    "                                      ('Cumulative Day count', '@count_cum{0,0}')],\n",
    "                          mode='vline')\n",
    "\n",
    "        df_cumstats = pd.DataFrame({'height': np.linspace(df_cum['count_cum'].min(),df_cum['count_cum'].max(),2),\n",
    "                                 'mean':np.nanmean(counts), 'median': np.nanmedian(counts), 'mode':stats.mode(counts)[0][0]})\n",
    "        p2.line(x='mean', y='height', line_color=\"black\", line_dash='solid', line_width = 4, legend=\"Mean (%.2f %s)\"%(df_cumstats['mean'][0], unit), source=df_cumstats)\n",
    "        p2.line(x='median', y='height', line_color = \"red\", line_dash='dashed', line_width=3, legend=\"Median (%.2f %s)\"%(df_cumstats['median'][0], unit), source=df_cumstats)\n",
    "        p2.line(x='mode', y='height', line_color = \"lightgreen\", line_dash = 'dashdot',line_width=2,legend=\"Mode (%.2f %s)\"%(df_cumstats['mode'][0], unit), source=df_cumstats)\n",
    "#         p2.add_layout(Span(location=10, dimension='height', legend='Expected date file count'))\n",
    "        \n",
    "        # Add the hover tool to the graph\n",
    "        p2.add_tools(hover)\n",
    "        p2.title.align = 'center'\n",
    "        p2.title.text_font_size = '18pt'\n",
    "        p2.xaxis.axis_label_text_font_size = '12pt'\n",
    "        p2.xaxis.major_label_text_font_size = '12pt'\n",
    "        p2.yaxis.axis_label_text_font_size = '12pt'\n",
    "        p2.yaxis.major_label_text_font_size = '12pt'\n",
    "        p2.legend.location = \"bottom_right\"\n",
    "#         p2.yaxis[0].formatter = PrintfTickFormatter(format=\"0,0%f\")\n",
    "        p2.yaxis[0].formatter = NumeralTickFormatter(format='0,0')\n",
    "        \n",
    "\n",
    "        grid = gridplot([[p, p2]], sizing_mode='stretch_both')# width_policy='max', height_policy='max')#,plot_width=1200, plot_height=1000, sizing_mode='scale_width')#, plot_width=250, plot_height=250)\n",
    "        panel = Panel(child=grid, title=axis_type)\n",
    "        panels.append(panel)\n",
    "    tabs = Tabs(tabs=panels)\n",
    "    panel_pov = Panel(child=tabs, title=ref)\n",
    "    panels_pov.append(panel_pov)\n",
    "\n",
    "tabs_pov = Tabs(tabs=panels_pov)\n",
    "show(tabs_pov)\n",
    "save(tabs_pov, filename='./%s/histogram_length.html'%key, title='Histogram for length of Helioviewer %s'%key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hv={}\n",
    "hv['movies'] = sql_query(\"SELECT date_format(timestamp, '%Y-%m-%d 00:00:00') as date, count(*) as count FROM movies GROUP BY date_format(timestamp, '%Y-%m-%d 00:00:00');\")\n",
    "hv['screenshots'] = sql_query(\"SELECT date_format(timestamp, '%Y-%m-%d 00:00:00') as date, count(*) as count FROM screenshots GROUP BY date_format(timestamp, '%Y-%m-%d 00:00:00');\")\n",
    "\n",
    "hv['movies']['date'] = pd.to_datetime(hv['movies']['date'])\n",
    "hv['movies'] = hv['movies'].sort_values(['date']).reset_index(drop=True)\n",
    "\n",
    "hv['screenshots']['date'] = pd.to_datetime(hv['screenshots']['date'])\n",
    "hv['screenshots'] = hv['screenshots'].sort_values(['date']).reset_index(drop=True)\n",
    "hv['screenshots']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def service_pause(p, df):\n",
    "#     box = BoxAnnotation(left=pd.Timestamp('2012/01/01'), right=pd.Timestamp('2013/01/01'), fill_alpha=0.1, fill_color='red', legend='HV')\n",
    "    p.harea(y=range(0, df['count'].max()), x1=pd.Timestamp('2011/06/07'), x2=pd.Timestamp('2011/06/08'), fill_color='red', fill_alpha=1, legend= \"failed eruption (2011/06/07)\")\n",
    "    p.harea(y=range(0, df['count'].max()), x1=pd.Timestamp('2013/11/28'), x2=pd.Timestamp('2013/11/29'), fill_color='purple', fill_alpha=1, legend= \"Comet ISON (2013/11/28)\")\n",
    "    p.harea(y=range(0, df['count'].max()), x1=pd.Timestamp('2017/09/06'), x2=pd.Timestamp('2017/09/10'), fill_color='purple', fill_alpha=1, legend= \"large flares (2017/9/06-09)\")\n",
    "    p.harea(y=range(0, df['count'].max()), x1=pd.Timestamp('2011/08/11'), x2=pd.Timestamp('2011/09/18'), fill_color='gray', fill_alpha=0.3, legend= \"GSFC server repair (2011/08/11 - 2011/09/18)\")\n",
    "    p.harea(y=range(0, df['count'].max()), x1=pd.Timestamp('2015/02/04'), x2=pd.Timestamp('2015/09/23'), fill_color='red', fill_alpha=0.1, legend= \"GSFC server down (2015/02/04 - 2015/09/23)\")\n",
    "    p.harea(y=range(0, df['count'].max()), x1=pd.Timestamp('2013/10/01'), x2=pd.Timestamp('2013/10/16'), fill_color='green', fill_alpha=0.3, legend= \"U.S. Fed. Gov. shutdown (2013/10/01 - 2013/10/16)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for key in hv.keys():\n",
    "    df = hv[key].copy()\n",
    "    df = df.set_index('date')\n",
    "    df = df.reindex(pd.date_range(df.index.min(), df.index.max(), freq='D').to_period('D').to_timestamp(),\n",
    "                                  fill_value=0)\n",
    "    df['date'] = df.index\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "    TOOLS = \"save, pan, box_zoom, reset, wheel_zoom\"\n",
    "\n",
    "    df_src = ColumnDataSource(df)\n",
    "\n",
    "    p = figure(plot_height=250, x_axis_type=\"datetime\", \n",
    "               tools=TOOLS,\n",
    "               sizing_mode=\"scale_width\", min_border_left = 0)\n",
    "    \n",
    "#     p.min_border_left = 0\n",
    "#     p.min_border_right = 0\n",
    "#     p.min_border_top = 0\n",
    "\n",
    "    p.add_layout(Title(text = \"Number of %s generated every day\"%key, text_font_size = \"16pt\", text_font_style=\"bold\"), \n",
    "                 place = 'above')\n",
    "    p.add_layout(Title(text = \"Date Range: %s - %s\"%(df['date'].min().strftime('%Y, %b %d'),df['date'].max().strftime('%Y, %b %d'))), \n",
    "                 place = 'above')\n",
    "    p.add_layout(Title(text=\"Total {} generated: {:,} | Total Days: {:,} \".format(key,df['count'].sum(), len(df)), text_font_style=\"italic\"), \n",
    "                 place = 'above')\n",
    "\n",
    "    p.background_fill_color=\"#f5f5f5\"\n",
    "    p.grid.grid_line_color=\"white\"\n",
    "    p.xaxis.axis_label = 'Date'\n",
    "    p.yaxis.axis_label = 'No. of %s'%key\n",
    "    p.axis.axis_line_color = None\n",
    "    p.x_range.range_padding = 0.02\n",
    "    p.x_range.range_padding = 0.02\n",
    "    p.y_range.range_padding = 0.02\n",
    "    p.yaxis[0].formatter = NumeralTickFormatter(format='0,0')\n",
    "#     p.xaxis[0].formatter = DatetimeTickFormatter(days=[\"%b %d, %Y %H\"])\n",
    "    p.xaxis.ticker = YearsTicker(desired_num_ticks=10, num_minor_ticks=12)\n",
    "#     p.xaxis[0].ticker.desired_num_ticks = 10\n",
    "    \n",
    "    p.line(x='date', y='count', line_width=2, color='#ebbd5b', source=df_src)\n",
    "\n",
    "    p.add_tools(HoverTool(\n",
    "        tooltips=[( 'date',   '@date{%F}'),\n",
    "    #               ( 'close',  '$@{adj close}{%0.2f}' ), # use @{ } for field names with spaces\n",
    "                  ( 'count', '@count{0,0}'),#{0.00 a}'      ),\n",
    "                 ],\n",
    "        formatters={'date'      : 'datetime', # use 'datetime' formatter for 'date' field\n",
    "    #                 'count' : 'int',   # use 'printf' formatter for 'adj close' field\n",
    "                                      # use default 'numeral' formatter for other fields\n",
    "                   },\n",
    "    #     display a tooltip whenever the cursor is vertically in line with a glyph\n",
    "    #     mode='vline'\n",
    "    ))\n",
    "    df_stats = pd.DataFrame({'height': pd.date_range(df['date'].min(),df['date'].max(),periods=2),\n",
    "                                 'mean':np.nanmean(df['count']), 'median': np.nanmedian(df['count']), 'mode':stats.mode(df['count'])[0][0]})\n",
    "    p.line(y='mean', x='height', line_color=\"black\", line_dash='dotdash', line_width = 2, legend=\"Mean (%.2f)\"%(df_stats['mean'][0]), source=df_stats)\n",
    "    p.line(y='median', x='height', line_color = \"red\", line_dash='dashed', line_width=2, legend=\"Median (%.2f)\"%(df_stats['median'][0]), source=df_stats)\n",
    "    service_pause(p, df)\n",
    "    show(p)\n",
    "    save(p, filename='./%s/time_series.html'%key, title='Helioviewer %s generated every day'%key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Histogram of media per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def bin_width(m):\n",
    "    n = np.int(np.log10(m+1))\n",
    "    n = 10**(n-1)\n",
    "    q = np.ceil(m/(n*(36))).astype(int)\n",
    "    bw = max(q*n,1)\n",
    "    return bw#, m//n+1\n",
    "\n",
    "for key in hv.keys():\n",
    "    df = hv[key].copy()\n",
    "    df = df.set_index('date')\n",
    "    df = df.reindex(pd.date_range(df.index.min(), df.index.max(), freq='D').to_period('D').to_timestamp(),\n",
    "                                  fill_value=0)\n",
    "    df['date'] = df.index\n",
    "    df = df.reset_index(drop=True)\n",
    "\n",
    "    bin_size = bin_width(df['count'].max())# np.arange(0,count.max(),) 30#.astype(int)#100\n",
    "    counts = df['count']\n",
    "\n",
    "    arr_hist, edges = np.histogram(counts, bins=np.arange(0, counts.max()+bin_size, bin_size))\n",
    "    cum_bin_size  = max(bin_size//10,1)\n",
    "    cum_hist, cum_edges, patches = plt.hist(counts, bins=np.arange(0,counts.max()+cum_bin_size, cum_bin_size), cumulative=True)\n",
    "    plt.close()\n",
    "\n",
    "    # Column data source\n",
    "    df_hist = pd.DataFrame({'count': arr_hist, 'left': edges[:-1], 'right': edges[1:]})\n",
    "    total = df_hist['count'].sum()\n",
    "    df_hist['f_count'] = ['%d' % count for count in df_hist['count']]\n",
    "    df_hist['f_percent'] = ['%.2f%%' %(count/total*100) for count in df_hist['count']]\n",
    "    df_hist['f_interval'] = ['[{:,.0f} - {:,.0f})'.format(left, right) for left, right in zip(df_hist['left'], df_hist['right'])]\n",
    "    hist_src = ColumnDataSource(df_hist)\n",
    "\n",
    "    #cumulative data\n",
    "    cumulative_data = cum_hist#np.cumsum(arr_hist)\n",
    "    x_bins = cum_edges[1:]#edges[1:]# np.arange(0, counts.max(), bin_size)[1:]\n",
    "    df_cum = pd.DataFrame({'count_cum': cumulative_data, 'x': x_bins})\n",
    "    df_cum['f_percent'] = ['%.2f%%' %(count/total*100) for count in df_cum['count_cum']]\n",
    "    cum_src = ColumnDataSource(df_cum)\n",
    "\n",
    "    panels = []\n",
    "    for axis_type in [\"log\",\"linear\"]:\n",
    "        p = figure(y_axis_type = axis_type,\n",
    "                   x_axis_label = 'No. of %s'%key, y_axis_label = 'Day count', \n",
    "                   background_fill_color=\"#fafafa\",\n",
    "                   y_range = (0.9, df_hist['count'].max() + df_hist['count'].max()//10))\n",
    "\n",
    "        # Add a quad glyph with source this time\n",
    "        p.quad(bottom=0.9, top='count', left='left', right='right', source=hist_src, fill_color='navy', alpha=0.5,\n",
    "               hover_fill_color='navy', hover_fill_alpha=0.2, line_color='white', legend='Histogram')\n",
    "    #         p.y_range(Range1d(0.8,df_hist['count'].max()))\n",
    "        # Add style to the plot\n",
    "        p.title.align = 'center'\n",
    "        p.title.text_font_size = '18pt'\n",
    "        p.xaxis.axis_label_text_font_size = '12pt'\n",
    "        p.xaxis.major_label_text_font_size = '12pt'\n",
    "        p.yaxis.axis_label_text_font_size = '12pt'\n",
    "        p.yaxis.major_label_text_font_size = '12pt'\n",
    "        p.yaxis[0].formatter = NumeralTickFormatter(format='0,0')\n",
    "        p.xaxis[0].formatter = NumeralTickFormatter(format='0,0')\n",
    "        \n",
    "        df_stats = pd.DataFrame({'height': np.linspace(0.5, df_hist['count'].max(), 2),\n",
    "                                 'mean':np.nanmean(counts), 'median': np.nanmedian(counts), 'mode':stats.mode(counts)[0][0]})\n",
    "        p.line(x='mean', y='height', line_color=\"black\", line_dash='solid', line_width = 4, legend=\"Mean (%.2f)\"%(df_stats['mean'][0]), source=df_stats)\n",
    "        p.line(x='median', y='height', line_color = \"red\", line_dash='dashed', line_width=3, legend=\"Median (%.2f)\"%(df_stats['median'][0]), source=df_stats)\n",
    "#         p.line(x='mode', y='height', line_color = \"lightgreen\", line_dash = 'dashdot',line_width=2,legend=\"Mode (%.2f)\"%(df_stats['mode'][0]), source=df_stats)\n",
    "        \n",
    "        total_days = (counts>=0).sum()\n",
    "        total_files = counts.sum()\n",
    "\n",
    "        p.add_layout(Title(text = \"Histogram for %s generated per day\"%key, text_font_size = \"16pt\", text_font_style=\"bold\"), place = 'above')\n",
    "        p.add_layout(Title(text=\"Date range: %s - %s\"%(df['date'].min().strftime('%Y, %b %d'),df['date'].max().strftime('%Y, %b %d'))), 'above')\n",
    "        p.add_layout(Title(text=\"Total {} generated: {:,} | Total Days: {:,} \".format(key, total_files, total_days), text_font_style=\"italic\"), 'above')\n",
    "\n",
    "        p.legend.location = \"top_right\"\n",
    "    #     p.grid.grid_line_color=\"white\"\n",
    "\n",
    "    #     text_source = ColumnDataSource(dict(x=[x_bins.max()*3/4],y=[df_hist['count'].max()*3/4],text=['Total Day Count = \\n %d'%total]))\n",
    "    #     glyph = Text(x=\"x\", y=\"y\", text=\"text\", text_color=\"black\")\n",
    "    #     p.add_glyph(text_source, glyph)\n",
    "\n",
    "        # Add a hover tool referring to the formatted columns\n",
    "        hover = HoverTool(tooltips = [('#%s generated'%key, '@f_interval'),\n",
    "                                      ('Day count', '@f_count{0,0}'),\n",
    "                                      ('Day count percentage', '@f_percent')],\n",
    "                          mode= 'vline')\n",
    "\n",
    "        # Add the hover tool to the graph\n",
    "        p.add_tools(hover)\n",
    "        p2 = figure(y_axis_type=axis_type,\n",
    "                           x_axis_label = 'No. of %s'%key, \n",
    "                           y_axis_label = 'Day count',\n",
    "                           background_fill_color=\"#fafafa\")\n",
    "\n",
    "\n",
    "        p2_line = p2.line(x='x', y='count_cum', line_color='#036564', line_width=3, source=cum_src, legend=\"Cumulative distribution\")\n",
    "    #         p2_circle = p2.circle(x='x', y='count_cum', line_color='#036564', line_width=5, source=cum_src, hover_line_alpha=0.5, legend=\"Cumulative distribution\" )\n",
    "        p2.add_layout(Title(text = \"Cumulative distribution for number of %s generated\"%key, text_font_size = \"16pt\", text_font_style=\"bold\"), place = 'above')\n",
    "        p2.add_layout(Title(text=\"Date range: %s - %s\"%(df['date'].min().strftime('%Y, %b %d'),df['date'].max().strftime('%Y, %b %d'))), 'above')\n",
    "        p2.add_layout(Title(text=\"Total {} generated: {:,} | Total Days: {:,}\".format(key, total_files, total_days), text_font_style=\"italic\"), 'above')\n",
    "    #             p2.add_layout(Title(text=\"Total Days: %d\"%total_days, text_font_style=\"italic\"), 'above')\n",
    "    #             p2.add_layout(Title(text=\"Source ID: %d\"%sid, text_font_style=\"italic\"), 'above')\n",
    "\n",
    "        hover = HoverTool(line_policy='nearest', \n",
    "                          tooltips = [('#%s generated'%key, '<@x{0,0}'), \n",
    "                                      ('Percentage of %s generated'%key, '<@f_percent'),\n",
    "                                      ('Cumulative Day count', '@count_cum{0,0}')],\n",
    "                          mode='vline')\n",
    "\n",
    "    #         p2.add_layout(Span(location=1800, dimension='height'))#, legend='Expected date file count'))\n",
    "        \n",
    "        df_cumstats = pd.DataFrame({'height': np.linspace(df_cum['count_cum'].min(),df_cum['count_cum'].max(),2),\n",
    "                                 'mean':np.nanmean(counts), 'median': np.nanmedian(counts), 'mode':stats.mode(counts)[0][0]})\n",
    "        p2.line(x='mean', y='height', line_color=\"black\", line_dash='solid', line_width = 4, legend=\"Mean (%.2f)\"%(df_cumstats['mean'][0]), source=df_cumstats)\n",
    "        p2.line(x='median', y='height', line_color = \"red\", line_dash='dashed', line_width=3, legend=\"Median (%.2f)\"%(df_cumstats['median'][0]), source=df_cumstats)\n",
    "#         p2.line(x='mode', y='height', line_color = \"lightgreen\", line_dash = 'dashdot',line_width=2,legend=\"Mode (%.2f)\"%(df_cumstats['mode'][0]), source=df_cumstats)\n",
    "        \n",
    "        # Add the hover tool to the graph\n",
    "        p2.add_tools(hover)\n",
    "        p2.title.align = 'center'\n",
    "        p2.title.text_font_size = '18pt'\n",
    "        p2.xaxis.axis_label_text_font_size = '12pt'\n",
    "        p2.xaxis.major_label_text_font_size = '12pt'\n",
    "        p2.yaxis.axis_label_text_font_size = '12pt'\n",
    "        p2.yaxis.major_label_text_font_size = '12pt'\n",
    "        p2.legend.location = \"bottom_right\"\n",
    "        p2.yaxis[0].formatter = NumeralTickFormatter(format='0,0')\n",
    "        p2.xaxis[0].formatter = NumeralTickFormatter(format='0,0')\n",
    "\n",
    "\n",
    "        grid = gridplot([[p, p2]], sizing_mode='stretch_both')# width_policy='max', height_policy='max')#,plot_width=1200, plot_height=1000, sizing_mode='scale_width')#, plot_width=250, plot_height=250)\n",
    "        panel = Panel(child=grid, title=axis_type)\n",
    "    #     panel = Panel(child=p, title=axis_type)\n",
    "        panels.append(panel)\n",
    "    tabs = Tabs(tabs=panels)\n",
    "    show(tabs)\n",
    "    save(tabs, filename='./%s/histogram.html'%key, title='Histogram for Helioviewer %s generated every day'%key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weekday frequency distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for key in hv.keys():\n",
    "    df = hv[key].copy()\n",
    "    df['weekday'] = df['date'].dt.weekday_name\n",
    "    weekdays = [ 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "    df = df.groupby('weekday').sum().reindex(weekdays)\n",
    "    df['weekday'] = df.index\n",
    "    df = df.reset_index(drop=True)\n",
    "    df\n",
    "\n",
    "    # Column data source\n",
    "    df['percent'] = np.float64([\"%.2f\"%(count/df['count'].sum()*100) for count in df['count']])\n",
    "    df['percent%'] = df['percent'].astype(str)+\"%\"\n",
    "    df['vbar_top'] = df['count'].astype(str) + '\\n' + df['percent'].astype(str)+'%'\n",
    "    df_src = ColumnDataSource(df)\n",
    "    panels = []\n",
    "    for axis_type in [\"linear\",\"log\"]:\n",
    "        p = figure(x_range = df['weekday'],\n",
    "                   y_axis_type = axis_type,\n",
    "                   x_axis_label = 'Weekdays', y_axis_label = 'Day count', \n",
    "                   background_fill_color=\"#fafafa\", aspect_ratio=16/9, plot_width=1000)\n",
    "\n",
    "        # Add a quad glyph with source this time\n",
    "        p.vbar(x='weekday', top='count', width=0.75, source=df_src, bottom=0.1,\n",
    "               hover_fill_alpha=0.5, line_color='white', legend=\"weekday\",\n",
    "               fill_color=factor_cmap('weekday', palette=bp.Spectral7, factors=df['weekday']),\n",
    "               hover_fill_color=factor_cmap('weekday', palette=bp.Spectral7, factors=df['weekday']), \n",
    "              )\n",
    "        # Add style to the plot\n",
    "        p.title.align = 'center'\n",
    "        p.title.text_font_size = '18pt'\n",
    "        p.xaxis.axis_label_text_font_size = '12pt'\n",
    "        p.xaxis.major_label_text_font_size = '12pt'\n",
    "        p.yaxis.axis_label_text_font_size = '12pt'\n",
    "        p.yaxis.major_label_text_font_size = '12pt'\n",
    "        p.xgrid.grid_line_color = None\n",
    "        p.y_range.start = 0.1\n",
    "        p.y_range.end = df['count'].max()*1.5\n",
    "        p.yaxis[0].formatter = NumeralTickFormatter(format='0,0')\n",
    "        \n",
    "        if(axis_type==\"log\"): p.y_range.end = df['count'].max()**1.5\n",
    "\n",
    "        p.add_layout(Title(text = \"Frequency of %s generated per weekday\"%key, text_font_size = \"16pt\", text_font_style=\"bold\"), place = 'above')\n",
    "        p.add_layout(Title(text=\"Date range: %s - %s\"%(hv[key]['date'].min().strftime('%Y, %b %d'),hv[key]['date'].max().strftime('%Y, %b %d'))), 'above')\n",
    "        p.add_layout(Title(text=\"Total {} generated: {:,} | Total Days: {:,}\".format(key,df['count'].sum(), total_days), text_font_style=\"italic\"), 'above')\n",
    "\n",
    "        p.legend.orientation = \"horizontal\"\n",
    "        p.legend.location = \"top_center\"\n",
    "        p.grid.grid_line_color=\"white\"\n",
    "        labels = LabelSet(x='weekday', y='count', text='percent%', level='glyph',\n",
    "                          x_offset=-30, y_offset=0, source=df_src, render_mode='canvas')\n",
    "        p.add_layout(labels)\n",
    "\n",
    "        # Add a hover tool referring to the formatted column\n",
    "\n",
    "        hover = HoverTool(tooltips = [('%s generated'%key, '@count{0,0}'),\n",
    "                                      ('Percentage of %s generated'%key, '@percent%')],\n",
    "                          mode= 'vline')\n",
    "\n",
    "    #     Add the hover tool to the graph\n",
    "        p.add_tools(hover)\n",
    "        panel = Panel(child=p, title=axis_type)\n",
    "        panels.append(panel)\n",
    "    tabs = Tabs(tabs=panels)\n",
    "    show(tabs)\n",
    "    save(tabs, filename='./%s/weekday_freq.html'%key, title='Histogram for Helioviewer %s generated every day'%key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weekday frequency against week number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_service = pd.concat([pd.DataFrame({'date': pd.date_range('2011/08/11', '2011/09/18'), 'reason':\"GSFC server repair \\n (2011/08/11 - 2011/09/18)\"}),\n",
    "                        pd.DataFrame({'date': pd.date_range('2013/10/01', '2013/10/16'), 'reason':\"U.S. Fed. Gov. shutdown \\n  (2013/10/01 - 2013/10/16)\"}),\n",
    "                        pd.DataFrame({'date': pd.date_range('2015/02/04', '2015/09/23'), 'reason':\"GSFC server down   \\n (2015/02/04 - 2015/09/23)\"})],\n",
    "                       ignore_index=True)\n",
    "df_service['weekday'] = df_service['date'].dt.weekday_name\n",
    "df_service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for key in hv.keys():\n",
    "    df = hv[key].copy()\n",
    "    df['weekday'] = df['date'].dt.weekday_name\n",
    "    df['weeknumber'] = ((df['date']-df['date'][0]).dt.days/7).astype(int)\n",
    "    df_service['weeknumber'] = ((df_service['date']-df['date'][0]).dt.days/7).astype(int)\n",
    "    # df = df.groupby(['weeknumber','weekday']).sum().reset_index()\n",
    "\n",
    "    weeknumber = np.array(df['weeknumber'].unique()).astype(str)# hv_cov.index.values#.astype(str)\n",
    "    # weekdays = weekdays# df['weekday'].unique().astype(str) # np.arange(1,32).astype(str)\n",
    "\n",
    "    colors = bp.Viridis[256]# [\"#75968f\", \"#a5bab7\", \"#c9d9d3\", \"#e2e2e2\", \"#dfccce\", \"#ddb7b1\", \"#cc7878\", \"#933b41\", \"#550b1d\"]\n",
    "\n",
    "    TOOLS = \"save,pan,box_zoom,reset,wheel_zoom\"\n",
    "\n",
    "    # output_file('AIA1600_coverage.html')\n",
    "    panels = []\n",
    "    for mapper_type, mapper, ticker in zip([\"log\", \"linear\"],\n",
    "                                           [LogColorMapper, LinearColorMapper],\n",
    "                                           [LogTicker, BasicTicker]):\n",
    "        p = figure(#x_axis_type='datetime',\n",
    "                   x_range=weeknumber, y_range=list(reversed(weekdays)),\n",
    "                   x_axis_location=None, sizing_mode='stretch_both',# width_policy='max', height_policy='max',#, \n",
    "    #                plot_width=2000,\n",
    "                   x_axis_label=\"Weeks since first data\", y_axis_label=\"Weekday\",\n",
    "                   tools=TOOLS)\n",
    "\n",
    "        p_rect = p.rect(x=\"weeknumber\", y=\"weekday\", width=1, height=1,\n",
    "               source=df,\n",
    "               color={'field': 'count', 'transform': mapper(palette=colors, low=0.1, high=np.nanmax(df['count']))},\n",
    "               hover_fill_alpha=0.2)\n",
    "\n",
    "        p.add_tools(HoverTool(renderers = [p_rect], \n",
    "                              tooltips=[('Week Number', '@weeknumber'), \n",
    "                                        ('#%s generated'%key, '@count{0,0}'), \n",
    "                                        ('Date','@date{%F}')],\n",
    "                              formatters={'date': 'datetime'}\n",
    "        ))\n",
    "        xaxis = LinearAxis(ticker=SingleIntervalTicker(interval=7, num_minor_ticks= 1))\n",
    "        p.add_layout(xaxis, 'above')\n",
    "        p.xaxis.axis_label = \"Weeks since first data\"\n",
    "        # p.grid.grid_line_color = None\n",
    "        p.axis.axis_line_color = None\n",
    "        p.axis.major_tick_line_color = None\n",
    "        p.axis.major_label_text_font_size = \"7px\"\n",
    "        p.axis.major_label_standoff = 0\n",
    "        p.xaxis.major_label_orientation = np.pi / 3\n",
    "        p.xaxis.axis_label_text_font_size = \"12pt\"\n",
    "    #     p.xaxis.major_label_text_color = {'field': 'weeknumber', 'transform': mapper(palette=bp.Spectral6, low=0.1, high=np.nanmax(df['count']))}\n",
    "        p.yaxis.axis_label_text_font_size = \"12pt\"\n",
    "        p.xaxis.visible = True\n",
    "        p.xgrid.visible = False\n",
    "        p.ygrid.visible = False\n",
    "\n",
    "        p.xaxis.major_label_text_font_size = \"7pt\"\n",
    "        p.yaxis.major_label_text_font_size = \"8pt\"\n",
    "\n",
    "        p.add_layout(Title(text = \"Weekday frequency against week number\", text_font_size = \"16pt\", text_font_style=\"bold\"), place = 'above')\n",
    "        p.add_layout(Title(text=\"Date range: %s - %s\"%(hv[key]['date'].min().strftime('%Y, %b %d'),hv[key]['date'].max().strftime('%Y, %b %d'))), 'above')\n",
    "        p.add_layout(Title(text=\"Total {} generated: {:,} | Total days: {:,} \".format(key,df['count'].sum(), len(df)), text_font_style=\"italic\"), 'above')\n",
    "        \n",
    "        p_service = p.rect(x=\"weeknumber\", y=\"weekday\", width=1, height=1,\n",
    "                           source=df_service,\n",
    "                           fill_color='red', fill_alpha=0.5, hover_fill_alpha=0.2, line_color=None)\n",
    "        p.add_tools(HoverTool(renderers = [p_service], \n",
    "                              tooltips=[('Week Number', '@weeknumber'), \n",
    "                                        ('Shutdown', '@reason'), \n",
    "                                        ('Date','@date{%F}')],\n",
    "                              formatters={'date': 'datetime'}))\n",
    "\n",
    "        num_ticks=10\n",
    "        if (len(df[df['count']>0]['count'].unique()) <= 10):\n",
    "            num_ticks = len(df[df['count']>0]['count'].unique())\n",
    "        color_bar = ColorBar(color_mapper = mapper(palette=colors, low=0.1, high=np.nanmax(df['count'])), \n",
    "                             major_label_text_font_size=\"10px\",\n",
    "                             ticker=ticker(desired_num_ticks=num_ticks),\n",
    "                             formatter=PrintfTickFormatter(format=\"%d\"),\n",
    "                             label_standoff=6, border_line_color=None, location=(0, 0))\n",
    "        p.add_layout(color_bar, 'right')\n",
    "    #             p.width_policy = 'fit'\n",
    "    #             p.height_policy = 'fit'\n",
    "        panel = Panel(child=p, title=mapper_type)\n",
    "        panels.append(panel)\n",
    "    tabs = Tabs(tabs=panels)\n",
    "    show(tabs)\n",
    "    save(tabs, filename='./%s/weeknumber_frequency.html'%key, title='Weekday frequency against weeknumber for %s'%key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "TOOLS = \"save, pan, box_zoom, reset, wheel_zoom\"\n",
    "for key in hv.keys():\n",
    "    df = hv[key].copy()\n",
    "    df = df.set_index('date')\n",
    "    df = df.reindex(pd.date_range(df.index.min(), df.index.max(), freq='D').to_period('D').to_timestamp(),\n",
    "                                  fill_value=0)\n",
    "    df['date'] = df.index\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    df['weekday'] = df['date'].dt.weekday_name\n",
    "    df['weeknumber'] = ((df['date']-df['date'][0]).dt.days/7).astype(int)\n",
    "    df_service['weeknumber'] = ((df_service['date']-df['date'][0]).dt.days/7).astype(int)\n",
    "    # df = df.groupby(['weeknumber','weekday']).sum().reset_index()\n",
    "    weeknumber = np.array(df['weeknumber'].unique())# hv_cov.index.values#.astype(str)\n",
    "   \n",
    "    color = {weekdays[i]:bp.Spectral7[i] for i in range(len(weekdays))}\n",
    "    p_wd=[]\n",
    "    panels=[]\n",
    "    for wd in weekdays:\n",
    "        df_wd = df.loc[df['weekday']==wd]\n",
    "        p = figure(x_axis_type=\"datetime\",tools=TOOLS,\n",
    "                   plot_height=200, sizing_mode=\"scale_width\", \n",
    "                   title=\"Weekly coverage of %s for %s\"%(key, wd),\n",
    "                   x_axis_label=\"Date\", \n",
    "                   y_axis_label=\"Count\")\n",
    "        \n",
    "        p.title.text_font_size = '16pt'\n",
    "        p.line(x='date', y='count', source=df_wd, legend=wd, color=\"red\")\n",
    "        p.add_tools(HoverTool(tooltips=[('Week Number', '@weeknumber'), \n",
    "                                        ('Date','@date{%F}'),\n",
    "                                        ('count','@count')],\n",
    "                              formatters={'date': 'datetime'},\n",
    "                              mode='vline'))\n",
    "        service_pause(p, df_wd)\n",
    "        panel=Panel(child = p, title=wd)\n",
    "        panels.append(panel)\n",
    "    tabs=Tabs(tabs=panels)\n",
    "#     grid = gridplot(list(np.array([p_wd]).T), sizing_mode=\"scale_width\")\n",
    "    show(tabs)\n",
    "    save(tabs, filename='%s/weekly_weekday.html'%key, title='Weekly coverage of movies per weekday')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_wd.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for wd in ['Monday']:\n",
    "    df_wd = df.loc[df['weekday']==wd]\n",
    "    plt.figure()\n",
    "    plt.subplot(211)\n",
    "    plt.plot(df_wd['weeknumber'], df_wd['count'], label=wd)\n",
    "    plt.subplot(212)\n",
    "    freq = np.fft.fftfreq(df_wd['weeknumber'].size,d=1)[:df_wd['weeknumber'].size//2]\n",
    "    ft = np.fft.fft(df_wd['count'])[:df_wd['weeknumber'].size//2]/df_wd['count'].size\n",
    "    df_ft = pd.DataFrame()\n",
    "    df_ft['freq'] = freq\n",
    "    df_ft['ft'] = abs(ft)\n",
    "    plt.plot(df_ft['freq'], df_ft['ft'])\n",
    "    plt.ylim(0,50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "1/df_ft.loc[df_ft['freq']>0.01].sort_values('ft')['freq'].iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = np.array(df_wd['weeknumber'])\n",
    "dt = x[1]-x[0]\n",
    "nf = int(x.size/2+1)\n",
    "f = np.arange(0,nf)\n",
    "f = f/(dt*x.size)\n",
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Popularity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_url = urllib.request.urlopen('https://api.helioviewer.org/?action=getDataSources')\n",
    "hv_keys = json.loads(json_url.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv_sid = pd.DataFrame(columns=['OBS','SOURCE_ID'])\n",
    "\n",
    "# while sid=='sourceId':\n",
    "#     key=hv_keys.keys()\n",
    "\n",
    "for key1 in hv_keys.keys():\n",
    "    for key2 in hv_keys[key1].keys():\n",
    "        if 'sourceId' in hv_keys[key1][key2].keys(): \n",
    "            hv_sid.loc[len(hv_sid)] = \" \".join([key1, key2]), hv_keys[key1][key2]['sourceId']\n",
    "        else:\n",
    "            for key3 in hv_keys[key1][key2].keys():\n",
    "                if 'sourceId' in hv_keys[key1][key2][key3].keys(): \n",
    "                    hv_sid.loc[len(hv_sid)] = \" \".join([key1, key2, key3]), hv_keys[key1][key2][key3]['sourceId']\n",
    "                else:\n",
    "                    for key4 in hv_keys[key1][key2][key3].keys():\n",
    "                        if 'sourceId' in hv_keys[key1][key2][key3][key4].keys(): \n",
    "                            hv_sid.loc[len(hv_sid)] = \" \".join([key1, key2, key3, key4]), hv_keys[key1][key2][key3][key4]['sourceId']\n",
    "                        else:\n",
    "                            for key5 in hv_keys[key1][key2][key3][key4].keys():\n",
    "                                if 'sourceId' in hv_keys[key1][key2][key3][key4][key5].keys(): \n",
    "                                    hv_sid.loc[len(hv_sid)] = \" \".join([key1, key2, key3, key4, key5]), hv_keys[key1][key2][key3][key4][key5]['sourceId']\n",
    "                                else:\n",
    "                                    for key6 in hv_keys[key1][key2][key3][key4][key5].keys():\n",
    "                                        if 'sourceId' in hv_keys[key1][key2][key3][key4][key5][key6].keys(): \n",
    "                                            hv_sid.loc[len(hv_sid)] = \" \".join([key1, key2, key3, key4, key5,key6]), hv_keys[key1][key2][key3][key4][key5][key6]['sourceId']    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OBS</th>\n",
       "      <th>SOURCE_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SOHO EIT 171</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SOHO EIT 195</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SOHO EIT 284</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SOHO EIT 304</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SOHO LASCO C2 white-light</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Hinode XRT Al_poly Any</td>\n",
       "      <td>10009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Hinode XRT Be_med Any</td>\n",
       "      <td>10010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Hinode XRT Be_thin Any</td>\n",
       "      <td>10011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Hinode XRT C_poly Any</td>\n",
       "      <td>10012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Hinode XRT Open Any</td>\n",
       "      <td>10013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>77 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          OBS SOURCE_ID\n",
       "0                SOHO EIT 171         0\n",
       "1                SOHO EIT 195         1\n",
       "2                SOHO EIT 284         2\n",
       "3                SOHO EIT 304         3\n",
       "4   SOHO LASCO C2 white-light         4\n",
       "..                        ...       ...\n",
       "72     Hinode XRT Al_poly Any     10009\n",
       "73      Hinode XRT Be_med Any     10010\n",
       "74     Hinode XRT Be_thin Any     10011\n",
       "75      Hinode XRT C_poly Any     10012\n",
       "76        Hinode XRT Open Any     10013\n",
       "\n",
       "[77 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hv_sid = hv_sid.sort_values(['SOURCE_ID']).reset_index(drop=True)\n",
    "hv_sid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sourceId=15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hv['data'] = sql_query(\"SELECT date FROM data FORCE INDEX (date_index) WHERE sourceId={};\".format(sourceId))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>SOURCE_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-06-02 00:05:30</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-06-02 00:05:54</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-06-02 00:06:18</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-06-23 00:00:17</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-06-23 00:00:41</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7056347</th>\n",
       "      <td>2020-08-03 13:59:26</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7056348</th>\n",
       "      <td>2020-08-03 14:00:14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7056349</th>\n",
       "      <td>2020-08-03 14:01:02</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7056350</th>\n",
       "      <td>2020-08-03 14:01:50</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7056351</th>\n",
       "      <td>2020-08-03 14:02:38</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7056352 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                       date  SOURCE_ID\n",
       "0       2010-06-02 00:05:30         15\n",
       "1       2010-06-02 00:05:54         15\n",
       "2       2010-06-02 00:06:18         15\n",
       "3       2010-06-23 00:00:17         15\n",
       "4       2010-06-23 00:00:41         15\n",
       "...                     ...        ...\n",
       "7056347 2020-08-03 13:59:26         15\n",
       "7056348 2020-08-03 14:00:14         15\n",
       "7056349 2020-08-03 14:01:02         15\n",
       "7056350 2020-08-03 14:01:50         15\n",
       "7056351 2020-08-03 14:02:38         15\n",
       "\n",
       "[7056352 rows x 2 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hv['data']['SOURCE_ID'] = sourceId\n",
    "hv['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.620729684829712\n"
     ]
    }
   ],
   "source": [
    "start_time=time.time()\n",
    "hv['movies'] = sql_query(\"SELECT startDate, endDate FROM movies WHERE dataSourceString LIKE \\'%SDO%AIA%1600%\\';\")\n",
    "print(time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>startDate</th>\n",
       "      <th>endDate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-05-26 20:27:05</td>\n",
       "      <td>2011-05-27 07:49:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-05-15 11:32:41</td>\n",
       "      <td>2011-05-16 11:27:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-05-15 11:32:41</td>\n",
       "      <td>2011-05-16 11:27:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-05-15 11:32:41</td>\n",
       "      <td>2011-05-16 11:27:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-05-28 20:00:17</td>\n",
       "      <td>2011-05-28 22:59:05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13297</th>\n",
       "      <td>2020-08-18 13:19:26</td>\n",
       "      <td>2020-08-18 14:19:26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13298</th>\n",
       "      <td>2014-10-25 16:40:16</td>\n",
       "      <td>2014-10-25 18:39:28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13299</th>\n",
       "      <td>2014-10-25 16:40:14</td>\n",
       "      <td>2014-10-25 18:39:29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13300</th>\n",
       "      <td>2020-08-20 21:06:59</td>\n",
       "      <td>2020-08-21 08:22:35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13301</th>\n",
       "      <td>2014-05-10 06:00:16</td>\n",
       "      <td>2014-05-10 07:59:52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13302 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                startDate             endDate\n",
       "0     2011-05-26 20:27:05 2011-05-27 07:49:29\n",
       "1     2011-05-15 11:32:41 2011-05-16 11:27:05\n",
       "2     2011-05-15 11:32:41 2011-05-16 11:27:05\n",
       "3     2011-05-15 11:32:41 2011-05-16 11:27:05\n",
       "4     2011-05-28 20:00:17 2011-05-28 22:59:05\n",
       "...                   ...                 ...\n",
       "13297 2020-08-18 13:19:26 2020-08-18 14:19:26\n",
       "13298 2014-10-25 16:40:16 2014-10-25 18:39:28\n",
       "13299 2014-10-25 16:40:14 2014-10-25 18:39:29\n",
       "13300 2020-08-20 21:06:59 2020-08-21 08:22:35\n",
       "13301 2014-05-10 06:00:16 2014-05-10 07:59:52\n",
       "\n",
       "[13302 rows x 2 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hv['movies']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'SDO AIA 1600'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hv_sid.loc[hv_sid['SOURCE_ID']==sourceId]['OBS'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sql_hv(sourceId, obs=None):\n",
    "    query = \"SELECT date_format(date, '%Y-%m-%d 00:00:00') as date, count(*) as count FROM data FORCE INDEX (date_index) WHERE sourceId={} GROUP BY date_format(date, '%Y-%m-%d 00:00:00');\".format(sourceId)\n",
    "    hv = sql_query(query)\n",
    "    return hv_prepare(hv, sourceId, obs)\n",
    "\n",
    "par = Parallel(n_jobs=20)\n",
    "start_time=time.time()\n",
    "results = par(delayed(sql_hv)(df['SOURCE_ID'], df['OBS']) for ind, df in hv_sid.iterrows())\n",
    "print(time.time()-start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
